{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scraper Bot\n",
    "\n",
    "In this notebook, we create a bot that will automatically collect job postings from LinkedIn.\n",
    "\n",
    "Shoutout to Matan Freedman for the inspiration and the initial code structure:\n",
    "<a href=\"https://medium.com/nerd-for-tech/linked-in-web-scraper-using-selenium-15189959b3ba\">article here.</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from src.bot.ScraperNew import ScraperNew\n",
    "from src.database.csv import save_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FOLDER = '../data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in...\n"
     ]
    }
   ],
   "source": [
    "# Create a scraper object\n",
    "scraper = ScraperNew(delay=1)\n",
    "\n",
    "# Login to LinkedIn\n",
    "scraper.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for jobs: data scientist in canada\n",
      "Found 3 search bars\n",
      "Location search bar not found.\n",
      "Getting pagination buttons...\n",
      "Found 4 pagination buttons\n"
     ]
    }
   ],
   "source": [
    "# Search jobs by title and location\n",
    "job_title = 'data scientist'\n",
    "job_location = 'canada'\n",
    "scraper.search_jobs(job_title, job_location)\n",
    "\n",
    "# Get the  pagination buttons\n",
    "time.sleep(2)\n",
    "pagination_buttons = scraper.get_pagination_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page_jobs = scraper.get_current_page_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_page_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pagination buttons...\n",
      "Found 4 pagination buttons\n"
     ]
    }
   ],
   "source": [
    "pagination_buttons = scraper.get_pagination_buttons()\n",
    "pagination_buttons[1].click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Job Data\n",
    "\n",
    "Search for jobs and loop through all pages to get the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_job_data(job_title, job_location, delay=3):\n",
    "    \n",
    "    # Perform the initial search\n",
    "    scraper.search_jobs(job_title, job_location)\n",
    "    time.sleep(delay)\n",
    "\n",
    "    # Get the pagination buttons\n",
    "    pagination_buttons = scraper.get_pagination_buttons()\n",
    "    num_pages = len(pagination_buttons)\n",
    "    print(f\"{num_pages} pages found\")\n",
    "\n",
    "    all_jobs = []\n",
    "\n",
    "    # Loop through each page\n",
    "    # We stop at num_pages, clicking “Next” after each scrape\n",
    "    for page_idx in range(num_pages):\n",
    "        print(f\"--- Page {page_idx + 1}/{num_pages} ---\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "        try:\n",
    "            # — scrape this page —\n",
    "            current_page_jobs = scraper.get_current_page_jobs()\n",
    "            all_jobs.extend(current_page_jobs)\n",
    "\n",
    "            # If there’s a next page, click it —\n",
    "            if page_idx < num_pages - 1:\n",
    "                # Re-grab buttons to avoid StaleElementReference\n",
    "                pagination_buttons = scraper.get_pagination_buttons()\n",
    "                next_button = pagination_buttons[page_idx + 1]\n",
    "                next_button.click()\n",
    "\n",
    "        except StaleElementReferenceException as e:\n",
    "            print(f\"StaleElementReferenceException on page {page_idx+1}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error on page {page_idx+1}: {e}\")\n",
    "\n",
    "    return all_jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = [\n",
    "    \"data scientist\",\n",
    "    \"machine learning engineer\",\n",
    "    \"deep learning engineer\",\n",
    "    \"mlops engineer\",\n",
    "    \"llm engineer\",\n",
    "    \"ai engineer\",\n",
    "    \"ai researcher\",\n",
    "    \"generative ai engineer\",\n",
    "    \"prompt engineer\",\n",
    "    \"NLP engineer\",\n",
    "    \"computer vision engineer\",\n",
    "    \"applied scientist\",\n",
    "    \"AI software engineer\"\n",
    "]\n",
    "job_location = \"canada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Collecting data for: Ai Software Engineer ===\n",
      "Searching for jobs: AI software engineer in canada\n",
      "Found 3 search bars\n",
      "Location search bar not found.\n",
      "Getting pagination buttons...\n",
      "Found 4 pagination buttons\n",
      "4 pages found\n",
      "--- Page 1/4 ---\n",
      "Getting current page jobs…\n",
      "Scrolling all job listings...\n",
      "Layout detected: AI-powered\n",
      "  → 25 cards loaded so far…\n",
      "  → 25 cards loaded so far…\n",
      "Reached bottom of job list.\n",
      "Layout detected: AI-powered\n",
      "Found 25 job cards.\n",
      "Gathering job 0 information...\n",
      "Gathering job 1 information...\n",
      "Gathering job 2 information...\n",
      "Gathering job 3 information...\n",
      "Gathering job 4 information...\n",
      "Gathering job 5 information...\n",
      "Gathering job 6 information...\n",
      "Gathering job 7 information...\n",
      "Gathering job 8 information...\n",
      "Gathering job 9 information...\n",
      "Gathering job 10 information...\n",
      "Gathering job 11 information...\n",
      "Gathering job 12 information...\n",
      "Gathering job 13 information...\n",
      "Gathering job 14 information...\n",
      "Gathering job 15 information...\n",
      "Gathering job 16 information...\n",
      "Gathering job 17 information...\n",
      "Gathering job 18 information...\n",
      "Gathering job 19 information...\n",
      "Gathering job 20 information...\n",
      "Gathering job 21 information...\n",
      "Gathering job 22 information...\n",
      "Gathering job 23 information...\n",
      "Gathering job 24 information...\n",
      "Getting pagination buttons...\n",
      "Found 4 pagination buttons\n",
      "--- Page 2/4 ---\n",
      "Getting current page jobs…\n",
      "Scrolling all job listings...\n",
      "Layout detected: AI-powered\n",
      "  → 25 cards loaded so far…\n",
      "  → 25 cards loaded so far…\n",
      "Reached bottom of job list.\n",
      "Layout detected: AI-powered\n",
      "Found 25 job cards.\n",
      "Gathering job 0 information...\n",
      "Gathering job 1 information...\n",
      "Gathering job 2 information...\n",
      "Gathering job 3 information...\n",
      "Gathering job 4 information...\n",
      "Gathering job 5 information...\n",
      "Gathering job 6 information...\n",
      "Gathering job 7 information...\n",
      "Gathering job 8 information...\n",
      "Gathering job 9 information...\n",
      "Gathering job 10 information...\n",
      "Gathering job 11 information...\n",
      "Gathering job 12 information...\n",
      "Gathering job 13 information...\n",
      "Gathering job 14 information...\n",
      "Gathering job 15 information...\n",
      "Gathering job 16 information...\n",
      "Gathering job 17 information...\n",
      "Gathering job 18 information...\n",
      "Gathering job 19 information...\n",
      "Gathering job 20 information...\n",
      "Gathering job 21 information...\n",
      "Gathering job 22 information...\n",
      "Gathering job 23 information...\n",
      "Gathering job 24 information...\n",
      "Getting pagination buttons...\n",
      "Found 4 pagination buttons\n",
      "--- Page 3/4 ---\n",
      "Getting current page jobs…\n",
      "Scrolling all job listings...\n",
      "Layout detected: AI-powered\n",
      "  → 25 cards loaded so far…\n",
      "  → 25 cards loaded so far…\n",
      "Reached bottom of job list.\n",
      "Layout detected: AI-powered\n",
      "Found 25 job cards.\n",
      "Gathering job 0 information...\n",
      "Gathering job 1 information...\n",
      "Gathering job 2 information...\n",
      "Gathering job 3 information...\n",
      "Gathering job 4 information...\n",
      "Gathering job 5 information...\n",
      "Gathering job 6 information...\n",
      "Gathering job 7 information...\n",
      "Gathering job 8 information...\n",
      "Gathering job 9 information...\n",
      "Gathering job 10 information...\n",
      "Gathering job 11 information...\n",
      "Gathering job 12 information...\n",
      "Gathering job 13 information...\n",
      "Gathering job 14 information...\n",
      "Gathering job 15 information...\n",
      "Gathering job 16 information...\n",
      "Gathering job 17 information...\n",
      "Gathering job 18 information...\n",
      "Gathering job 19 information...\n",
      "Gathering job 20 information...\n",
      "Gathering job 21 information...\n",
      "Gathering job 22 information...\n",
      "Gathering job 23 information...\n",
      "Gathering job 24 information...\n",
      "Getting pagination buttons...\n",
      "Found 5 pagination buttons\n",
      "--- Page 4/4 ---\n",
      "Getting current page jobs…\n",
      "Scrolling all job listings...\n",
      "Layout detected: AI-powered\n",
      "  → 25 cards loaded so far…\n",
      "  → 25 cards loaded so far…\n",
      "Reached bottom of job list.\n",
      "Layout detected: AI-powered\n",
      "Found 25 job cards.\n",
      "Gathering job 0 information...\n",
      "Gathering job 1 information...\n",
      "Gathering job 2 information...\n",
      "Gathering job 3 information...\n",
      "Gathering job 4 information...\n",
      "Gathering job 5 information...\n",
      "Gathering job 6 information...\n",
      "Gathering job 7 information...\n",
      "Gathering job 8 information...\n",
      "Gathering job 9 information...\n",
      "Gathering job 10 information...\n",
      "Gathering job 11 information...\n",
      "Gathering job 12 information...\n",
      "Gathering job 13 information...\n",
      "Gathering job 14 information...\n",
      "Gathering job 15 information...\n",
      "Gathering job 16 information...\n",
      "Gathering job 17 information...\n",
      "Gathering job 18 information...\n",
      "Gathering job 19 information...\n",
      "Gathering job 20 information...\n",
      "Gathering job 21 information...\n",
      "StaleElementReferenceException on page 4: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=138.0.7204.158); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x7ff72784e925+77845]\n",
      "\tGetHandleVerifier [0x0x7ff72784e980+77936]\n",
      "\t(No symbol) [0x0x7ff727609cda]\n",
      "\t(No symbol) [0x0x7ff727611679]\n",
      "\t(No symbol) [0x0x7ff72761471c]\n",
      "\t(No symbol) [0x0x7ff7276147ef]\n",
      "\t(No symbol) [0x0x7ff72765a1b6]\n",
      "\t(No symbol) [0x0x7ff7276888ca]\n",
      "\t(No symbol) [0x0x7ff727652f76]\n",
      "\t(No symbol) [0x0x7ff727688ae0]\n",
      "\t(No symbol) [0x0x7ff7276b0b07]\n",
      "\t(No symbol) [0x0x7ff7276886a3]\n",
      "\t(No symbol) [0x0x7ff727651791]\n",
      "\t(No symbol) [0x0x7ff727652523]\n",
      "\tGetHandleVerifier [0x0x7ff727b2683d+3059501]\n",
      "\tGetHandleVerifier [0x0x7ff727b20bfd+3035885]\n",
      "\tGetHandleVerifier [0x0x7ff727b403f0+3164896]\n",
      "\tGetHandleVerifier [0x0x7ff727868c2e+185118]\n",
      "\tGetHandleVerifier [0x0x7ff72787053f+216111]\n",
      "\tGetHandleVerifier [0x0x7ff7278572d4+113092]\n",
      "\tGetHandleVerifier [0x0x7ff727857489+113529]\n",
      "\tGetHandleVerifier [0x0x7ff72783e288+10616]\n",
      "\tBaseThreadInitThunk [0x0x7ffbb2f5e8d7+23]\n",
      "\tRtlUserThreadStart [0x0x7ffbb33fc34c+44]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_jobs_titles = []\n",
    "for title in job_titles:\n",
    "    print(f\"\\n=== Collecting data for: {title.title()} ===\")\n",
    "    try:\n",
    "        # Collect job data for the given title and location\n",
    "        jobs = collect_job_data(title, job_location, delay=3)\n",
    "        columns = [\"Job Title\", \"Company\", \"City\", \"Work Mode\", \"Description\", \"Skills\"]\n",
    "\n",
    "        # print(f\"---------------->\")\n",
    "        # print(jobs)  # Print the first two jobs for verification\n",
    "\n",
    "        all_jobs_titles.extend(jobs)\n",
    "        \n",
    "        # Save the jobs to a CSV file with the title as the filename\n",
    "        save_to_csv(\n",
    "            data=jobs,\n",
    "            folder=RAW_FOLDER,\n",
    "            filename=title,\n",
    "            colnames=columns\n",
    "        )\n",
    "\n",
    "        # break\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while collecting data for {title}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.close_driver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
