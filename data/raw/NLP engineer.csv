Job Title,Company,City,Work Mode,Description,Skills
Software Developer - Machine Learning (NLP),Coveo,"Quebec, Canada",Hybrid,"About the job
Enable NLP technology reuse across the company
As a Software Developer in Machine Learning, you will play a key role in supporting teams of applied scientists and ML developers who train, evaluate, and use a variety of NLP models, including LLMs.

Your team is the CoreNLP team, a mix of scientists and developers who provide reusable NLP technologies that accelerate delivery for the other teams in your unit. Your mission is to contribute to prototyping, productionizing, and maintaining the NLP technologies that power some of Coveo's most visible AI capabilities.

Here is what makes this opportunity exciting:
Your team is uniquely positioned to impact Coveo’s research and development efforts and offers one of the best environments to quickly get up to speed with state-of-the-art NLP technology.

The ML unit at Coveo focuses on finding ways to apply the latest advances in Recommender Systems, Ranking Optimization, LLMs and NLP to build innovative solutions in commerce, self-service and other business verticals. We solve real problems with real data, for hundreds of large enterprise clients all around the world, on a modern platform that serves over 100M requests and automatically trains thousands of ML models on a daily basis.

Here is a glimpse at your responsibilities:
Participate directly in every aspect of NLP technology delivery: requirements gathering, conception, implementation, automated testing, release, monitoring, maintenance, etc.
Along with the rest of your team, make continuous learning a weekly practice that ensures awareness of emerging opportunities in the field.
Identify current pain points in NLP research and development and deliver software that addresses them.
Engage with your community of peers to challenge the status quo, improve our shared ways of working, and influence overall architecture decisions.
Learn, utilize and evolve our data and tech stack which includes Python, AWS, Snowflake, Honeycomb and others.

Here is what will qualify you for the role:
3+ years of industry experience in Machine Learning, including maintaining internal tools and libraries relied on by other teams.
Strong fluency in data and software engineering best practices, with a proven ability to deliver reliable production code efficiently.
A collaborative mindset: you enjoy working closely with scientists to understand their challenges and improve their tools and workflows.
Experience with widely used NLP libraries such as Langchain, Haystack, and Transformers.

Here is what will make you stand out:
Familiarity with asynchronous programming.
Domain knowledge in areas like Natural Language Processing, Information Retrieval or Retrieval Augmented Generation, along with an understanding of the technical implications of building software for such use cases.
Excellent communication skills and the ability to clearly explain complex technical concepts to audiences with varying levels of technical proficiency.

Do you think you can bring this role to life?
You don’t need to check every single box; passion goes a long way and we appreciate that skillsets are transferable. Send us your CV, we want to get to know you! Join the #Coveolife!

We encourage all qualified applications regardless of, for example, age, gender, disability, gaps in CV, national or ethnic background. We know that applying for a new role is a lot of work and we really appreciate your time.

#li-hybrid #li-remote",[]
Senior Principal Researcher-NLP,Huawei Canada,,,"About the job
Huawei Canada has an immediate permanent opening for a Senior Principal Researcher.

About the team:

We are a growing, dynamic and diverse team driving AI innovation in a large organization with a vast network of R&D centers across the world. The NLP team in Huawei's Noah's Ark Lab is working on the future of Large Language Model (LLM). We are committed to training LLM, improving LLM, and applying LLM to many business scenarios both inside and outside Huawei Company to create value for our customers.

About the job:

Responsible for the development strategy, technical path, and key technology direction in the fields of NLP and Large Language Model.
Lead research, develop state-of the-art AI solutions and collaborate with product groups to deploy them in real-world settings.
Identify new and upcoming research areas by interacting with potential external and internal collaborators.
Publication, presentation, and contribution as a thought leader in the relative fields.
Apply your passion and out-of-the-box thinking to collaborate with a team of researchers.

Job requirements

About the ideal candidate:

Hold a PhD degree in Computer Science or related fields with a focus on NLP, Large Language Model, or equivalent practical experience.
Papers at relevant conferences such as ACL, EMNLP, NACAL, NeurIPS, ICML, ICLR, AAAI, etc.
In-depth hands-on experience in Python, PyTorch, TensorFlow etc. and a track record of translating ideas into research prototypes quickly.
Working or collaboration experience at/with industry research labs or technology companies is an asset.
Experience in neural network architecture design and Large Language Model techniques, familiar with Transformer and its variants, linear Transformers, state space models, and AutoML techniques.",[]
Senior Researcher - NLP,Huawei Canada,,,"About the job
Huawei Canada has an immediate permanent opening for a Senior Researcher.

About the team:

Founded in 2012, the Noah’s Ark lab has evolved into a prominent research organization with notable achievements in academia and industry. The lab’s mission focuses on advancing artificial intelligence and related fields to benefit the company and society. Driven by impactful, long-term projects, the aim is to enhance state-of-the-art research while integrating innovations into the company's products and services, including LLMs, RL, NLP, computer vision, AI theory, and Autonomous driving.

About the job:

Participate in applied research projects in Huawei by proposing new solutions, developing the solutions, and doing experiments
Training and developing models and Building prototypes
Deliver projects, presenting results, publishing in top AI conferences
Tracking the new advances in the NLP/AI field and bringing insights to the team

Job requirements

About the ideal candidate:

PhD graduate in Computer Science, Software Engineering, or related subjects
Publications in top-tier ML/NLP conferences (NeurIPS, ICML, ICLR, ACL, EMNLP, NAACL, etc. …)
Deep understanding of fundamentals and state-of-the-art techniques in NLP
Good theoretical grounding in machine learning techniques
Great coding skills in Python
Experience in machine learning and deep learning libraries such as TensorFlow or PyTorch
Experience using modern LLM training frameworks, such as Hugging Face and Megatron. 
Being familiar with modern LLM architectures, including transformers and linear transformer-based models such as LLaMA, QWEN, Mamba, GLA, and others",[]
Senior Machine Learning Engineer,Loopio,"Toronto, ON",Remote,"About the job
We’re seeking an experienced Senior Machine Learning Engineer to build and scale ML-powered features that help customers improve proposal quality, boost win rates, and increase team productivity. In this role, you’ll drive enhancements to dashboard usability, deliver tailored recommendations, and optimize workflows through actionable analytics—showcasing Loopio’s ROI to executive stakeholders. You’ll work across our platform portfolio, applying NLP and GenAI to power intelligent solutions that support users as they build their content library, review and import documents, search for answers, and collaborate on proposals.

This is a unique opportunity to join a growing, creative, and mission-driven team solving real-world problems with modern AI practices. You’ll collaborate closely with Product Managers, Engineers, Architects, and Data Scientists to deliver ML solutions that elevate the value our users experience across the platform.

What You’ll Be Doing
End-to-End ML & NLP Deployment: Design, build, and optimize scalable ML systems for NLP applications, including fine-tuning large language models (LLMs), deploying transformer-based architectures, and optimizing inference for real-time and batch workloads. Architect distributed ML solutions for large-scale data processing and efficient retrieval-augmented generation (RAG).
MLOps & Cloud Infrastructure: Implement best practices for ML lifecycle management, including model versioning, monitoring, and automation. Build robust CI/CD pipelines, integrate with feature stores and vector databases, and deploy models on cloud platforms (preferably AWS).
Software Engineering & Microservices: Develop high-performance ML systems using Python, deep learning frameworks (TensorFlow, PyTorch), and distributed computing frameworks (Spark). Build scalable microservices and APIs for real-time model serving using containerized (Docker, Kubernetes) and serverless (AWS Lambda, Kinesis) architectures. Strong Object Oriented Programming fundamentals to build modular and reusable code.
Agent Workflow Intelligence: Design and deploy ML-powered systems to enhance agent workflows through intelligent task orchestration, context-aware assistance, and real-time response optimization. Leverage LLMs to build agent copilots that integrate with CRM and ticketing platforms, delivering in-the-moment suggestions, summarizations, and action recommendations. Instrument workflows to capture agent behavior signals and feedback loops, enabling continuous learning and adaptive automation that improves efficiency, accuracy, and customer satisfaction.
Cross-Functional Collaboration: Work closely with Data Scientists, Engineers, and Product teams to productionize NLP models, ensuring alignment with business needs and maintaining robust, scalable AI-driven solutions.

What You’ll Bring to the Team
ML & NLP Expertise: 4+ years of experience in ML engineering, with strong expertise in NLP, LLMs, transformers, and RAG. Proven ability to fine-tune, optimize, and deploy large-scale NLP models.
MLOps & Cloud Engineering: Hands-on experience with ML pipeline automation, monitoring, and deployment using cloud services. Strong background in data engineering for scalable AI systems, including structured (MySQL, PostgreSQL) and NoSQL (Redis, Cassandra) databases.
Scalable Systems & Distributed Computing: Experience with performance optimization techniques for ML inference, distributed computing (Spark, Presto, Databricks), and real-time/batch processing pipelines.
Software Development & Microservices: Strong Python development skills, experience with API-driven architectures (REST, gRPC), and ability to build robust, maintainable ML services.
Agent Workflow Optimization: Experience designing intelligent agent workflows and copilots powered by LLMs, including context-aware recommendations, task automation, and feedback-driven improvement loops. Proven ability to integrate ML solutions into agent-facing systems, enhancing efficiency and decision-making in real time.
Collaborative Problem Solving: Ability to work cross-functionally with product, engineering, and design teams effectively to translate business needs into AI solutions. Skilled at fostering alignment, sharing knowledge, and co-creating strategies that drive measurable impact.

Where You’ll Work 📍
Loopio is a remote-first workplace because we recognize the advantages of working flexibly. We are HQ’d in Canada, with established hub regions around the world where we hire from.
Our employees (or Loopers, as we call ourselves!) live and work in 🇨🇦 Canada (British Columbia and Ontario), 🇬🇧 London, and 🇮🇳 India (specifically in Gujarat, Maharashtra, and Bengaluru).
The majority of our team is based in ON and BC, which means these employees live and work remotely within a 300km radius of Toronto (within Ontario) and Vancouver (Within BC).
We offer flexible co-working locations available to Loopers in ON and BC. Those based in ON have the option of working out of our convenient co-working space located in the heart of Downtown Toronto and a 12-minute walk from Union Station. BC Loopers have the option to work centrally in Vancouver. It is whatever works best for you!
You’ll collaborate with your teams virtually across the UK, India, and North America (we’re just a Zoom call and Slack message away!) with core sync hours and focus time for headsdown work 🙇🏾 during the workday
We encourage asynchronous collaboration to effectively work as a global #OneTeam!

Why You’ll ♥️ Working at Loopio
Your manager supports your development by providing ongoing feedback and regular 1-on-1s, we leverage Lattice for our 1:1s and performance conversations
You will have the opportunity to elevate 🪄 your craft and the opportunity to explore your creativity, with a dedicated professional mastery allowance for more learning support! We encourage experimentation and innovative thinking to drive business impact.
We offer a wide range of health and wellness benefits to support your physical and mental well-being, starting day 1️⃣ with Loopio.
We’ll set you up to work remotely with a MacBook laptop 🍏, a monthly phone and internet subsidy, and a work-from-home budget to help get your home office all set up.
You’ll be joining a supportive culture that has thoughtfully built out opportunities for connections in a remote first environment.
Participate in 🎤 townhalls, AMA (Ask-Me-Anything), and quarterly celebrations to celebrate the big wins and milestones as #oneteam!
Our four active Employee Resource Groups offer opportunities for employees to learn and connect year-round.
You’ll be a part of an award-winning workplace 🏆with an opportunity to make a big impact on the business.",[]
Software Developer - Machine Learning,Coveo,"Montreal, QC",Hybrid,"About the job
Enable NLP Technology Reuse Across The Company

As a Software Developer in Machine Learning, you will play a key role in supporting teams of applied scientists and ML developers who train, evaluate, and use a variety of NLP models, including LLMs.

Your team is the CoreNLP team, a mix of scientists and developers who provide reusable NLP technologies that accelerate delivery for the other teams in your unit. Your mission is to contribute to prototyping, productionizing, and maintaining the NLP technologies that power some of Coveo's most visible AI capabilities.

Here Is What Makes This Opportunity Exciting

Your team is uniquely positioned to impact Coveo’s research and development efforts and offers one of the best environments to quickly get up to speed with state-of-the-art NLP technology.

The ML unit at Coveo focuses on finding ways to apply the latest advances in Recommender Systems, Ranking Optimization, LLMs and NLP to build innovative solutions in commerce, self-service and other business verticals. We solve real problems with real data, for hundreds of large enterprise clients all around the world, on a modern platform that serves over 100M requests and automatically trains thousands of ML models on a daily basis.

Here Is a Glimpse At Your Responsibilities

Participate directly in every aspect of NLP technology delivery: requirements gathering, conception, implementation, automated testing, release, monitoring, maintenance, etc.
Along with the rest of your team, make continuous learning a weekly practice that ensures awareness of emerging opportunities in the field.
Identify current pain points in NLP research and development and deliver software that addresses them.
Engage with your community of peers to challenge the status quo, improve our shared ways of working, and influence overall architecture decisions.
Learn, utilize and evolve our data and tech stack which includes Python, AWS, Snowflake, Honeycomb and others.

Here Is What Will Qualify You For The Role

3+ years of industry experience in Machine Learning, including maintaining internal tools and libraries relied on by other teams.
Strong fluency in data and software engineering best practices, with a proven ability to deliver reliable production code efficiently.
A collaborative mindset: you enjoy working closely with scientists to understand their challenges and improve their tools and workflows.
Experience with widely used NLP libraries such as Langchain, Haystack, and Transformers.

Here Is What Will Make You Stand Out

Familiarity with asynchronous programming.
Domain knowledge in areas like Natural Language Processing, Information Retrieval or Retrieval Augmented Generation, along with an understanding of the technical implications of building software for such use cases.
Excellent communication skills and the ability to clearly explain complex technical concepts to audiences with varying levels of technical proficiency.

Do you think you can bring this role to life?

You don’t need to check every single box; passion goes a long way and we appreciate that skillsets are transferable. Send us your CV, we want to get to know you! Join the #Coveolife!

We encourage all qualified applications regardless of, for example, age, gender, disability, gaps in CV, national or ethnic background. We know that applying for a new role is a lot of work and we really appreciate your time.",[]
Deep Learning Engineer,Numerator,,,"About the job
We’re reinventing the market research industry. Let’s reinvent it together.

At Numerator, we believe tomorrow’s success starts with today’s market intelligence. We empower the world’s leading brands and retailers with unmatched insights into consumer behavior and the influencers that drive it.

Numerator is looking for a passionate Deep Learning Software Engineer to join our growing Machine Learning team. This is a unique opportunity where you will get a chance to work with an established and rapidly evolving platform that handles millions of requests and massive amounts of events, and other data. In this position, you will be responsible for taking on new initiatives to design, build, deploy, and support high performance deep learning systems in a rapidly-scaling environment.

As a member of our team, you will make an immediate impact as you help build out and expand our technology platforms across several software products. This is a high growth and impact role that will give you tons of opportunity to drive decisions for projects from inception through production.

What You'll Do:

Develop and train deep learning models on computing clusters to perform NLP-related tasks, such as applying both pre-trained and custom transformers for NER, sequence classification, language modeling, etc. 
Build and maintain systems, APIs, and end-to-end data pipelines to deliver deep learning insights throughout all of Numerator’s products and platforms. 
Work closely with other deep learning engineers, MLOps engineers, product managers, and other teams, both internal and external stakeholders, owning a large part of the process from problem understanding to shipping the solution. 
Have the freedom to suggest and drive organization-wide initiatives while being part of providing the technical vision and strategy at Numerator. 

What You'll Bring to Numerator

2+ years experience building and deploying robust machine learning APIs in production environments (ideally cloud-based environments such as AWS or GCP). 
Background in the foundations of deep learning modeling with experience building high throughput, production quality deep learning pipelines for NLP, computer vision, information extraction/retrieval, or related practice 
Foundational understanding of Python, Pytorch, and Hugging Face transformers library 
Knowledge in the latest NLP-related algorithms and methods such as LLMs, transformers, sequence-to-sequence models, word and sentence embeddings, attention, information retrival etc 
Experienced software engineering, data modeling, and debugging/profiling fundamentals 
A Masters or PhD in Machine learning, Computer Science, Mathematics, Statistics, or another quantitative discipline or 3+ years equivalent industry experience 

Nice to Haves:

Production experience with LLMs including RAG, Agenic patterns, and information retrieval techniques. LLM Self-hosting and training experience not required. 
Demonstrated ability to drive selection of machine learning approaches to solve specific problems coupled with the ability to clearly communicate tradeoffs 
Experience with one or more model inference optimization libraries (TensorRT, ONNX, torch script, etc) 
General software design patterns (REST, MVC, Auto-scaling, etc.) 
Experience supporting machine learning solutions for multiple languages",[]
Artificial Intelligence Engineer,Tilda Research,Greater Vancouver Metropolitan Area,Remote,"About the job
We're seeking an AI Engineer to assist us in designing, developing, and deploying machine learning models and AI systems across our products. You’ll work closely with data scientists, backend engineers, and product managers to bring cutting-edge AI capabilities to life in production environments.

What You'll Do
Design, train, and optimize machine learning models for a range of NLP tasks, including classification, prediction, and generative applications, based on project requirements
Fine-tune pre-trained models, including large language models (LLMs), to adapt them to domain-specific or task-specific objectives
Evaluate and deploy ML models using appropriate metrics and tools, ensuring model performance, robustness, and scalability across use cases. Responsibilities include designing evaluation strategies, conducting error analysis, and iteratively refining models for production readiness
Work with large-scale datasets, perform feature engineering, and build robust data pipelines
Collaborate with cross-functional teams to identify opportunities for AI-driven improvements
Deploy models into production using MLOps best practices (e.g., CI/CD, versioning, monitoring)
Develop APIs or services to integrate AI capabilities into applications
Stay current on state-of-the-art techniques in AI/ML and recommend relevant tools or approaches
Contribute to architecture discussions and help shape the roadmap for AI solutions

What We're Looking For
PhD Required, Computer Science, Machine Learning, Statistics, or a related field.
2–5 years of hands-on experience in applied machine learning or AI engineering
Proficient in Python and common ML libraries (TensorFlow, PyTorch, scikit-learn, Hugging Face, etc.)
Experience with large language models (LLMs), NLP, computer vision, or recommendation systems is a strong plus
Familiarity with model deployment tools and MLOps platforms (e.g., MLflow, SageMaker, Vertex AI, or Docker/Kubernetes)
Solid understanding of data structures, algorithms, and model evaluation techniques

Bonus Points For
Experience with generative AI (e.g., LLM fine-tuning, embeddings, vector databases)
Familiarity with graph neural networks, reinforcement learning, or time-series forecasting
Exposure to cloud platforms like AWS, GCP, or Azure",[]
Ingénieur NLP,Inacre Conseil inc,"Montreal, QC",Hybrid,"About the job
Rejoignez une équipe passionnée où développeurs, data scientists, linguistes et juristes unissent leurs forces pour réinventer la recherche d'information dans le domaine juridique.

Au quotidien, vous serez amené à :
Améliorer et enrichir un moteur de recherche juridique à la pointe de la technologie.
Développer un système d'analyse des clics pour mieux comprendre les comportements utilisateurs.
Créer un assistant de recherche intelligent propulsé par des modèles de langage (LLM).
Optimiser l'infrastructure backend pour un traitement de données rapide, fiable et évolutif.
Travailler main dans la main avec des experts en NLP, en science des données et en droit pour tester, affiner et innover constamment.
Participer à des campagnes de performance (précision, rappel, temps de réponse...) et ajuster les systèmes en conséquence.
Expérimenter des approches de pointe : prompting avancé, apprentissage par renforcement, ou combinaisons symbolique/neurale.

Ce que nous recherchons :
Expérience concrète en machine learning et en traitement du langage naturel (NLP).
Maîtrise des modèles de langage modernes (LLM), que ce soit via API, fine-tuning ou prompting avancé.
Solide background en Python (et/ou Java), en particulier dans des projets liés à l'IA et à la donnée.
À l'aise avec les outils clés : Hugging Face, spaCy, scikit-learn, PyTorch
Bonne compréhension des techniques de recherche d'information : TF-IDF, BM25, dense retrieval, RAG, etc.
À l'aise avec Git, les pipelines CI/CD et les environnements conteneurisés.
Autonomie dans la mise en place d'expériences robustes : tests A/B, suivi des performances, reproductibilité.
Français obligatoire

Atouts:
Intérêt ou expérience dans le domaine juridique ou la recherche documentaire spécialisée.
Connaissance des systèmes à grande échelle ou des architectures microservices.
Appétence pour les interfaces conversationnelles et les assistants IA.

Conditions et avantages : 
35h / semaine (horaire flexible).
1 journée par semaine au bureau.
4 semaines de vacances + 5 jours de maladies et congés supplémentaires aux fêtes.
Assurances collectives complètes et PAE.
REER 6%
Bonification annuelle de 15% garantie
Formations payées.

Si vous êtes intéressé, faites-nous parvenir votre candidature via notre site internet à https://www.careers-page.com/inacre ou par courriel à noemie.barthelet@inacre.ca
Nous remercions toutes les personnes qui proposeront leur candidature. Cependant, seules les personnes sélectionnées seront contactées pour une entrevue. Le masculin est utilisé seulement pour alléger le texte. Inacre Conseil Inc. souscrit au principe d'équité pour tous, en matière de sélection et de recrutement de personnel. Pour plus d'information, vous pouvez aller visiter notre site internet www.inacre.ca ou nous contacter par téléphone à (514) 405-5360.",[]
Copy of Senior Scientist - Automatic Natural Language Processing (ANLP),CRIM,"Montreal, QC",Hybrid,"About the job
We are looking for a senior scientist, specialized in automatic natural language processing (NLP), who is motivated to join a group of scientists and developers experienced in this field. The candidate should have concrete experience of implementing NLP solutions, and an interest in working with real data on industrial issues such as information extraction, classification, named entity recognition and sentiment analysis. He/she should have advanced experience of the latest state-of-the-art in generative models and deep learning.

He/she will be actively involved in the development of proofs of concept, cutting-edge prototypes, experimental development projects and applied research. He/she will be called upon to collaborate with specialized experts in various scientific fields, including data science, computer vision and speech processing.

To succeed in this position, the successful candidate will need to combine passions for linguistics, computer science and machine learning. He/she must have a keen interest in communication and customer relations, to understand industrial challenges and share his/her cutting-edge expertise

Description Of Responsibilities

Participate simultaneously in the implementation and supervision of several NLP projects addressing industrial issues
Propose and lead NLP research projects on topics of scientific and business development interest
Participate in the evaluation of new projects (technical complexity, challenges, feasibility, etc.). 
Participate in drafting service offers
Contribute to CRIM's scientific and technical outreach by organizing activities or disseminating relevant advances to the community through various channels. 
Keep knowledge up to date, contribute to internal and external scientific seminars to share know-how. 
Ensure and document in-depth scientific monitoring of advances in NLP and generative models and share this knowledge within CRIM. 

Qualifications Required

Doctorate in computer science or master’s degree with research experience, specializing in language processing
Minimum five (5) years of experience in NLP and machine learning
Excellent writing skills in a variety of contexts (scientific journals, technical documentation, popularization, etc.)
Demonstrable experience in text classification, named entity recognition, information extraction and retrieval, use of generative models
expertise in language models: fine-tuning, adaptation, hallucination management, model safety and ethics. 
Proficiency in Python and a deep learning library (Pytorch, Tensorflow)
Excellent understanding of deep learning applied to NLP, in particular Transformers
Written and oral proficiency in English and French 

Abilities

Technical leadership and ability to evolve successfully within a team of scientists and with other stakeholders
Curiosity and initiative to explore scientific and technological advances in the field
Quick to learn and adapt. Autonomy and initiative. Ability to work on several projects at the same time
Ability to synthesize and make decisions on scientific and technical issues at the heart of customer mandates
Ability to communicate, listen and share knowledge
Interest in receiving and giving constructive feedback

Good reasons to work at CRIM

Benefit from excellent employment conditions (comprehensive group insurance program, RRSP, telecommuting, vacation)
Enjoy a stimulating environment at the cutting edge of developments in artificial intelligence
Access state-of-the-art computational resources
Maintain a balance and quality of life between work and family with a flexible schedule
Take part in a weekly research seminar and benefit from time dedicated to the realization of creative and exploratory projects. 
Meet passionate people in a collaborative environment

CRIM is an equal opportunity employer and is committed to diversity. We value the development of ideas as a team and cultivate a work environment that is open and respectful of differences. We encourage all candidates to apply for this position. Thank you for your interest in CRIM!

This position is available immediately.

Join the CRIM team and work with passionate, dynamic people!",[]
"Applied Scientist II, Alexa Devices, GENIE Science",Amazon,,,"About the job
Description

We are a part of Amazon Alexa Devices organization with the mission “delight customers through contextual and personalized proactive experiences that keep customers informed, engaged, and productive without cognitive burden”.

We are developing an advanced system using Large Language Model (LLM) technologies to deliver engaging, intuitive, and adaptive content recommendations across all Amazon surfaces. We aim to facilitate seamless reasoning and customer experiences, surpassing the capabilities of previous machine learning models. We are looking for a passionate, talented, and resourceful Applied Scientist in the field of Natural Language Processing (NLP), Recommender Systems and/or Information Retrieval, to invent and build scalable solutions for a state-of-the-art context-aware speech assistant. A successful candidate will have strong machine learning background and a desire to push the envelope in one or more of the above areas. The ideal candidate would also enjoy operating in dynamic environments, be self-motivated to take on challenging problems to deliver big customer impact, shipping solutions via rapid experimentation and then iterating on user feedback and interactions.

Key job responsibilities

As an Applied Scientist on the team, you will collaborate with other applied scientists and engineers to develop novel algorithms to enable timely, relevant and delightful recommendations and conversations. Your work will directly impact our customers in the form of products and services that make use of various machine learning, deep learning and language model technologies. You will leverage Amazon’s heterogeneous data sources and large-scale computing resources to accelerate advances in the state of art.

Basic Qualifications

 PhD, or Master's degree and 3+ years of building machine learning models for business application experience
 3+ years of building models for business application experience
 Experience programming in Java, C++, Python or related language

Preferred Qualifications

 PhD in Electrical Engineering, Computer Sciences, or Mathematics with specialties in natural language processing, recommendation system, information retrieval
 2+ years experience in building machine learning or deep learning models for large scale customer facing product or features.
 Publications at peer-reviewed NLP/ML conferences (e.g. ACL, EMNLP, NAACL, NeurIPS, ICLR, ICML, AAAI)
 Solid software development experience
 Good written and verbal communication skills

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - Amazon Development Centre Canada ULC - K03

Job ID: A2849828",[]
"Applied Scientist II, Alexa AI, GENIE Science",Amazon,,,"About the job
Description

We are a part of Amazon Alexa Devices organization with the mission “delight customers through contextual and personalized proactive experiences that keep customers informed, engaged, and productive without cognitive burden”.

We are developing an advanced system using Large Language Model (LLM) technologies to deliver engaging, intuitive, and adaptive content recommendations across all Amazon surfaces. We aim to facilitate seamless reasoning and customer experiences, surpassing the capabilities of previous machine learning models. We are looking for a passionate, talented, and resourceful Applied Scientist in the field of Natural Language Processing (NLP), Recommender Systems and/or Information Retrieval, to invent and build scalable solutions for a state-of-the-art context-aware speech assistant. A successful candidate will have strong machine learning background and a desire to push the envelope in one or more of the above areas. The ideal candidate would also enjoy operating in dynamic environments, be self-motivated to take on challenging problems to deliver big customer impact, shipping solutions via rapid experimentation and then iterating on user feedback and interactions.

Key job responsibilities

As an Applied Scientist on the team, you will collaborate with other applied scientists and engineers to develop novel algorithms to enable timely, relevant and delightful recommendations and conversations. Your work will directly impact our customers in the form of products and services that make use of various machine learning, deep learning and language model technologies. You will leverage Amazon’s heterogeneous data sources and large-scale computing resources to accelerate advances in the state of art.

Basic Qualifications

 PhD, or Master's degree and 3+ years of building machine learning models for business application experience
 3+ years of building models for business application experience
 Experience programming in Java, C++, Python or related language

Preferred Qualifications

 PhD in Electrical Engineering, Computer Sciences, or Mathematics with specialties in natural language processing, recommendation system, information retrieval
 2+ years experience in building machine learning or deep learning models for large scale customer facing product or features.
 Publications at peer-reviewed NLP/ML conferences (e.g. ACL, EMNLP, NAACL, NeurIPS, ICLR, ICML, AAAI)
 Solid software development experience
 Good written and verbal communication skills

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - Amazon Development Centre Canada ULC

Job ID: A2944360",[]
"Member of Technical Staff, MLE",Cohere,"Ottawa, ON",Hybrid,"About the job
Who are we?

Our mission is to scale intelligence to serve humanity. We’re training and deploying frontier models for developers and enterprises who are building AI systems to power magical experiences like content generation, semantic search, RAG, and agents. We believe that our work is instrumental to the widespread adoption of AI.

We obsess over what we build. Each one of us is responsible for contributing to increasing the capabilities of our models and the value they drive for our customers. We like to work hard and move fast to do what’s best for our customers.

Cohere is a team of researchers, engineers, designers, and more, who are passionate about their craft. Each person is one of the best in the world at what they do. We believe that a diverse range of perspectives is a requirement for building great products.

Join us on our mission and shape the future!

Why this role?

As a Member of Technical Staff on our Applied ML team, you will work directly with customers to quickly understand their greatest problems and design and implement solutions using Large Language Models.

You’ll apply your problem-solving ability, creativity, and technical skills to close the last-mile gap in Enterprise AI adoption. You’ll be able to deliver products like early startup CTOs/CEOs do and disrupt some of the most important industries and institutions globally!

In This Role, You Will

Own and build large new areas within our product.
Work across backend, frontend, and customize Large Language Models.
Experiment at a high velocity and level of quality to engage our customers and eventually deliver solutions that exceed their expectations.
Work across the entire product lifecycle from conceptualization through production.

This career opportunity may be a good match for you if you have:

3+ years of model training, deployment, and maintenance in a production environment.
Strong skills in NLP and deep learning.
Experience scaling products at hyper-growth startup.
Strong written and verbal communication skills.
Ability and interest to travel up to 25%, as needed to client sites, but flexible based on personal preferences.

Nice To Have Skills/experiences

Experience improving LLM performance for custom domains via fine tuning or RLHF.
Experience in Information Retrieval systems for document question answering.
Experience in day-to-day NLP for industry using Python and related toolchains (SpaCy, HuggingFace, NLTK, etc.).
Published research in areas of machine learning at major conferences and/or journals.

If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply! If you want to work really hard on a glorious mission with teammates that want the same thing, Cohere is the place for you.

We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants from all backgrounds and are committed to providing equal opportunities. Should you require any accommodations during the recruitment process, please submit an Accommodations Request Form, and we will work together to meet your needs.

Full-Time Employees At Cohere Enjoy These Perks

🤝 An open and inclusive culture and work environment

🧑‍💻 Work closely with a team on the cutting edge of AI research

🍽 Weekly lunch stipend, in-office lunches & snacks

🦷 Full health and dental benefits, including a separate budget to take care of your mental health

🐣 100% Parental Leave top-up for 6 months for employees based in Canada, the US, and the UK

🎨 Personal enrichment benefits towards arts and culture, fitness and well-being, quality time, and workspace improvement

🏙 Remote-flexible, offices in Toronto, New York, San Francisco and London and co-working stipend

✈️ 6 weeks of vacation

Note: This post is co-authored by both Cohere humans and Cohere technology.",[]
Senior Machine Learning Engineer - Poe (Remote),Quora,Canada,Remote,"About the job
[Quora is a privately held, ""remote-first"" company. This position can be performed remotely from multiple countries around the world. Please visit careers.quora.com/eligible-countries for details regarding employment eligibility by country.]

About Quora

Quora’s mission is to grow and share the world’s knowledge. To do so, we have two knowledge sharing products:


Quora: a global knowledge sharing platform with over 400M monthly unique visitors, bringing people together to share insights on various topics and providing a unique platform to learn and connect with others.
Poe: a platform providing millions of global users with one place to chat, explore and build with a wide variety of AI language models (bots), including o3, o4-mini, Claude 3.7 Sonnet, GPT Image 1 and more. As AI capabilities rapidly advance, Poe provides a single platform to instantly integrate and utilize these new models.


Behind these products are passionate, collaborative, and high-performing global teams. We have a culture rooted in transparency, idea-sharing, and experimentation that allows us to celebrate success and grow together through meaningful work. Join us on this journey to create a positive impact and make a significant change in the world.

This role will be working on our Poe product.

About The Team And Role

We are seeking a talented Senior ML Engineer to join us in building Poe, an exciting new platform at the forefront of AI. You will work at the cutting edge of technology to develop Poe’s bot ecosystem with state of art machine learning algorithms. This includes architecting a scalable recommender system architecture, building performant and reliable NLP applications and collaborating with our product team to build various personalized AI-driven user features.

Poe has experienced awesome growth so far, and as a Senior MLE for Poe, you can build the future of bot ecosystem while gaining invaluable experience with complex problems. Your contributions will have a direct influence on the Poe’s roadmap. If you have a passion for search and retrieval, emerging LLM modeling techniques and recommender system at scale, this role offers an invaluable opportunity to spearhead progress.

Responsibilities


Be responsible for developing, designing, and maintaining cutting-edge applied LLM projects including but not limited to search result retrieval, recommender systems, and multi-bot agents, ensuring smooth and engaging user experiences.
Participate in a wide variety of NLP activities, including refining and optimizing prompting, retrieval-augmented generation, etc, to improve the outcome of LLM.
Continuously research and stay up-to-date with the latest developments in NLP and large language models, utilizing innovative techniques and methodologies to enhance our models.
Take end to end ownership of large and scalable machine learning systems - from data pipelines, feature engineering, candidate extraction, model training, as well as integration into our production systems.


Minimum Requirements


Availability for meetings and impromptu communication during Quora's “coordination hours"" (Mon-Fri: 9am-3pm Pacific Time)
Demonstrated professional experience in software development and machine learning
Proven track record of tech leading NLP/Search models to solve industry-scale problems
4+ years of experience writing Python or C++ code
Experience of transformer models and LLM applications
BS, MS or PhD in Computer Science, Engineering or a related technical field


Preferred Requirements


5+ years of professional experience working on natural language processing, language modeling, etc.
Previous experience tech leading complicated end to end machine learning systems
Experience with leading large-scale multi-engineer projects
Flexible and positive team player with outstanding interpersonal skills
Passion for Poe's mission and goals


At Quora, we value diversity and inclusivity and welcome individuals from all backgrounds, including marginalized or underrepresented groups in tech, to apply for our job openings. We encourage all candidates who share a passion for growing the world’s knowledge, even those who may not strictly meet all the preferred requirements, to apply, as we know that a diverse range of perspectives can have a significant impact on our products and our culture.

Additional Information

We are accepting applications on an ongoing basis.

Quora offers a wide range of benefits including medical/dental/vision coverage, equity refreshers, remote work reimbursement, paid time off, employee assistance programs, and more. Benefits are country-specific and may vary. For more information on benefits, visit this link: https://www.careers.quora.com/benefits

There are many factors that will determine the starting pay, including but not limited to experience, location, education, and business needs.


US candidates only: For US based applicants, the salary range is $165,604 - $252,439 USD + equity + benefits.
Canada candidates only: For Toronto and Vancouver based applicants, the salary range is $215,317 - $262,575 CAD + equity + benefits. For all other locations in Canada, the salary range is $200,962 - $245,070 CAD + equity + benefits.


We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Job Applicant Privacy Notice: https://www.careers.quora.com/applicant-privacy-notice",[]
Scientifique senior – Traitement automatique du langage naturel (TALN),CRIM,"Montreal, QC",Hybrid,"About the job
Nous recherchons un(e) scientifique senior, spécialisé(e) en traitement automatique du langage naturel (TALN) motivé(e) à se joindre à un groupe de scientifiques et de développeurs expérimentés dans ce domaine. Le(la) candidat(e) doit avoir une expérience concrète d’implémentation de solutions en TALN et démontrer un intérêt à travailler sur des données réelles portant sur des problématiques industrielles comme l’extraction d’information, la classification, la reconnaissance d’entités nommées ou encore l’analyse de sentiments. Il(elle) devra avoir une expérience avancée des dernières avancées de l’état de l’art en matière de modèles génératifs et d’apprentissage profond.

Il(elle) participera activement à l’élaboration de preuves de concept, de prototypes d’avant- garde, à des projets de développement expérimental et de recherche appliquée. Il(elle) sera appelé(e) à collaborer avec des experts spécialisés dans différents domaines scientifiques dont la science des données, la vision par ordinateur ou encore le traitement de la parole.

Pour réussir à ce poste, le(la) candidat(e) retenu(e) devra combiner des passions pour la linguistique, l’informatique ainsi que pour l’apprentissage automatique. Il(elle) devra avoir un intérêt marqué pour la communication et les relations clients afin de comprendre des défis industriels et partager son expertise de pointe.

Description des principales fonctions

Participer simultanément à la réalisation et à l’encadrement de plusieurs projets en TALN portant sur des problématiques industrielles
Proposer et mener des projets de recherche en TALN sur des sujets d’intérêt scientifique et de développement des affaires
Participer à l’évaluation de nouveaux projets (complexité technique, enjeux, faisabilité, etc.)
Participer à la rédaction d’offres de service
Participer au rayonnement scientifique et technique du CRIM par l’organisation d’activités ou en disséminant les avancées pertinentes à la communauté par divers modes de diffusion
Maintenir ses connaissances à jour, contribuer aux séminaires scientifiques internes et externes pour partager son savoir-faire. 
Assurer et documenter des activités de veille scientifique approfondie sur les avancées en TALN, modèles génératifs et partager ces connaissances au sein du CRIM

Qualifications Recherchées

Doctorat en informatique ou Maîtrise avec expérience de recherche avec spécialisation en traitement du langage
Expérience minimale de cinq (5) années en TALN et apprentissage automatique
Excellentes capacités de rédaction dans différents contextes (revue scientifique, documentation technique, vulgarisation, etc.)
Expérience démontrable en matière de classification de textes, de reconnaissance d’entités nommées, d’extraction et de recherche de l’information, d’utilisation des modèles génératifs
Expertise en modèles de langue : fine-tuning, adaptation, gestion des hallucinations, sécurité et éthique des modèles. 
Maîtrise de Python et d’une librairie d’apprentissage profond (Pytorch, Tensorflow)
Excellente compréhension de l’apprentissage profond appliqué au TALN, en particulier des Transformers
Maîtrise du français et de l’anglais parlé et écrit

Qualités recherchées

Leadership technique et capacité à évoluer avec succès dans une équipe de scientifiques et auprès d’autres parties prenantes
Curiosité et prise d’initiative pour explorer les avancées scientifiques et technologiques du domaine
Rapidité d’apprentissage et d’adaptation. Autonomie et initiative. Facilité à travailler à plusieurs projets en parallèle
Esprit de synthèse et capacité décisionnelle face à des enjeux scientifiques et techniques au cœur des mandats clients
Habileté de communication, d’écoute et de partage de connaissances
Intérêt à recevoir et donner du feedback constructif

De bonnes raisons pour travailler au CRIM

Bénéficiez d’excellentes conditions d’emploi (programme d’assurance collective complet, REER, télétravail, vacances)
Profitez d’un environnement stimulant et à la fine pointe des développements en intelligence artificielle
Ayez accès à des ressources computationnelles de pointe
Maintenez un équilibre et une qualité de vie entre le travail et la famille avec un horaire flexible 
Participez à un séminaire de recherche hebdomadaire et profitez de temps dédié à la réalisation de projets créatifs et exploratoires
Côtoyez des gens passionnés et passionnants dans un milieu collaboratif

Le CRIM est un employeur équitable et la diversité lui tient à cœur. Nous valorisons le développement d’idées en équipe et cultivons un environnement de travail ouvert et respectueux des différences. Nous encourageons tous(tes) les candidat(e)s à postuler sur ce poste. Merci de votre intérêt envers le CRIM !

Ce poste est à combler dès maintenant. 

Joignez-vous à l’équipe du CRIM et travaillez avec des gens passionnés et dynamiques !",[]
Senior AI Solutions Engineer,Mission.dev,Canada,Remote,"About the job
Our company description
Mission is a platform for hiring, vetting and managing software development talents. It enables our clients to connect with the world’s best talent to build mission-critical software products.

About the client
A leading Canadian organization in the professional services sector, managing confidential multilingual content. They deliver tailored solutions through expert teams and global partners.
Services include adaptation, localization, multimedia, and compliance support.

About the role
We´re looking for a Senior AI / NLP Specialist to drive the deployment and fine-tuning of large language models (LLMs) and generative AI for content creation, transformation, and localization workflows. You’ll work across teams—from engineering to operations—to embed AI seamlessly into core systems.

Key Responsibilities
Design AI engines and LLM solutions tailored to diverse business use-cases.
Implement and fine-tune models (e.g., GPT-style, translation models) for optimal performance.
Advise on selecting appropriate AI technologies and architectures.
Integrate AI workflows into existing platforms (e.g. translation memory systems, CAT tools) via APIs.
Monitor model performance and ensure reliability and continual optimization.
Collaborate with engineering, operations, and content teams on infrastructure and deployment needs.
Streamline AI-enhanced workflows to boost automation and efficiency.
Define user stories and technical requirements to guide engineering implementation.

Requirements
Minimum 3 years of hands-on experience with LLMs, machine translation, or NLP.
Strong knowledge of ML pipelines: training, fine-tuning, data management.
Technical proficiency with AI frameworks like TensorFlow, PyTorch, Hugging Face, OpenAI API, or similar.
Proven ability to integrate AI systems via APIs and automation scripts.
Analytics-driven mindset: experience tracking model metrics and improving datasets.
Collaborative communicator, capable of working with both technical and non-technical stakeholders.
Excellent problem-solving skills, especially around AI scalability and optimization.

Preferred Qualifications
Experience with AI in translation/localization tools or content management systems.
Familiarity with MLOps/AIops and cloud-based AI infrastructure (e.g. Azure, AWS).
Experience in Agile/Scrum environments using tools like Jira & Confluence.
Deep awareness of AI ethics and bias mitigation strategies.

Type & Perks
Position type: Remote-first, full-time, permanent.
Compensation: Negotiable based on experience.
Must be located in Canada, with basic French proficiency (spoken & written).
Occasional travel to office expected.

#GenerativeAI #LargeLanguageModels #LLM #NLP #MachineTranslation #TensorFlow #PyTorch #HuggingFace #OpenAI #API #PromptEngineering #MLOps #AIops #ModelDeployment #APIIntegration #Agile #Bilingual #Canada",[]
"Senior Member of Technical Staff, MLE",Cohere,"Ottawa, ON",Hybrid,"About the job
Who are we?

Our mission is to scale intelligence to serve humanity. We’re training and deploying frontier models for developers and enterprises who are building AI systems to power magical experiences like content generation, semantic search, RAG, and agents. We believe that our work is instrumental to the widespread adoption of AI.

We obsess over what we build. Each one of us is responsible for contributing to increasing the capabilities of our models and the value they drive for our customers. We like to work hard and move fast to do what’s best for our customers.

Cohere is a team of researchers, engineers, designers, and more, who are passionate about their craft. Each person is one of the best in the world at what they do. We believe that a diverse range of perspectives is a requirement for building great products.

Join us on our mission and shape the future!

Why this role?

As a Senior Member of Technical Staff on our Applied ML team in NYC or SF, you will work directly with customers to quickly understand their greatest problems and design and implement solutions using Large Language Models.

You’ll apply your problem-solving ability, creativity, and technical skills to close the last-mile gap in Enterprise AI adoption. You’ll be able to deliver products like early startup CTOs/CEOs do and disrupt some of the most important industries and institutions globally!

As a Senior Member Of Technical Staff, You Will

Plan and execute large-group projects that carry through from ideation to production.
Bring cross-functional alignment across engineering, product and other disciplines. 
Mentor a distributed team of engineers in subject matter expertise. 
Identify opportunities and gaps in existing models and strategize what to work on.
Work closely with product teams to develop solutions.
Engage in collaborations with our partner organizations.
Assist our legal teams with preparation of patents on developed IP.
Join us at a pivotal moment, shape what we build and wear multiple hats!

You May Be a Good Fit If You Have

Prior experience in leading ML teams in applied research and production.
Prior experience in setting as well as executing technical direction to build new or to refine existing products.
Prior experience in working cross-discipline in matrixed organizations. 
Proficiency in Python and related ML frameworks such as Tensorflow, TF-Serving, JAX, and XLA/MLIR.
Experience using large-scale distributed training and inference.
Strong mentorship, communication, and problem-solving skills.
A demonstrated passion for applied ML models and products.
Bonus: experience working for B2B companies in the ML space. 
 This is neither an exhaustive nor necessary set of attributes. Even if none of these apply to you, but you believe you will contribute to Cohere, please reach out. We have a wide variety of backgrounds at Cohere.

If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply! If you want to work really hard on a glorious mission with teammates that want the same thing, Cohere is the place for you.

We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants from all backgrounds and are committed to providing equal opportunities. Should you require any accommodations during the recruitment process, please submit an Accommodations Request Form, and we will work together to meet your needs.

Full-Time Employees At Cohere Enjoy These Perks

🤝 An open and inclusive culture and work environment

🧑‍💻 Work closely with a team on the cutting edge of AI research

🍽 Weekly lunch stipend, in-office lunches & snacks

🦷 Full health and dental benefits, including a separate budget to take care of your mental health

🐣 100% Parental Leave top-up for 6 months for employees based in Canada, the US, and the UK

🎨 Personal enrichment benefits towards arts and culture, fitness and well-being, quality time, and workspace improvement

🏙 Remote-flexible, offices in Toronto, New York, San Francisco and London and co-working stipend

✈️ 6 weeks of vacation

Note: This post is co-authored by both Cohere humans and Cohere technology.",[]
AI Solutions Engineer,Thomson Reuters,"Toronto, ON",Hybrid,"About the job
AI Solutions Engineer, TR Labs

Are you excited about working at the forefront of applied research in an industry setting? Thomson Reuters Labs is seeking AI Solutions Engineers with a passion for solving problems using state-of-the-art information retrieval, natural language processing and generative AI.

What does Thomson Reuters Labs do? We experiment, we build, we deliver. We work closely with product and domain experts to identify compelling solutions at the intersection of user need and technical feasibility. Our team is designing the next generation of expert systems for legal, tax, and risk compliance. You’ll leverage state-of-the-art large language models on a robust AI platform to develop agents and tools that transform the future of work for legal and tax professionals.

About The Role:

As an AI Solutions Engineer, you will work with a cross functional team at the intersection of science, product, and engineering to:

Develop zero-to-one concepts for expert systems 
Systematically discover and test prompt engineering best practices 
Optimize data sets for prompt development, model training and evaluation 
Help create and maintain infrastructure required for efficient prompt development 
Test and assess open-source solutions for LLM application development including orchestration frameworks, tool interfaces, solutions for context management, etc. 
Develop automated techniques for the design and evaluation of AI agents 
Analyze usage data to gauge the effectiveness of AI solutions and iteratively improve 
Stay up to date with the latest research and emerging tech for AI Engineering 


About You:

The ideal candidate for the role of AI Solutions Engineer will have a background in NLP, experience building with LLMs, python proficiency for rapid prototyping, and the soft skills to bridge technical and business perspectives.

Required Qualifications:

Master’s degree in CS/ML/DS or a bachelor's with equivalent experience. 
0 to 3 years of transferrable experience in natural language processing (NLP) 
Basic familiarity with the architecture and operation of large language models
Strong desire to work closely with subject matter experts on real world use cases 
Active interest in emerging research and industry trends around AI software development 
Proficiency in python and AI development tools 
A mindset for good experiment design and evaluation; strong analytical and critical thinking 
Excellent communication and organization skills 


Preferred Qualifications:

Experience working on legal AI systems (e.g., for contract analysis, legal research, or drafting) 
Domain knowledge in legal, tax, or accounting. A law degree (J.D.), paralegal experience, etc. 
A portfolio of projects demonstrating creativity and skill building solutions with LLMs 
Experience developing NLP applications involving NER, information retrieval, text summarization, question answering, or similar. 
Knowledge of MLOps and the end-to-end lifecycle of software applications involving AI models 


What’s in it For You?

Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Industry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Culture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives. 
Making a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.


About Us

Thomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

As a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.

Learn more on how to protect yourself from fraudulent job postings here.

More information about Thomson Reuters can be found on thomsonreuters.com.",[]
Senior AI Solutions Engineer,Thomson Reuters,"Toronto, ON",Hybrid,"About the job
Senior AI Solutions Engineer, TR Labs

Are you excited about working at the forefront of applied research in an industry setting? Thomson Reuters Labs is seeking Senior AI Solutions Engineers with a passion for solving problems using state-of-the-art information retrieval, natural language processing and generative AI.

What does Thomson Reuters Labs do? We experiment, we build, we deliver. We work closely with product and domain experts to identify compelling solutions at the intersection of user need and technical feasibility. Our team is designing the next generation of expert systems for legal, tax, and risk compliance. You’ll leverage state-of-the-art large language models on a robust AI platform to develop agents and tools that transform the future of work for legal and tax professionals.

About The Role:

As an Senior AI Solutions Engineer, you will work with a cross functional team at the intersection of science, product, and engineering to:

Develop zero-to-one concepts for expert systems 
Systematically discover and test prompt engineering best practices 
Optimize data sets for prompt development, model training and evaluation 
Help create and maintain infrastructure required for efficient prompt development 
Test and assess open-source solutions for LLM application development including orchestration frameworks, tool interfaces, solutions for context management, etc. 
Develop automated techniques for the design and evaluation of AI agents 
Analyze usage data to gauge the effectiveness of AI solutions and iteratively improve 
Stay up to date with the latest research and emerging tech for AI Engineering 


About You:

The ideal candidate for the role of Senior AI Solutions Engineer will have a background in NLP, experience building with LLMs, python proficiency for rapid prototyping, and the soft skills to bridge technical and business perspectives.

Required Qualifications:

Master’s degree in CS/ML/DS or a bachelor's with equivalent experience. 
4 to 6 years of transferrable experience in natural language processing (NLP) 
Basic familiarity with the architecture and operation of large language models
Strong desire to work closely with subject matter experts on real world use cases 
Active interest in emerging research and industry trends around AI software development 
Proficiency in python and AI development tools 
A mindset for good experiment design and evaluation; strong analytical and critical thinking 
Excellent communication and organization skills 


Preferred Qualifications:

Experience working on legal AI systems (e.g., for contract analysis, legal research, or drafting) 
Domain knowledge in legal, tax, or accounting. A law degree (J.D.), paralegal experience, etc. 
A portfolio of projects demonstrating creativity and skill building solutions with LLMs 
Experience developing NLP applications involving NER, information retrieval, text summarization, question answering, or similar. 
Knowledge of MLOps and the end-to-end lifecycle of software applications involving AI models 


What’s in it For You?

Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Industry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Culture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives. 
Making a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.


About Us

Thomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

As a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.

Learn more on how to protect yourself from fraudulent job postings here.

More information about Thomson Reuters can be found on thomsonreuters.com.",[]
Senior Machine Learning Engineer,GENIE AI,,,"About the job
This job is sourced from a job board. Learn More
About Company

GENIE is an applied AI lab developing Assistive Intelligence (AI) solutions for businesses, governments, and non-profits. Our focus is on translating the massive potential of GenAI, RPA, and AR/VR technologies into a measurable competitive advantage. We firmly believe in the future of interactive technology and view cognition as its most capable instrument. With a track record of firsts, we've partnered with category-leading businesses to pilot ALBIS Experience Studio™. 

About Team

 GENIE comprises a winning team of Subject Matter Experts with over 20 years of specialization in ML/AI, offering world-class strategy, engineering, and design. Our team includes 42+ executives, business experts, ML engineers, RPA engineers, security engineers, data engineers, product designers, researchers, testers, content creators, and sales professionals.

 About the Product

 ALBIS™ Enterprise-grade no code AI Automation studio designed to enable anyone to create and manage experiences across physical, digital, and virtual spaces. ALBIS takes experience management to a whole new standard by leveraging Gen AI, Robotic Automation, IoT, AR/VR, and other advanced tech to enable actions like real-time data checks, outcome prediction, task automation, and autopilot activation.

What’s in it for you?

Opportunity to lead at the forefront of an AI SaaS platform; Rapid growth driven by cutting-edge technologies; Disruptive impact on global industries; Collaboration with diverse teams worldwide; Hands-on experience in a dynamic, fast-paced environment; Mentorship from seasoned professionals; Engagement in impactful projects; Networking opportunities within the industry

Role: Senior Machine Learning Engineer Lead

Location: Remote

Role Summary

We are seeking a seasoned Senior Machine Learning Engineer Lead with expertise in NLP, prompt training with end-to-end product deployment experience. As a key member of our team, you will spearhead the design, development, and deployment of our solutions. The ideal candidate possesses deep expertise in Python programming, proficiency in NLP libraries such as NLTK, spaCy, or Transformers, and a proven track record of delivering successful chatbot projects.

Responsibilities

Lead the design, development, and implementation of cutting-edge solutions to streamline conversations and enhance user interactions
Conduct comprehensive analysis of business processes to identify automation opportunities and drive efficiency
Architect and maintain chatbot workflows utilizing Python, NLP libraries, and web-based integration scripts
Collaborate closely with stakeholders to gather requirements and offer technical guidance on chatbot initiatives
Ensure the quality, performance, and security compliance of chatbot solutions
Provide expert technical support and troubleshoot issues related to chatbot deployments
Stay abreast of emerging chatbot technologies and industry trends to drive innovation and continuous improvement
Develop and maintain comprehensive project documentation, including design specifications, test plans, and user manuals
Lead team of ML engineers and interns in deploying solutions

Qualifications

Bachelor's degree in Computer Science, Information Technology, or a related field
Minimum of 3 years of experience in chatbot development and implementation
Proficiency in Python programming language
Strong expertise in NLP libraries such as NLTK, spaCy, or Transformers
Excellent analytical and problem-solving skills
Exceptional communication and interpersonal abilities
Proven ability to work both independently and collaboratively in a team environment
Strong attention to detail and ability to manage multiple tasks effectively
Experience in project management and delivery methodologies is advantageous

If you are passionate about leveraging automation and NLP to enhance user experiences through innovative solutions, we invite you to apply for this role.

GENIE AI is committed to fostering an inclusive workplace and encourages applications from all qualified individuals regardless of race, religion, national origin, gender, sexual orientation, age, marital status, veteran status, disability, or other characteristics protected by law.

Please submit your application in English.",[]
AI Systems Engineer,Benevity,,,"About the job
Meet Benevity 

Benevity is the way the world does good, providing companies (and their employees) with technology to take social action on the issues they care about. Through giving, volunteering, grantmaking, employee resource groups and micro-actions, we help most of the Fortune 100 brands build better cultures and use their power for good. We’re also one of the first B Corporations in Canada, meaning we’re as committed to purpose as we are to profits. We have people working all over the world, including Canada, Spain, Switzerland, the United Kingdom, the United States and more!

We’re looking for an AI Systems Engineer to help build and optimize real-world applications powered by large language models and intelligent automation. In this role, you’ll contribute to the design and deployment of AI features that integrate retrieval systems, agents, and foundation models into production-grade systems. You’ll work cross-functionally with data scientists, product managers, and platform engineers to deploy, optimize, and maintain reliable and scalable ML/AI services in a production environment—ensuring they perform well and deliver value to all our clients.

 What You’ll Do 

 AI System Development & Implementation 

Develop and maintain AI-powered workflows using LLMs, embeddings, and automation tools
Contribute to building RAG (retrieval-augmented generation) systems integrated with platform features
Build and improve natural language interfaces such as semantic search and text-to-SQL queries
Assist with prompt engineering, evaluation, and fine-tuning of LLMs for production use

 Collaborate in the design of scalable, modular AI components that can be reused across products 

 Platform Engineering & Integration 

Deploy AI services in cloud-native environments (AWS, GCP, or Azure) using containerized pipelines
Build and monitor embedding and vector database workflows (e.g., FAISS, Pinecone, Weaviate)
Maintain CI/CD workflows and support versioning, testing, and safe deployment of AI systems
Contribute to LLMOps efforts around logging, observability, and responsible AI practices

 Work with data teams to ensure clean, structured inputs for model training and inference 

 Collaboration & Technical Growth 

Work cross-functionally with product, design, and data science to bring AI features to life
Participate in architectural discussions and advocate for scalable, maintainable solutions
Stay up to date with advancements in the LLM and MLOps ecosystem and explore new tools and frameworks
Contribute to documentation and internal tooling that improve team efficiency and transparency

 What You’ll Bring 

A Bachelor's degree in Computer Science, Engineering, or related field (or equivalent experience)
3+ years of software engineering experience, with at least 1–2 years working with ML/AI systems
Solid Python development skills, including building APIs or backend services with FastAPI or Flask
Experience integrating with LLMs (e.g., OpenAI, Cohere) and using embedding models
Familiarity with retrieval systems and vector databases (Pinecone, FAISS, Qdrant, etc.)
Hands-on experience with cloud platforms and containerized deployment (e.g., Docker, Kubernetes)
Understanding of prompt engineering, semantic search, and NLP tasks like text classification or Q&A
Interest in responsible AI practices and building traceable, explainable ML pipelines
Exposure to tools such as LangChain, MLflow, LangSmith, or Weights & Biases is a plus

 Technical Skills & Expertise 

Programming: Proficient in Python; experience with backend development and REST APIs
AI Tools: Familiar with Hugging Face, OpenAI APIs, LangChain, and RAG pipelines
Infrastructure: Comfortable with cloud deployment (AWS preferred), Docker, Kubernetes
Vector Search: Experience with embeddings and vector databases like FAISS or Pinecone
MLOps/LLMOps: Exposure to tools like MLflow, BentoML, or LangSmith
Data Systems: Familiar with SQL and NoSQL databases, data pipelines, and structured data integration
Monitoring: Experience with observability tools like Datadog, Prometheus, or OpenTelemetry
Development Practices: Git, CI/CD, agile teamwork, and documentation habits

 Discover your purpose at work 

We’re not employees, we’re Benevity-ites. From all locations, backgrounds and walks of life, who deserve more …

Innovative work. Growth opportunities. Caring co-workers. And a chance to do work that fills us with a sense of purpose.

If the idea of working on tech that helps people do good in the world lights you up ... If you want a career where you’re valued for who you are and challenged to see who you can become …

It’s time to join Benevity. We’re so excited to meet you.

 Where we work 

At Benevity, we embrace a flexible hybrid approach to where we work that empowers our people in a way that supports great work, strong relationships, and personal well-being. For those located near one of our offices, while there’s no set requirement for in-office time, we do value the moments when coming together in person helps us build connection and collaboration. Whether it’s for onboarding, project work, or a chance to align and bond as a team, we trust our people to make thoughtful decisions about when showing up in person matters most.

 Join a Company Where DEIB Isn’t a Buzzword 

Diversity, equity, inclusion and belonging are part of Benevity’s DNA. You’ll see the impact of our massive investment in DEIB daily — from our well-supported employee resources groups to the exceptional diversity on our leadership and tech teams.

We know that diverse backgrounds, experiences, skills and passions are what move our business and our people forward, so we're committed to creating a culture of belonging with equal opportunities for everyone to shine.

That starts with a fair and accessible hiring process. If you want to feel seen, heard and celebrated, you belong at Benevity.

Candidates with disabilities who may require accommodations throughout the hiring or assessment process are encouraged to reach out to accommodations@benevity.com.",[]
"AI Specialist NLP, GenAI & Large Language Models",TRSB Inc.,Canada,Remote,"About the job
Want to join a Canadian leader? Love to work with experienced professionals? Eager to make a valued contribution to a team of some 250 colleagues? Sounds like you’re ready for a job at TRSB, Canada’s number one translation provider.

TRSB is seeking an AI Specialist – Content Management/Localization, NLP & Large Language Models (LLMs) to lead the deployment and training of LLMs tailored to specific use cases in content creation, transformation, and localization workflows. This role ensures that AI technologies are strategically selected, effectively integrated into existing systems, and consistently monitored for reliability and performance improvements. The AI Specialist will work closely with DevOps, engineering, and operations teams to design, implement, and optimize AI-powered solutions for content creation, transformation, and localization.

Your Daily Routine

AI Engine Design: Design the AI solution that solves given business challenges or use cases.
AI Deployment & Training: Select, fine-tune, and deploy LLMs for specific localization use cases, ensuring optimal performance and efficiency.
Technology Selection: Assess and recommend AI technologies that best address given use cases and business requirements.
Solution Integration: Collaborate with DevOPS team to ensure seamless integration of AI-powered workflows into existing systems (e.g., TMS), tools (e.g., CAT), and workflows.
Reliability & Performance Monitoring: Develop methodologies to track AI system reliability and continuously enhance model performance.
Collaboration with DevOps: Define infrastructure requirements, including hardware and software needs, to support AI solutions.
Workflow Optimization: Work with stakeholders to refine and improve AI-driven workflows, maximizing automation and efficiency.
User Story & Requirement Definition: Document technical requirements and user stories to guide engineering teams in solution development.

You Will Need

AI & NLP Expertise: 3+ years of experience in NLP working with LLMs, machine translation, and AI-driven solutions.
Machine Learning: Strong understanding of machine learning operations to establish and manage machine learning pipelines for each use case.
Technical Background: Strong understanding of AI model training, fine-tuning, and deployment methodologies.
AI Model Evaluation: Experience in setting up and evaluating AI models to ensure continued performance up to the standards.
Integration Experience: Hands-on experience in integrating AI solutions with existing platforms via APIs and automation scripts.
Data & Performance Analysis: Ability to analyse model performance, optimize datasets, and implement continuous improvements.
Collaboration & Communication: Strong ability to work cross-functionally with technical and non-technical teams to define and execute AI strategies.
Problem-Solving Skills: Proficiency in troubleshooting AI-related challenges and optimizing performance for scalability.

This position may be ideal for you if you have:

Experience with AI frameworks: TensorFlow, PyTorch, Hugging Face, Azure, OpenAI API, or similar AI toolkits.
Exposure to MLOps/DevOps practices for AI deployment (e.g., MLOps, cloud-based AI infrastructures).
Knowledge of Agile/Scrum methodologies like Jira or Confluence.
Understanding of AI ethics: Grasp of bias mitigation strategies.
Localization and/or Content Management Industry Knowledge
Familiarity with Tools and Systems: Python, Translation Management Systems (TMS), Computer-Assisted Translation (CAT) tools, content management, and localization workflows.

Why join us?

Work at the intersection of AI and content management systems, shaping the future of content management services.
Collaborate with a dynamic and innovative team driving cutting-edge AI solutions.
Opportunity to influence and build AI-powered workflows for global enterprise clients.

We value our teams and offer working conditions to match:

Competitive salary
Comprehensive group insurance
Group RRSP
Flexible work arrangements
Fitness benefit
Payment of dues to your professional order
Referral program
Public transit credit
Paid vacation on your birthday",[]
AI/ML Engineer (Toronto),US Mobile,"Toronto, ON",Remote,"About the job
US Mobile is on a mission to revolutionize connectivity. Imagine a world where you can go into a single app and buy terabytes of data for every one of your devices: phone, smart devices, car, home broadband, and more. That’s the future that US Mobile is building: a software platform built truly for the 21st century and the age of 5G and IoT, with world class engineering, best-in-class user experience, and features that will define the next generation of connectivity.

At the core of it all, we have a team and culture that has been recognized by Forbes as one of the top 500 best startup employers in the US. Our team spans diverse backgrounds, cultures, and stories, with employees coming from 20+ countries.

We're a venture-backed company entering hypergrowth, having recently ranked 94th on Inc 5000's fastest-growing private companies in America, and we’re looking for someone exceptional to join our team.

Job Description:

We’re looking for an AI/ML Engineer who will develop, optimize, and scale machine learning models that power our next generation of user experiences. Working closely with product, engineering, and design, you’ll ensure our ML tools truly address user needs—whether they’re discovering new features, troubleshooting connectivity, or receiving proactive solutions to common issues.

Key Responsibilities:

Design & Deploy Conversational / Multi-Agent LLM Solutions
Craft multi-agent conversational flows capable of handling a wide range of user requests—both purely informational and action-oriented
Employ advanced LLM techniques (prompt engineering, context retrieval, multi-step reasoning) to ensure robust, context-aware dialogues
Multi-Modal & Multi-Model Integration
Explore different input/output formats (e.g., text, potential voice or image-based flows) to enrich user interactions
Evaluate different models based on their intended use case, considering both technical capabilities and cost efficiency
Platform & Pipeline Building
Work with cross-functional teams to design data pipelines that feed your models real-time or near real-time data
Implement best practices around model lifecycle management—versioning, containerization, deployment orchestration, etc
Optimization & Scale
Ensure the chat system can handle thousands (eventually millions) of concurrent interactions, maintaining low latency and high availability
Monitor performance, define metrics (latency, user success rate, fallback rate, etc.), and iteratively improve
Ongoing Innovation & Experimentation
Remain current on the rapidly evolving AI/ML landscape, especially in generative models, multi-agent orchestration, and knowledge retrieval
Propose new ways to extend AI across our platform—e.g., advanced personalization, proactive customer engagements, etc


Qualifications:

Core AI/ML Expertise
3+ years hands-on experience building and deploying machine learning solutions at scale
Solid understanding of NLP techniques, including transformer models and embeddings, with hands-on experience using modern tools like Hugging Face, AWS Bedrock, and OpenAI’s API
Backend & Data Infrastructure
Proficient in Python or a similar language for data pipelines and model development
Experience with cloud platforms (AWS strongly preferred), containerization (Docker, Kubernetes), and microservices
Research & Problem-Solving Mindset
Up-to-date on AI/ML trends—especially in multi-agent systems, generative modeling, or multi-modal approaches
Skilled at diagnosing bottlenecks, scaling solutions, and balancing innovation against real-world constraints
Collaboration & Communication
Comfortable presenting complex ML concepts to non-technical stakeholders
Passion for iterative development—able to pivot based on user feedback and product metrics


Bonus Points:

Familiarity with vector search solutions (e.g. Pinecone, Weaviate, or Elasticsearch with vector plugins)
Familiarity with building or deploying large language models and related tooling in the AWS Bedrock ecosystem
Experience designing or contributing to multi-agent LLM frameworks or orchestrations (e.g., specialized agent-based approaches in advanced NLP)


Benefits:

Competitive salary 150k CAD - 240k CAD (based on experience)
Flexible working hours
Supplemental health insurance
Professional development stipend
$500 wfh tech set-up reimbursement


Think you’d be a great fit? Apply to learn more!",[]
Machine Learning Engineer – Senior,Damco Solutions,"Toronto, ON",Hybrid,"About the job
Must Haves:
Deep Understanding of Machine Learning Concepts: Proficiency in fundamental machine learning concepts, algorithms, and techniques.
Expertise in Natural Language Processing (NLP): Knowledge of NLP techniques and models, especially BERT and other transformer-based models, for tasks like text classification, sentiment analysis, and language understanding.
Experience with Deep Learning Frameworks: Proficiency in deep learning libraries such as TensorFlow or PyTorch. Experience with implementing, training, and fine-tuning BERT models using these frameworks is crucial.
Data Preprocessing Skills: Ability to perform text preprocessing, tokenization, and understanding of word embeddings.
Programming Skills: Strong programming skills in Python, including experience with libraries like NumPy, Pandas, and Scikit-learn.
Model Optimization and Tuning: Skills in optimizing model performance through hyperparameter tuning and understanding of trade-offs between model complexity and performance.
Understanding of Transfer Learning: Knowledge of how to leverage pre-trained models like BERT for specific tasks and adapt them to custom datasets.
 Experience and Skill Set Requirements
(15%) Deep Understanding of Machine Learning Concepts: Proficiency in fundamental machine learning concepts, algorithms, and techniques.
Expertise in Natural Language Processing (NLP): Knowledge of NLP techniques and models, especially BERT and other transformer-based models, for tasks like text classification, sentiment analysis, and language understanding.
(20%) Experience with Deep Learning Frameworks: Proficiency in deep learning libraries such as TensorFlow or PyTorch. Experience with implementing, training, and fine-tuning BERT models using these frameworks is crucial.
(30%)Data Preprocessing Skills: Ability to perform text preprocessing, tokenization, and understanding of word embeddings.
Programming Skills: Strong programming skills in Python, including experience with libraries like NumPy, Pandas, and Scikit-learn.
(20%) Model Optimization and Tuning: Skills in optimizing model performance through hyperparameter tuning and understanding of trade-offs between model complexity and performance.
(15%) Understanding of Transfer Learning: Knowledge of how to leverage pre-trained models like BERT for specific tasks and adapt them to custom datasets.",[]
"Sr Staff Machine Learning Engineer, GenAI",Mozilla,"Toronto, ON",Remote,"About the job
Why Mozilla?

Mozilla Corporation is the non-profit-backed technology company that has shaped the internet for the better over the last 25 years. We make pioneering brands like Firefox, the privacy-minded web browser. Now, with more than 225 million people around the world using our products each month, we’re shaping the next 25 years of technology and helping to reclaim an internet built for people, not companies. Our work focuses on diverse areas including AI, social media, security and more. And we’re doing this while never losing our focus on our core mission – to make the internet better for people.

The Mozilla Corporation is wholly owned by the non-profit 501(c) Mozilla Foundation. This means we aren’t beholden to any shareholders — only to our mission. Along with thousands of volunteer contributors and collaborators all over the world, Mozillians design, build and distribute open-source software that enables people to enjoy the internet on their terms.

About This Team And Role

The Firefox team is a community of engineers who care deeply about delivering the fastest, friendliest, most usable browser possible. We are responsible for making the things you see in the browser work securely, quickly, and well! We are looking for a Senior Staff Machine Learning Engineer to help us develop and grow new machine learning driven products and tools. You will play a key role in enabling safe and healthy machine learning and AI driven experiences in Firefox.

Senior Staff Engineers are industry experts in their domain. They help define our product strategy and goals affecting multiple teams and turn our strategy into coordinated action for those teams. They mentor others through transfer of responsibilities to more junior engineers, so they can tackle new ones, while collaborating with management on building team consensus and providing direction.

What You’ll Do

Take on large open-ended problems and drive them to completion, collaborating with other designers and engineers to make the web a better place.
Identify strategic opportunities where Large Language models improve the experience in Firefox.
Lead the design, development, and integration of innovative AI and machine learning models in Firefox, collaborating cross functionally with product management, full stack engineering and design.
Stay up-to-date with the latest advancements in AI, and inform feature development, and ensure our methodologies remain innovative and relevant.
Lead by example to upskill the team on AI and generate thought leadership.

What You'll Bring

8+ years experience as an engineer in machine learning with experience building and shipping machine learning models in production environments for user-facing applications.
Experience with shipping LLMs and multimodal models in user-centric products.
Deep understanding of fundamental machine learning concepts, including deep learning, natural language processing, large language models, and reinforcement learning, with proven expertise in one or more of these areas.
Identify difficult problems that are important for the organization, collaborate across teams and the organization to find the best strategy to resolve.
Consistent track record of technical leadership across multiple teams, shipping AI products showing a high degree of collaboration, flexibility, and respect for different perspectives
Experience with tooling in the AI ecosystem, that are open source and services in the cloud(such as GCP, AWS, Azure)
Experience with design of experiments, survey design, and large-scale AB testing
Experience with responsible AI, transparent algorithms, and putting users’ needs first.
You’re pragmatic about how to move things forward in specific timeframes including trade-offs and safeguards when implementing new functionality.
Lead and thrive effectively on a distributed team.

Bonus Points

Experience with working on on-device machine learning models.
You have previously successfully contributed to an open source project.
Experience with the browser architecture or ecosystem.

We value a variety of voices within our team and at Mozilla. You don't need to check every box on this list to apply.

What You’ll Get

Generous performance-based bonus plans to all eligible employees - we share in our success as one team
Rich medical, dental, and vision coverage
Generous retirement contributions with 100% immediate vesting (regardless of whether you contribute)
Quarterly all-company wellness days where everyone takes a pause together
Country specific holidays plus a day off for your birthday
One-time home office stipend
Annual professional development budget
Quarterly well-being stipend
Considerable paid parental leave
Employee referral bonus program
Other benefits (life/AD&D, disability, EAP, etc. varies by country)

About Mozilla

Mozilla exists to build the Internet as a public resource accessible to all because we believe that open and free is better than closed and controlled. When you work at Mozilla, you give yourself a chance to make a difference in the lives of Web users everywhere. And you give us a chance to make a difference in your life every single day. Join us to work on the Web as the platform and help create more opportunity and innovation for everyone online.

Commitment to diversity, equity, inclusion, and belonging

Mozilla understands that valuing diverse creative practices and forms of knowledge are crucial to and enrich the company’s core mission. We encourage applications from everyone, including members of all equity-seeking communities, such as (but certainly not limited to) women, racialized and Indigenous persons, persons with disabilities, persons of all sexual orientations, gender identities, and expressions.

We will ensure that qualified individuals with disabilities are provided reasonable accommodations to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment, as appropriate. Please contact us at hiringaccommodation@mozilla.com to request accommodation.

We are an equal opportunity employer. We do not discriminate on the basis of race (including hairstyle and texture), religion (including religious grooming and dress practices), gender, gender identity, gender expression, color, national origin, pregnancy, ancestry, domestic partner status, disability, sexual orientation, age, genetic predisposition, medical condition, marital status, citizenship status, military or veteran status, or any other basis covered by applicable laws. Mozilla will not tolerate discrimination or harassment based on any of these characteristics or any other unlawful behavior, conduct, or purpose.

Group: C

ReqID: R2843

Hiring Ranges

Canada Tier 1 Locations

$191,000—$255,000 CAD

Canada Tier 2 Locations

$173,000—$230,000 CAD",[]
AI Engineer - Language (Canada),Motorola Solutions,"Vancouver, BC",Hybrid,"About the job
Company Overview

At Motorola Solutions, we believe that everything starts with our people. We’re a global close-knit community, united by the relentless pursuit to help keep people safer everywhere. Our critical communications, video security and command center technologies support public safety agencies and enterprises alike, enabling the coordination that’s critical for safer communities, safer schools, safer hospitals and safer businesses. Connect with a career that matters, and help us build a safer future.

Aperçu de l’entreprise

Chez Motorola Solutions, nous pensons que tout commence par nos employés. Nous sommes une communauté mondiale soudée, unie par la volonté incessante de contribuer à la sécurité des personnes partout dans le monde. Nos technologies de communication, de sécurité vidéo et de centre de commandement essentielles soutiennent les agences de sécurité publique et les entreprises, permettant une coordination essentielle pour des communautés, des écoles, des hôpitaux et des entreprises plus sécuritaires. Connectez-vous à une carrière qui compte et aidez-nous à bâtir un avenir plus sûr.

Department Overview

The Language & Audio group within the Chief Technology Office brings together Motorola Solutions’ end-to-end suite of public safety offerings, leveraging cutting edge voice technology, language and video models, and natural language understanding to enable our customers to focus on what matters while providing faster responses, safer outcomes and greater transparency.

Job Description

You will join the Language & Audio group where you will be building machine learning solutions for our public safety and commercial security customers. Your work will impact all aspects of the machine learning cycle, from data curation to model training to deployment to monitoring and feedback.

Application areas include speech-to-text interfaces, video captioning, natural language processing, summarization, and search over public-safety data. You will work with infrastructure engineers and research scientists to build machine learning products that are informative and responsive, leveraging your collaboration skills as you work with a team to develop reusable components, enabling cooperation between research units and production engineers.

Required Skills

3+ years of combined experience as a software developer and/or a post-graduate degree in a quantitative science or engineering
Previous experience using Python in a software development project
Previous experience contributing to a Machine Learning project
Strong written and oral communication skills in English

Desired Skills

Experience with cloud-based infrastructure: Azure, AWS and/or GCP
Experience with Linux, DevOps, containerized infrastructure (Docker, Kubernetes)
Experience using version control to collaborate with team members
Experience with using CI/CD pipelines to build, test and deploy Python services
Knowledgeable of Machine Learning fundamentals and best practices

As a part of the application process, we encourage you to include a link to code you’ve written.

We believe that diversity spawns innovation – the more diverse our employees are, the more ideas and talents we have to excel as a leader in the technology sector. If you would like to be part of a dynamic team of people who are committed, focused, and hardworking then we look forward to meeting you!

Target Base Salary Range: $85,000 CAD - $118,000 CAD

Consistent with Motorola Solutions values and applicable law, we provide the following information to promote pay transparency and equity. Pay within this range varies and depends on job-related knowledge, skills, and experience. The actual offer will be based on the individual candidate.

Note: Candidate must live near a Motorola Solutions Canada office.

Basic Requirements

Bachelor's degree with 3+ years in a software research team
OR Masters in Computer Science, Math, Physics, Statistics or Engineering with 1+ years in a software research team

Travel Requirements

None

Relocation Provided

None

Position Type

New Grad

Referral Payment Plan

Yes

EEO Statement

Motorola Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other legally-protected characteristic.

We are proud of our people-first and community-focused culture, empowering every Motorolan to be their most authentic self and to do their best work to deliver on the promise of a safer world. If you’d like to join our team but feel that you don’t quite meet all of the preferred skills, we’d still love to hear why you think you’d be a great addition to our team.

We’re committed to providing an inclusive and accessible recruiting experience for candidates with disabilities, or other physical or mental health conditions. To request an accommodation, please complete this Reasonable Accommodations Form so we can assist you.

Motorola Solutions adopte, favorise et promeut les principes de diversité, d’équité et d’inclusion. Nous encourageons et accueillons les candidatures de toutes les personnes qualifiées, quelles que soient leur race, origines ethnique, religion ou croyance, orientation sexuelle, identité et expression sexuelle, statut d’anciens combattants ou tout autre statut protégé par la Loi.

Nous sommes fiers de notre culture axée sur les personnes et les communautés, encourageant ainsi chaque Motorolan d’être la version la plus authentique de lui-même dans ses responsabilités afin de tenir la promesse d’un monde plus sécuritaire.

Si vous souhaitez vous joindre à notre communauté mais croyez que vous ne possédez pas toutes les exigences requises pour le poste convoité, nous aimerions tout de même connaître les raisons pour lesquelles vous pensez être un excellent candidat pour notre équipe.

Nous offrons également des mesures d’adaptation pendant toutes les étapes du processus d’embauche afin de favoriser l’inclusion des personnes vivant avec un handicap physique et/ou mental. Pour demander un aménagement, veuillez remplir ce formulaire d'aménagement raisonnable afin que nous puissions vous aider.",[]
Research Engineer - Large Language Models,Huawei Canada,,,"About the job
Huawei Canada has an immediate 12-month contract opening for a Research Engineer. 

About the team:

The Human-Machine Interaction Lab unites global talents to redefine the relationship between humans and technology. Focused on innovation and user-centered design, the lab strives to advance human-computer interaction research. Our team includes researchers, engineers, and designers collaborating across disciplines to develop novel interactive systems, sensing technologies, wearable and IoT systems, human factors, computer vision, and multimodal interfaces. Through high-impact products and cutting-edge research, we aim to enhance user experiences and interactions with technology.

About the job:

Conduct research and development of advanced LLMs and NLP algorithms, enhancing language understanding and generation capabilities.
Design and optimize LLM architectures for scalability and efficiency in real-world applications, especially in human-computer interaction.
Develop innovative Human-Agent interaction systems that leverage LLMs for more natural, adaptive, and contextually aware user experiences.
Collaborate with cross-functional teams to implement LLM-driven solutions into interactive, production-level systems.
Research and develop novel dialogue management frameworks that support mixed-initiative conversations between humans and AI agents.
Stay updated on the latest advancements in LLMs, NLP, and related AI fields.
Contribute to the research community through patents, publications, and participation in industry conferences. 

Job requirements

About the ideal candidate:

Ph.D. or Master's in Computer Science, Machine Learning, NLP, or a closely related field with a focus on LLMs.
Minimum of 3 years of experience in LLM research and development, with a robust portfolio of applied projects or publications.
Expertise in building, fine-tuning, and deploying large-scale LLMs using frameworks like PyTorch or TensorFlow.
Proficiency in Python and familiarity with additional programming languages like Java or C++.
Proven experience in handling large datasets, data pre-processing pipelines, and optimizing model performance.
Experience with contributing to relevant open-source projects is an asset.
Experience with building commercialized agent/conversational systems is an asset.",[]
Algorithm Expert - NLP Large Model,Huawei Canada,,,"About the job
Huawei Canada has an immediate permanent opening for an Algorithm Expert - NLP Large Model. 

About the team:

The Software Engineering Coach Lab focuses on capability improvements. Undertaking Huawei's trusted change strategy, this lab is responsible for achieving the overall goal of trusted change, and systematically carries out public capacity building and change enablement and management such as trustworthy interpretation, change framework design and guidance, process IT and management systems.

About the job:

Responsible for exploring and tracking the forefront of NLP large model research, and driving the performance of self-developed NLP large models to achieve industry-leading results;
Responsible for addressing challenges such as insufficient controllability and trustworthiness of generated content, low inference efficiency, and overcoming technical barriers to large model deployment in real-world applications;
Responsible for collaborating across technical, pre-research, and business teams to jointly achieve technical and business objectives.

The base salary for this position ranges from $190,000 to $350,000 depending on education, experience and demonstrated expertise.

Job requirements

About the ideal candidate:

Master’s degree or above in Computer Science, Mathematics, Statistics, or a related field.
5+ years of experience in NLP and proficiency in deep learning frameworks.
In-depth research experience in NLP text generation or large-scale pre-training models.
Proficient in algorithm training paradigms; experience in building NLP large models (with over 10 billion parameters) from scratch is an asset.
Strong logical thinking, communication, collaboration, and self-learning abilities.",[]
Développeuse / Développeur en Apprentissage Automatique,Coveo,"bec, QC",Hybrid,"About the job
Fais rayonner la technologie de traitement du langage naturel dans toute l’entreprise

En tant que développeur/développeuse au sein de l’équipe d’apprentissage automatique, tu joueras un rôle clé pour appuyer les équipes de science appliquée et de développement qui entraînent, évaluent et exploitent divers modèles de traitement du langage naturel (NLP), y compris des modèles de langage de grande taille (LLMs).

Tu feras partie de l’équipe CoreNLP, un groupe dynamique de scientifiques et de développeur.euses dont la mission est de fournir des technologies réutilisables qui accélèrent le travail des autres équipes de recherche et développement chez Coveo. Ta mission : collaborer avec ton équipe pour prototyper, mettre en production et maintenir ces technologies qui alimentent plusieurs des fonctionnalités d’IA les plus visibles de Coveo.

Ce Qui Rend Cette Opportunité Aussi Stimulante

Tu te joins à une équipe unique en son genre, placée au cœur de l’innovation en traitement du langage chez Coveo, avec un accès privilégié aux plus récentes percées technologiques du domaine.

Notre équipe explore comment appliquer les dernières avancées en systèmes de recommandation, en optimisation du classement, en grands modèles de langage et en traitement du langage naturel pour créer des solutions novatrices dans les domaines du commerce électronique, du libre-service et bien plus encore. Ici, on s’attaque à de vrais défis avec de vraies données, pour des centaines de grandes entreprises dans le monde, grâce à une plateforme moderne qui gère plus de 100 millions de requêtes et entraîne automatiquement des milliers de modèles chaque jour.

Ce Que Tu Feras Au Quotidien

Participer à toutes les étapes de livraison de la technologie : collecte des besoins, conception, mise en œuvre, tests automatisés, déploiement, surveillance et maintenance.
Faire de l’apprentissage continu une habitude hebdomadaire pour rester à l’affût des tendances émergentes.
Identifier les points de friction et développer des outils qui y répondent concrètement.
Collaborer avec ta communauté de collègues pour remettre en question le statu quo et améliorer nos façons de faire.
Travailler avec notre pile technologique : Python, AWS, Snowflake, Honeycomb, etc.

Ce qui fait de toi la personne idéale pour ce rôle :

Plus de 3 ans d’expérience en apprentissage automatique dans l’industrie, incluant le développement et la maintenance d’outils internes utilisés par d’autres équipes.
Maîtrise des bonnes pratiques en génie logiciel et en ingénierie des données, avec une capacité à livrer un code robuste en production.
Collaboration étroite avec des scientifiques afin de comprendre leurs besoins et d’améliorer leurs outils.
Connaissance de bibliothèques reconnues telles que Langchain, Haystack ou Transformers.

Ce Qui Te Permettra De Te Démarquer

Familiarité avec la programmation asynchrone.
Expérience dans les domaines du traitement du langage naturel, de la recherche d’information ou des systèmes de recommandation, ainsi qu’une bonne compréhension des implications techniques liées à ces contextes.
Excellentes compétences en communication, avec la capacité de vulgariser des concepts complexes à des publics ayant des niveaux variés de connaissances techniques.

Penses-tu pouvoir faire de ce rôle une réalité?

Tu n’as pas besoin de cocher toutes les cases! Nous savons que la passion et les compétences transférables font toute la différence. Envoie-nous ta candidature, nous aimerions te connaître! Joins-toi à la vie chez Coveo!

Nous encourageons toutes les candidatures qualifiées, sans égard à l’âge, au genre, au handicap, aux écarts de parcours ou à l’origine ethnique ou nationale. Nous savons que postuler demande du temps, et nous apprécions vraiment ta démarche!",[]
"Language Engineer II, Alexa Customer Journeys",Amazon,,,"About the job
Description

The Alexa Customer Journeys team is seeking a Language Engineer with experience in the field of Natural Language Processing, Machine Learning, or Large Language Models, as well as expertise in handling large data sets and strong analytical skills. You will play a critical role in innovative projects by driving design of Alexa features. The key responsibilities are to generate high-quality data and to run and evaluate experiments, which involves prompt engineering our Large Language Model for API delivery. You will work closely with engineers, scientists, and program managers to ensure we're providing the best Alexa experience for millions of our customers.

As a Language Engineer, you will start by diving deep into a couple of critical projects across Alexa experiences. You will collaborate with fellow Language Engineers, Data Scientists, Program Managers, and stakeholders in science, engineering, and product teams to understand the role data plays in developing data sets and exemplars that meet customer needs. You will analyze and automate processes for collecting and annotating LLM inputs and outputs to assess data quality and measurement.

You will apply state-of-the-art Generative AI techniques to analyze how well our data represents human language and run experiments to gauge downstream interactions. You will work collaboratively with other Language Engineers and Scientists to design and implement principled strategies for data optimization.

Key job responsibilities

 Collaborate with scientists and software engineers to help design APIs and evaluate performance of LLM's
 Produce and manipulate different types of language data, analyze and provide efficient solutions
 Design and lead a data collection; define scope and target, provide a guideline and training, guide teams cross sites to meet the quality bar, and run evaluation of data for hand off
 Engineer prompts to guide generative AI to produce desired outputs in context
 Automate operations and perform data analysis using Python or other scripting language
 Advocate strict adherence to annotation guidelines
 Test and deploy changes to Alexa's language understanding codebase
 Identify and solve production issues that are impacting the Alexa customer experience
 Collaborate with other linguists, scientists, and designers in creating optimal solutions to elevate the customer experience
 Own the customer-facing machine learning and deterministic models for a specific domain of features
 Use modeling tools to bootstrap and test new functionalities

Basic Qualifications

 Experience in Python or another scripting languages
 Experience in Java basics
 Experience with database queries
 Experience in Natural Language Processing, Machine Learning, or Large Language Models
 Practical knowledge of version control and agile development
 Excellent communication, strong organizational skills and detail-oriented
 Comfortable working in a fast paced, highly collaborative, and dynamic work environment

Preferred Qualifications

 PhD in computational linguistics or equivalent field with computational analysis, or work experience equivalent
 Able to think creatively and possess strong analytical and problem solving skills

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

The base salary for this position ranges from $66,400/year up to $110,800/year. Salary is based on a number of factors and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. Applicants should apply via our internal or external career site.


Company - Amazon Development Centre Canada ULC

Job ID: A2912215",[]
"Member of Technical Staff, MLE",Cohere,"Toronto, ON",Hybrid,"About the job
Who are we?

Our mission is to scale intelligence to serve humanity. We’re training and deploying frontier models for developers and enterprises who are building AI systems to power magical experiences like content generation, semantic search, RAG, and agents. We believe that our work is instrumental to the widespread adoption of AI.

We obsess over what we build. Each one of us is responsible for contributing to increasing the capabilities of our models and the value they drive for our customers. We like to work hard and move fast to do what’s best for our customers.

Cohere is a team of researchers, engineers, designers, and more, who are passionate about their craft. Each person is one of the best in the world at what they do. We believe that a diverse range of perspectives is a requirement for building great products.

Join us on our mission and shape the future!

Why this role?

As a Member of Technical Staff on our Applied ML team, you will work directly with customers to quickly understand their greatest problems and design and implement solutions using Large Language Models.

You’ll apply your problem-solving ability, creativity, and technical skills to close the last-mile gap in Enterprise AI adoption. You’ll be able to deliver products like early startup CTOs/CEOs do and disrupt some of the most important industries and institutions globally!

In This Role, You Will

Own and build large new areas within our product.
Work across backend, frontend, and customize Large Language Models.
Experiment at a high velocity and level of quality to engage our customers and eventually deliver solutions that exceed their expectations.
Work across the entire product lifecycle from conceptualization through production.

This career opportunity may be a good match for you if you have:

3+ years of model training, deployment, and maintenance in a production environment.
Strong skills in NLP and deep learning.
Experience scaling products at hyper-growth startup.
Strong written and verbal communication skills.
Ability and interest to travel up to 25%, as needed to client sites, but flexible based on personal preferences.

Nice To Have Skills/experiences

Experience improving LLM performance for custom domains via fine tuning or RLHF.
Experience in Information Retrieval systems for document question answering.
Experience in day-to-day NLP for industry using Python and related toolchains (SpaCy, HuggingFace, NLTK, etc.).
Published research in areas of machine learning at major conferences and/or journals.

If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply! If you want to work really hard on a glorious mission with teammates that want the same thing, Cohere is the place for you.

We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants from all backgrounds and are committed to providing equal opportunities. Should you require any accommodations during the recruitment process, please submit an Accommodations Request Form, and we will work together to meet your needs.

Full-Time Employees At Cohere Enjoy These Perks

🤝 An open and inclusive culture and work environment

🧑‍💻 Work closely with a team on the cutting edge of AI research

🍽 Weekly lunch stipend, in-office lunches & snacks

🦷 Full health and dental benefits, including a separate budget to take care of your mental health

🐣 100% Parental Leave top-up for 6 months for employees based in Canada, the US, and the UK

🎨 Personal enrichment benefits towards arts and culture, fitness and well-being, quality time, and workspace improvement

🏙 Remote-flexible, offices in Toronto, New York, San Francisco and London and co-working stipend

✈️ 6 weeks of vacation

Note: This post is co-authored by both Cohere humans and Cohere technology.",[]
"Member of Technical Staff, Post training team",Cohere,"Ottawa, ON",Remote,"About the job
Who are we?

Our mission is to scale intelligence to serve humanity. We’re training and deploying frontier models for developers and enterprises who are building AI systems to power magical experiences like content generation, semantic search, RAG, and agents. We believe that our work is instrumental to the widespread adoption of AI.

We obsess over what we build. Each one of us is responsible for contributing to increasing the capabilities of our models and the value they drive for our customers. We like to work hard and move fast to do what’s best for our customers.

Cohere is a team of researchers, engineers, designers, and more, who are passionate about their craft. Each person is one of the best in the world at what they do. We believe that a diverse range of perspectives is a requirement for building great products.

Join us on our mission and shape the future!

Why this role?

Advance the state of the art for model post training, ship state of the art models to production, and bridge the gap between research and production. We have one of the highest ratio of compute to engineers in the world. We do not delineate strongly between engineering and research. Everyone will contribute to writing production code and supporting our research effort depending on individual interest and organisational needs. We have all the compute, data, and talent available for you to do your best work.

Please Note: We have offices in London, Paris, Toronto, San Francisco, New York but also embrace being remote-friendly!

As a Member Of Technical Staff, You Will

Design and write high-performant and scalable software for training models.
Consistently post-train the models to reach SOTA level performance.
Coordinate with other specialist teams (Agentic, Code…) to produce models that have strong all encompassing performance.
Craft and implement techniques to improve the performance and results of our training cycles both on the SFT and the RL regime.
Research, implement, and experiment with ideas on our supercompute and data infrastructure.
Learn from and work with the best researchers in the field.

You May Be a Good Fit If You Have

Extremely strong software engineering skills.
Proficiency in Python and related ML frameworks such as JAX, Pytorch and XLA/MLIR.
Experience with distributed training infrastructures (Kubernetes, Slurm) and associated frameworks (Ray).
Experience using large-scale distributed training strategies.
Hands on experience on training large model at scale.
Hands on experience with the post training phase of model training, with a strong emphasis on performance optimisation.
Bonus: paper at top-tier venues (such as NeurIPS, ICML, ICLR, AIStats, MLSys, JMLR, AAAI, Nature, COLING, ACL, EMNLP).
 This is neither an exhaustive nor necessary set of attributes. Even if none of these apply to you, but you believe you will contribute to Cohere, please reach out. We have a wide variety of backgrounds at Cohere.

If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply! If you want to work really hard on a glorious mission with teammates that want the same thing, Cohere is the place for you.

We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants from all backgrounds and are committed to providing equal opportunities. Should you require any accommodations during the recruitment process, please submit an Accommodations Request Form, and we will work together to meet your needs.

Full-Time Employees At Cohere Enjoy These Perks

🤝 An open and inclusive culture and work environment

🧑‍💻 Work closely with a team on the cutting edge of AI research

🍽 Weekly lunch stipend, in-office lunches & snacks

🦷 Full health and dental benefits, including a separate budget to take care of your mental health

🐣 100% Parental Leave top-up for 6 months for employees based in Canada, the US, and the UK

🎨 Personal enrichment benefits towards arts and culture, fitness and well-being, quality time, and workspace improvement

🏙 Remote-flexible, offices in Toronto, New York, San Francisco and London and co-working stipend

✈️ 6 weeks of vacation

Note: This post is co-authored by both Cohere humans and Cohere technology.",[]
Applied Scientist – Research Products,Thomson Reuters,"Toronto, ON",Hybrid,"About the job
Are you excited about working at the forefront of applied research in an industry setting? Thomson Reuters Labs in Toronto is seeking scientists with a passion for solving problems using state-of-the-art information retrieval, natural language processing and generative AI.

What does Thomson Reuters Labs do? We experiment, we build, we deliver. We support the organization and our customers through applied research in informational retrieval and natural language processing. We work closely with product and domain experts to identify compelling solutions at the intersection of user need and technical feasibility. Our team is designing the next generation of search technology for Legal and Tax Professionals globally. We drive AI innovation for Thomson Reuters’ Core Research Products, including Westlaw, Practical Law, and Checkpoint.

About The Role

Applied Scientists are experts in NLP, who contribute to the research and development of AI solutions that enhance Thomson Reuters' products. Their work ensures AI technologies are aligned with business objectives to drive innovation and deliver customer value.

As an Applied Scientist, you will:

Take ideas through the end-to-end model development lifecycle (task design, data creation, training, evaluation and model governance) 
Think creatively about new capabilities generative AI can unlock for our customers 
Work with stakeholders to define scope, determine feasibility, and translate business/customer objectives into technical requirements 
Create functional POCs to test new capabilities and Product concepts 
Write clean code, participate in code reviews, and contribute to well-managed software delivery in a production environment 


About You

You’re a fit for the role of Applied Scientist if your background includes:

PhD or Master’s in a relevant discipline 
Experience researching, building, and evaluating NLP systems 
Solid engineering skills for prototyping; experience contributing to a shared codebase; and familiarity with workflows for remote development (AWS, Azure or similar) 
Outstanding communication, problem solving, and analysis skills 
Demonstrated ability to communicate AI concepts to diverse audience 
Experience designing and implementing solutions with large language models 
Relevant publications at ACL, EMNLP, NAACL, NeurIPS, ICLR, SIGIR, KDD, or similar. 
Experience writing production code and ensuring well-managed software delivery 


What’s in it For You?

Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Industry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Culture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives. 
Making a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.


About Us

Thomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

As a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.

Learn more on how to protect yourself from fraudulent job postings here.

More information about Thomson Reuters can be found on thomsonreuters.com.",[]
"Sr. Software Development Engineer, Conversational AI Modeling and Learning, Alexa Conversational AI Modeling and Learning (CAMEL)",Amazon,,,"About the job
Description

The Alexa Conversational AI Modeling and Learning (CAMEL) team is looking for a highly-skilled SDE to lead a new initiative which is at the forefront of using state of the art (SOTA) innovations in Large Language Models (LLMs) to build an AI agent which can converse naturally with customers, entertain them, perform their requested tasks and act autonomously to solve complex tasks.

As a Sr.SDE on the team, you will own building and re-architect tier-1 services which are responsible for end-to-end orchestration and execution of multi-modal conversational agent requests. From getting the best prompt and context for the request, to picking the correct model to inference, to interpreting LLM's output, creating an actionable plan and executing it.

Key job responsibilities

We are looking for a talented Sr. Software Development Engineer to

 To quickly learn SOTA technologies and algorithms in the field of Generative AI on greenfield projects to participate in our journey to build the best conversational agent.
 Responsible for the development and maintenance of key platforms needed for connecting LLMs to actual user requests and real world APIs which act on them required for building conversational agents.
 Work with other team members to investigate design approaches, prototype new technology and evaluate technical feasibility.
 Work closely with Applied scientists to handle myriad of conversational use cases along with optimizing latency, cost and capacity.
 Work in an Agile/Scrum environment to deliver high quality software in a fast-paced environment.

Your time with us will be impactful, and your vision, creativeness and engineering output adopted by teams across Amazon and beyond.

As a member of the team you will be responsible for leading the development and launch of core product features. You will have significant influence on our overall strategy by helping define these product features, drive the system architecture, and spearhead the best practices that enable a quality product.

A day in the life

As a Sr.SDE in the CAMEL team, you will be responsible for leading the development of high performance, low latency and low cost solutions for building the best in class conversational agent which solves real world problems for millions of customer. You will have significant influence on our overall strategy by helping define the architecture of tomorrow, where multiple LLMs with different modalities come together to solve real world customer problems. Your work will directly impact our customers in the form of products and services that make use of conversational agent innovations. You will partner closely with experienced engineers and scientists to drive the system architecture, and spearhead the best practices that enable a quality infrastructure.

About The Team

Join our CAMEL team and work at the forefront of AI. Gain valuable experience and accelerate your career growth. This is a unique opportunity to create history and shape the future of artificial intelligence.

Basic Qualifications

 7+ years of non-internship professional software development experience
 7+ years of programming with at least one software programming language experience
 7+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
 Experience as a mentor, tech lead or leading an engineering team

Preferred Qualifications

 5+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
 Bachelor's degree in computer science or equivalent

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - Amazon Development Centre Canada ULC

Job ID: A2939726",[]
Lead AI Solutions Engineer,Thomson Reuters,"Toronto, ON",Hybrid,"About the job
Lead AI Solutions Engineer, TR Labs

Are you excited about working at the forefront of applied research in an industry setting? Thomson Reuters Labs is seeking Lead AI Solutions Engineer with a passion for solving problems using state-of-the-art information retrieval, natural language processing and generative AI.

What does Thomson Reuters Labs do? We experiment, we build, we deliver. We work closely with product and domain experts to identify compelling solutions at the intersection of user need and technical feasibility. Our team is designing the next generation of expert systems for legal, tax, and risk compliance. You’ll leverage state-of-the-art large language models on a robust AI platform to develop agents and tools that transform the future of work for legal and tax professionals.

About The Role:

As an Lead AI Solutions Engineer, you will work with a cross functional team at the intersection of science, product, and engineering to:

Develop zero-to-one concepts for expert systems 
Systematically discover and test prompt engineering best practices 
Optimize data sets for prompt development, model training and evaluation 
Help create and maintain infrastructure required for efficient prompt development 
Test and assess open-source solutions for LLM application development including orchestration frameworks, tool interfaces, solutions for context management, etc. 
Develop automated techniques for the design and evaluation of AI agents 
Analyze usage data to gauge the effectiveness of AI solutions and iteratively improve 
Stay up to date with the latest research and emerging tech for AI Engineering 


About You:

The ideal candidate for the role of Lead AI Solutions Engineer will have a background in NLP, experience building with LLMs, python proficiency for rapid prototyping, and the soft skills to bridge technical and business perspectives.

Required Qualifications:

Master’s degree in CS/ML/DS or a bachelor's with equivalent experience. 
7+ years of transferrable experience in natural language processing (NLP) 
Basic familiarity with the architecture and operation of large language models
Strong desire to work closely with subject matter experts on real world use cases 
Active interest in emerging research and industry trends around AI software development 
Proficiency in python and AI development tools 
A mindset for good experiment design and evaluation; strong analytical and critical thinking 
Excellent communication and organization skills 


Preferred Qualifications:

Experience working on legal AI systems (e.g., for contract analysis, legal research, or drafting) 
Domain knowledge in legal, tax, or accounting. A law degree (J.D.), paralegal experience, etc. 
A portfolio of projects demonstrating creativity and skill building solutions with LLMs 
Experience developing NLP applications involving NER, information retrieval, text summarization, question answering, or similar. 
Knowledge of MLOps and the end-to-end lifecycle of software applications involving AI models 


What’s in it For You?

Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Industry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Culture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives. 
Making a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.


About Us

Thomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

As a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.

Learn more on how to protect yourself from fraudulent job postings here.

More information about Thomson Reuters can be found on thomsonreuters.com.",[]
Senior Machine Learning Engineer,Instacart,,,"About the job
We're transforming the grocery industry

At Instacart, we invite the world to share love through food because we believe everyone should have access to the food they love and more time to enjoy it together. Where others see a simple need for grocery delivery, we see exciting complexity and endless opportunity to serve the varied needs of our community. We work to deliver an essential service that customers rely on to get their groceries and household goods, while also offering safe and flexible earnings opportunities to Instacart Personal Shoppers.

Instacart has become a lifeline for millions of people, and we’re building the team to help push our shopping cart forward. If you’re ready to do the best work of your life, come join our table.

Instacart is a Flex First team 

There’s no one-size fits all approach to how we do our best work. Our employees have the flexibility to choose where they do their best work—whether it’s from home, an office, or your favorite coffee shop—while staying connected and building community through regular in-person events. Learn more about our flexible approach to where we work.

Overview

About the Role:

This is a general posting for multiple Sr. Machine Learning roles open across our 4-sided marketplace. You’ll get the chance to learn about the problems the different ML teams solve as you go through the process. Towards the end of your process, we’ll do a team-matching exercise to determine which of the open roles/teams you’ll join. You can find a blurb on each team at the bottom of this page.

About The Team

Core Experience: The Core Experience organization at Instacart is at the forefront of applying cutting-edge AI technologies, including large language models (LLMs), to revolutionize how customers find products. Working alongside world-class engineers, data scientists, and product managers, we're building sophisticated machine learning and AI systems that power the future of search and recommendations at Instacart. Our team leverages state-of-the-art transformer architectures, multimodal AI, and generative models to enhance the relevance across all shopping surfaces. We're constantly innovating with advanced neural retrieval methods, LLM-powered ranking algorithms, and AI-driven personalization systems that deliver highly contextual and intuitive results to users throughout the Instacart ecosystem. As part of our team, you'll tackle one of the most critical aspects of the business—helping customers connect with exactly the right products through AI. We're solving complex, large-scale search challenges using the latest in deep learning, natural language understanding, and LLM fine-tuning techniques to create intelligent systems that truly understand user intent and shopping behavior. Our commitment to AI innovation is reflected in our recent publications and research contributions to the field (Recent publications 1, 2, 3, 4, 5).

About The Job

Design, develop, and deploy advanced AI and machine learning solutions, including LLMs and neural networks, to solve complex challenges in our dynamic marketplace environment.
Architect and implement state-of-the-art deep learning systems that leverage transformer models, multimodal AI, and generative techniques to create intelligent, adaptive solutions.
Collaborate closely with product managers, data scientists, and backend engineers to translate business requirements into cutting-edge AI applications that deliver measurable impact.
Pioneer the application of foundation models, prompt engineering, and fine-tuning methodologies to create AI systems that understand context and user intent at unprecedented levels.
Engage with diverse stakeholders to ensure our AI solutions are ethically implemented, well-integrated with existing systems, and fully aligned with strategic business objectives.
Drive continuous innovation in our AI infrastructure by researching, testing, and implementing the latest advancements in machine learning, from embeddings and vector databases to reinforcement learning from human feedback (RLHF).
Push the boundaries of operational efficiency through intelligent automation, predictive modeling, and algorithmic optimization powered by our custom-trained AI systems.

About You

Minimum Qualifications:

Have a graduate degree (masters or PhD) in artificial intelligence, machine learning or equivalent self study and experience
Have 7+ years of industry experience using machine learning to solve real-world problems with large datasets
Have strong programming skills in Python and fluency in data manipulation (SQL, Pandas) and Machine Learning (scikit-learn, XGBoost, Keras/Tensorflow) tools
Have strong analytical skills and problem-solving ability
Are a strong communicator who can collaborate with diverse stakeholders across all levels

Preferred Qualifications

Extensive expertise with modern deep learning frameworks (PyTorch, TensorFlow, JAX) and advanced LLM architectures including transformer models, attention mechanisms, and multimodal AI systems.
Demonstrated experience implementing and fine-tuning large language models, including prompt engineering, embedding techniques, and efficient inference optimization for production environments.
Strong foundation in AI fundamentals including neural network architectures, generative models, and foundation model adaptation methodologies like PEFT, LoRA, and RLHF.
Proven track record designing and deploying sophisticated ML/AI systems in production environments that drive measurable business impact through improved recommendations, search relevance, and user engagement metrics.
Experience optimizing AI model performance across the full stack, from model architecture and training workflows to distributed inference and serving infrastructure.
Self-motivated innovator with a strong sense of ownership who can navigate the rapidly evolving AI landscape, evaluate emerging techniques, and implement novel approaches to solve complex business challenges.
Passion for applying cutting-edge AI research to real-world applications and a keen understanding of the practical considerations in developing responsible, efficient AI systems at scale.

Instacart provides highly market-competitive compensation and benefits in each location where our employees work. This role is remote and the base pay range for a successful candidate is dependent on their permanent work location. Please review our Flex First remote work policy here. Currently, we are only hiring in the following provinces: Ontario, Alberta, British Columbia, and Nova Scotia.

Offers may vary based on many factors, such as candidate experience and skills required for the role. Additionally, this role is eligible for a new hire equity grant as well as annual refresh grants. Please read more about our benefits offerings here.

For Canadian based candidates, the base pay ranges for a successful candidate are listed below.

CAN

$176,000—$225,000 CAD",[]
Senior AI Systems Engineer,Benevity,"Toronto, ON",Remote,"About the job
Meet Benevity
Benevity is the way the world does good, providing companies (and their employees) with technology to take social action on the issues they care about. Through giving, volunteering, grantmaking, employee resource groups and micro-actions, we help most of the Fortune 100 brands build better cultures and use their power for good. We’re also one of the first B Corporations in Canada, meaning we’re as committed to purpose as we are to profits. We have people working all over the world, including Canada, Spain, Switzerland, the United Kingdom, the United States and more!
We’re looking for a Senior AI Engineer to lead the design and deployment of intelligent, scalable AI systems. In this role, you'll apply deep technical expertise across the AI/ML stack — from foundation models to system orchestration — to build real-world, production-ready applications. You’ll shape experiences powered by LLMs, retrieval systems, and intelligent automation, while contributing to a platform that prioritizes responsible AI. You’ll work cross-functionally with data scientists, product managers, and platform engineers to help steer the long-term direction of Benevity’s AI capabilities.
This role offers growth potential into a Lead AI Architect position as we scale our AI capabilities across the Benevity Impact Platform.
What you’ll do:
AI System Design & Development
Architect and implement intelligent AI workflows for complex task execution using LLMs and other AI techniques
Design retrieval-augmented generation (RAG) systems and integrate them with broader platform capabilities
Build automation frameworks that orchestrate tools, APIs, and structured data using AI-driven logic
Develop Text-to-SQL and semantic query interfaces for business and analytics users
Implement traceable, auditable AI pipelines that prioritize explainability and reliability
Evaluate model/system performance and iterate using systematic benchmarking approaches
Platform Integration & Infrastructure
Lead the development of scalable, cloud-native AI services on AWS, GCP, or Azure
Build and maintain CI/CD pipelines for continuously improving AI applications
Optimize vector search and embedding workflows, leveraging top vector DBs
Apply best practices in LLMOps including model versioning, telemetry, and automated evaluations
Contribute to the evolution of AI infrastructure, including observability, compliance, and security
Collaboration & Mentorship
Collaborate with Product, Design, and Operations teams to shape AI-enabled features across the platform
Serve as a mentor and technical guide for junior and mid-level engineers
Promote responsible AI practices and ensure systems meet privacy, compliance, and ethical standards
Research, evaluate, and implement state-of-the-art techniques in LLMs and AI agents
What you’ll bring:
A Bachelor's or Master’s in Computer Science, Engineering, or a related field
5+ years of software engineering experience, with 3+ years focused on AI/ML systems design
Proven ability to deliver end-to-end AI solutions in production environments
Deep proficiency in Python and modern frameworks (e.g., FastAPI, Flask)
Experience with retrieval systems, embedding models, and foundation model integration
Familiarity with LLM platforms (e.g., OpenAI, Cohere, Bedrock) and fine-tuning workflows
Understanding of agent-based systems and external tool orchestration
Strong foundation in NLP, including structured data interaction (e.g., Text-to-SQL)
Hands-on experience with LLMOps tools like LangSmith, BentoML, and Weights & Biases
Fluency in cloud-native deployment (Docker, Kubernetes, serverless)
Technical Skills & Expertise:
Programming: Expert-level proficiency in Python, including building scalable APIs and services; experience with TypeScript, Go, or Java is a plus
LLM & AI Frameworks: Advanced experience with Hugging Face Transformers, LangChain, OpenAI, and fine-tuning large language models; deep familiarity with frameworks like PyTorch and TensorFlow
RAG & Embeddings: Proficient in building and optimizing RAG pipelines using vector databases (e.g., Pinecone, Weaviate, FAISS, or Qdrant) and embedding models
MLOps & LLMOps: Hands-on experience with MLflow, Airflow, and advanced tools for LLMOps such as BentoML, LangSmith, and Weights & Biases; strong understanding of evaluation, model/version management, and prompt tuning workflows
Cloud & Infrastructure: Proven experience deploying AI systems in production on AWS, GCP, or Azure (AWS preferred); deep understanding of Kubernetes, Docker, Terraform, and serverless deployment patterns
System Integration: Skilled in connecting AI systems with real-world data pipelines and services, including structured databases (SQL/NoSQL), event-based systems (Kafka, Pub/Sub), and service interfaces (REST, gRPC)
Monitoring & Observability: Skilled in using Prometheus, Grafana, Datadog, or similar for monitoring LLM performance, usage metrics, and operational health
Security & Compliance: Familiar with implementing access control, data privacy, and ethical AI guidelines in cloud-based AI systems
Discover your purpose at work
We’re not employees, we’re Benevity-ites. From all locations, backgrounds and walks of life, who deserve more …
Innovative work. Growth opportunities. Caring co-workers. And a chance to do work that fills us with a sense of purpose.
If the idea of working on tech that helps people do good in the world lights you up ... If you want a career where you’re valued for who you are and challenged to see who you can become …
It’s time to join Benevity. We’re so excited to meet you.
Where we work
At Benevity, we embrace a flexible hybrid approach to where we work that empowers our people in a way that supports great work, strong relationships, and personal well-being. For those located near one of our offices, while there’s no set requirement for in-office time, we do value the moments when coming together in person helps us build connection and collaboration. Whether it’s for onboarding, project work, or a chance to align and bond as a team, we trust our people to make thoughtful decisions about when showing up in person matters most.
Join a company where DEIB isn’t a buzzword
Diversity, equity, inclusion and belonging are part of Benevity’s DNA. You’ll see the impact of our massive investment in DEIB daily — from our well-supported employee resources groups to the exceptional diversity on our leadership and tech teams.
We know that diverse backgrounds, experiences, skills and passions are what move our business and our people forward, so we're committed to creating a culture of belonging with equal opportunities for everyone to shine. 
That starts with a fair and accessible hiring process. If you want to feel seen, heard and celebrated, you belong at Benevity.
Candidates with disabilities who may require accommodations throughout the hiring or assessment process are encouraged to reach out to accommodations@benevity.com.",[]
Senior AI Systems Engineer,Benevity,"Toronto, ON",Remote,"About the job
Meet Benevity
Benevity is the way the world does good, providing companies (and their employees) with technology to take social action on the issues they care about. Through giving, volunteering, grantmaking, employee resource groups and micro-actions, we help most of the Fortune 100 brands build better cultures and use their power for good. We’re also one of the first B Corporations in Canada, meaning we’re as committed to purpose as we are to profits. We have people working all over the world, including Canada, Spain, Switzerland, the United Kingdom, the United States and more!
We’re looking for a Senior AI Engineer to lead the design and deployment of intelligent, scalable AI systems. In this role, you'll apply deep technical expertise across the AI/ML stack — from foundation models to system orchestration — to build real-world, production-ready applications. You’ll shape experiences powered by LLMs, retrieval systems, and intelligent automation, while contributing to a platform that prioritizes responsible AI. You’ll work cross-functionally with data scientists, product managers, and platform engineers to help steer the long-term direction of Benevity’s AI capabilities.
This role offers growth potential into a Lead AI Architect position as we scale our AI capabilities across the Benevity Impact Platform.
What you’ll do:
AI System Design & Development
Architect and implement intelligent AI workflows for complex task execution using LLMs and other AI techniques
Design retrieval-augmented generation (RAG) systems and integrate them with broader platform capabilities
Build automation frameworks that orchestrate tools, APIs, and structured data using AI-driven logic
Develop Text-to-SQL and semantic query interfaces for business and analytics users
Implement traceable, auditable AI pipelines that prioritize explainability and reliability
Evaluate model/system performance and iterate using systematic benchmarking approaches
Platform Integration & Infrastructure
Lead the development of scalable, cloud-native AI services on AWS, GCP, or Azure
Build and maintain CI/CD pipelines for continuously improving AI applications
Optimize vector search and embedding workflows, leveraging top vector DBs
Apply best practices in LLMOps including model versioning, telemetry, and automated evaluations
Contribute to the evolution of AI infrastructure, including observability, compliance, and security
Collaboration & Mentorship
Collaborate with Product, Design, and Operations teams to shape AI-enabled features across the platform
Serve as a mentor and technical guide for junior and mid-level engineers
Promote responsible AI practices and ensure systems meet privacy, compliance, and ethical standards
Research, evaluate, and implement state-of-the-art techniques in LLMs and AI agents
What you’ll bring:
A Bachelor's or Master’s in Computer Science, Engineering, or a related field
5+ years of software engineering experience, with 3+ years focused on AI/ML systems design
Proven ability to deliver end-to-end AI solutions in production environments
Deep proficiency in Python and modern frameworks (e.g., FastAPI, Flask)
Experience with retrieval systems, embedding models, and foundation model integration
Familiarity with LLM platforms (e.g., OpenAI, Cohere, Bedrock) and fine-tuning workflows
Understanding of agent-based systems and external tool orchestration
Strong foundation in NLP, including structured data interaction (e.g., Text-to-SQL)
Hands-on experience with LLMOps tools like LangSmith, BentoML, and Weights & Biases
Fluency in cloud-native deployment (Docker, Kubernetes, serverless)
Technical Skills & Expertise:
Programming: Expert-level proficiency in Python, including building scalable APIs and services; experience with TypeScript, Go, or Java is a plus
LLM & AI Frameworks: Advanced experience with Hugging Face Transformers, LangChain, OpenAI, and fine-tuning large language models; deep familiarity with frameworks like PyTorch and TensorFlow
RAG & Embeddings: Proficient in building and optimizing RAG pipelines using vector databases (e.g., Pinecone, Weaviate, FAISS, or Qdrant) and embedding models
MLOps & LLMOps: Hands-on experience with MLflow, Airflow, and advanced tools for LLMOps such as BentoML, LangSmith, and Weights & Biases; strong understanding of evaluation, model/version management, and prompt tuning workflows
Cloud & Infrastructure: Proven experience deploying AI systems in production on AWS, GCP, or Azure (AWS preferred); deep understanding of Kubernetes, Docker, Terraform, and serverless deployment patterns
System Integration: Skilled in connecting AI systems with real-world data pipelines and services, including structured databases (SQL/NoSQL), event-based systems (Kafka, Pub/Sub), and service interfaces (REST, gRPC)
Monitoring & Observability: Skilled in using Prometheus, Grafana, Datadog, or similar for monitoring LLM performance, usage metrics, and operational health
Security & Compliance: Familiar with implementing access control, data privacy, and ethical AI guidelines in cloud-based AI systems
Discover your purpose at work
We’re not employees, we’re Benevity-ites. From all locations, backgrounds and walks of life, who deserve more …
Innovative work. Growth opportunities. Caring co-workers. And a chance to do work that fills us with a sense of purpose.
If the idea of working on tech that helps people do good in the world lights you up ... If you want a career where you’re valued for who you are and challenged to see who you can become …
It’s time to join Benevity. We’re so excited to meet you.
Where we work
At Benevity, we embrace a flexible hybrid approach to where we work that empowers our people in a way that supports great work, strong relationships, and personal well-being. For those located near one of our offices, while there’s no set requirement for in-office time, we do value the moments when coming together in person helps us build connection and collaboration. Whether it’s for onboarding, project work, or a chance to align and bond as a team, we trust our people to make thoughtful decisions about when showing up in person matters most.
Join a company where DEIB isn’t a buzzword
Diversity, equity, inclusion and belonging are part of Benevity’s DNA. You’ll see the impact of our massive investment in DEIB daily — from our well-supported employee resources groups to the exceptional diversity on our leadership and tech teams.
We know that diverse backgrounds, experiences, skills and passions are what move our business and our people forward, so we're committed to creating a culture of belonging with equal opportunities for everyone to shine.
That starts with a fair and accessible hiring process. If you want to feel seen, heard and celebrated, you belong at Benevity.
Candidates with disabilities who may require accommodations throughout the hiring or assessment process are encouraged to reach out to accommodations@benevity.com.",[]
"Sr Data Scientist– NLP, LLM and GenAI",S&P Global,,,"About the job
About The Role

Grade Level (for internal use):

10

Job Description

The Role: Sr Data Scientist– NLP, LLM and GenAI

S&P is a leader in risk management solutions leveraging automation and AI/ML. This role is a unique opportunity for hands-on ML scientists and NLP/Gen AI/ LLM scientists to grow into the next step in their career journey and apply her or his technical expertise in NLP, deep learning, GenAI, and LLMs to drive business value for multiple stakeholders while conducting cutting-edge applied research around LLMs, Gen AI, and related areas.

Responsibilities

ML, Gen AI, NLP, LLM Model Development: Design and develop custom ML, Gen AI, NLP, LLM Models for batch and stream processing-based AI ML pipelines. Model components will include data ingestion, preprocessing, search and retrieval, Retrieval Augmented Generation (RAG), NLP/LLM model development, fine-tuning and prompt engineering and ensure the solution meets all technical and business requirements. Work closely with other members of data science, MlOps, technology teams in the design, development, and implementation of the ML model solutions.
ML, NLP, LLM Model Evaluation: Work closely with the other data science team members to develop, validate, and maintain robust evaluation solutions and tools to evaluate model performance, accuracy, consistency, reliability, during development, UAT. Implement model optimizations to improve system efficiency.
NLP, LLM, Gen AI Model Deployment: Work closely with the MLOps team for the deployment of machine learning models into production environments, ensuring reliability and scalability.
Internal Collaboration: Collaborate closely with product teams, business stakeholders, Mlops, machine learning engineers, and software engineers to ensure smooth integration of machine learning models into production systems.
Documentation: Write and Maintain comprehensive documentation of ML modeling processes and procedures for reference and knowledge sharing.
Develop Models Based on Standards and Best Practices: Ensure that the models are designed and developed while adhering to specified standards, governance and best practices in ML model development as specified by senior Data Science and MLOps leads.
Assist in Problem Solving: Troubleshoot complex issues related to machine learning model development and data pipelines and develop innovative solutions.

Compensation/Benefits Information (US Applicants Only)

S&P Global states that the anticipated base salary range for this position is $130,000 - $185,000. Final base salary for this role will be based on the individual’s geographical location as well as experience and qualifications for the role.

In addition to base compensation, this role is eligible for an annual incentive plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, please click here.

What We’re Looking For

Bachelor's / Master’s in Computer Science, Mathematics or Statistics, Computational linguistics, Engineering, or a related field. 
1+ years of professional hands-on experience leveraging large sets of structured and unstructured data to develop data-driven tactical and strategic analytics and insights using ML, NLP, computer vision solutions.
Demonstrated 1+ years hands-on experience with Python, Hugging Face, TensorFlow, Keras, PyTorch, or similar statistical tools. Expert in python programming.
1+ years hands-on experience developing natural language processing (NLP) models, ideally with transformer architectures. 
1+ years of experience with implementing information search and retrieval at scale, using a range of solutions ranging from keyword search to semantic search using embeddings.
Knowledge of developing or tuning Large Language Models (LLM) and Generative AI (GAI)
Knowledge of NLP, LLMs (extractive and generative), fine-tuning and LLM model development. Familiar with higher level trends in LLMs and open-source platforms
Nice to have: Experience with contributing to Github and open source initiatives or in research projects and/or participation in Kaggle competitions.

About S&P Global Ratings

At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions.

S&P Global Ratings is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit www.spglobal.com/ratings

What’s In It For You?

Our Purpose

Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People

We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.

Our Values

Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits

We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our Benefits Include

Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.

For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries

Global Hiring And Opportunity At S&P Global

At S&P Global, we are committed to fostering a connected and engaged workplace where all individuals have access to opportunities based on their skills, experience, and contributions. Our hiring practices emphasize fairness, transparency, and merit, ensuring that we attract and retain top talent. By valuing different perspectives and promoting a culture of respect and collaboration, we drive innovation and power global markets.

S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.

Recruitment Fraud Alert

If you receive an email from a spglobalind.com domain or any other regionally based domains, it is a scam and should be reported to reportfraud@spglobal.com. S&P Global never requires any candidate to pay money for job applications, interviews, offer letters, “pre-employment training” or for equipment/delivery of equipment. Stay informed and protect yourself from recruitment fraud by reviewing our guidelines, fraudulent domains, and how to report suspicious activity here.

Equal Opportunity Employer

S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. 

US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. Pay Transparency Nondiscrimination Provision - https://www.dol.gov/sites/dolgov/files/ofccp/pdf/pay-transp_%20English_formattedESQA508c.pdf

20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)

Job ID: 316456

Posted On: 2025-06-26

Location: New York, New York, United States",[]
"Software Engineer, NHX Express & Guide",Thumbtack,"Ontario, Canada",Remote,"About the job
Thumbtack helps millions of people confidently care for their homes.

Thumbtack is the one app you need to take care of and improve your home — from personalized guidance to AI tools and a best-in-class hiring experience. Every day in every county of the U.S., people turn to Thumbtack to complete urgent repairs, seasonal maintenance and bigger improvements. We help homeowners know which projects to do, when to do them and who to hire from our growing community of 300,000 local service businesses. If making an impact inspires you, join us. Imagine what we’ll build together.

About The NHX Express & Guide Team

The NHX Express & Guide team is reimagining how homeowners express problems and take action in the home services space. Our mission is simple but ambitious: help users feel seen, supported, and confident at every step of their journey from recognizing an issue to hiring the right professional. We’re building experiences that reduce uncertainty, clarify intent, and unlock forward momentum.

We’re an AI-native team at the core of Thumbtack’s product vision. We use multimodal inputs, Large Language Models (LLMs), and structured intelligence to transform how people describe home issues, troubleshoot needs, and discover solutions. Whether it’s interpreting a photo of a leaky faucet or guiding someone through a tricky repair with dynamic questions, we’re creating a new interaction layer that feels more like talking to a human than filling out a form.

The Challenge

This is a unique opportunity to design a brand-new kind of experience that helps people care for their homes with more clarity, confidence, and ease. We’re not just layering in AI features, we’re rethinking the product from the ground up using LLMs, vision models, and agentic workflows to create smarter, more human interactions. The team moves fast, shipping real features and learning quickly through dual-track execution balancing short-term impact with long-term innovation. We focus on solving real-world problems with clarity, not just building flashy demos. If you're excited about using cutting-edge tech to make everyday life better, you’ll thrive here.

What You'll Do

Build and ship end-to-end product experiences that help users describe and solve home issues using AI-native interactions.
Collaborate with designers, researchers, and product managers to prototype, test, and launch features that feel natural and support multimodality.
Develop backend services and APIs that power intelligent intake flows, dynamic guidance, and personalized hiring suggestions.
Integrate LLMs and vision models into user-facing experiences, applying techniques like context engineering, retrieval augmented generation, and structured memory.
Own and improve systems that turn messy real-world input (like photos or voice notes) into actionable insights for our pros and users.
Partner with infra and ML teams to monitor model performance, optimize latency, and drive continuous improvement in AI quality.
Contribute to a culture of fast experimentation and thoughtful iteration, learning from every launch to improve both product and process

In order to be successful, you must bring

2+ years of experience in software engineering
A strong passion for creating product experiences that genuinely delight users and improve their quality of life
Curiosity and drive to stay on top of cutting-edge technology, with a habit of bringing those learnings into everyday work
Hands-on experience building with AI whether through side projects, Vibe coding apps, or personal experiments, we’d love to see what you’ve built and hear how you approached it
Fluent in at least one major programming language and would be able to switch between multiple languages. We mainly use Go, Python for our backend with Swift, Kotlin and Java for our mobile apps
Familiarity with LLMs, machine learning frameworks, model performance monitoring & fine tuning
Solid experience building software on top of relational & non-relational databases such as Postgres, MySQL, DynamoDB

Thumbtack embraces diversity. We are proud to be an equal opportunity workplace and do not discriminate on the basis of sex, race, color, age, pregnancy, sexual orientation, gender identity or expression, religion, national origin, ancestry, citizenship, marital status, military or veteran status, genetic information, disability status, or any other characteristic protected by federal, provincial, state, or local law. We also will consider for employment qualified applicants with arrest and conviction records, consistent with applicable law.

Thumbtack is committed to working with and providing reasonable accommodation to individuals with disabilities. If you would like to request a reasonable accommodation for a medical condition or disability during any part of the application process, please contact: recruitingops@thumbtack.com.

If you are a California resident, please review information regarding your rights under California privacy laws contained in Thumbtack’s Privacy policy available at https://www.thumbtack.com/privacy/ .",[]
SPÉCIALISTE EN IA,TRSB Inc.,Canada,Remote,"About the job
SPÉCIALISTE EN IA – TALN, IA générative et grands modèles de langue
TRSB est à la recherche d’un ou d’une spécialiste en IA – TALN, IA générative et grands modèles de langue (GML) qui dirigera le déploiement et l’entraînement de GML adaptés à des cas d’utilisation précis de création de contenu, de transformation et de flux de localisation. Le ou la titulaire de ce poste veillera au choix stratégique des technologies d’IA, à leur intégration efficace aux systèmes existants et à leur supervision en continu aux fins d’amélioration de la fiabilité et du rendement. Cette personne travaillera, en concertation avec l’équipe d’ingénierie, l’équipe des opérations et l’équipe de développement et d’exploitation, à la conception, à la mise en œuvre et à l’optimisation de solutions de création de contenu, de transformation et de localisation alimentées par l’IA.

VOS ACTIVITÉS AU QUOTIDIEN :
Conception de moteurs d’IA : concevoir les solutions d’IA venant répondre aux différents défis commerciaux et cas d’utilisation. 
Mise en œuvre et entraînement de l’IA : sélectionner, mettre au point et mettre en œuvre des GML pour des cas d’utilisation précis dans une visée d’efficacité et de rendement optimaux.
Sélection des technologies : évaluer et recommander les technologies d’IA les mieux adaptées aux différents cas d’utilisation et besoins d’affaires.
Intégration de solutions : collaborer avec l’équipe de développement et d’exploitation afin d’assurer l’intégration harmonieuse de flux alimentés par l’IA dans les systèmes (mémoires de traduction, etc.), les outils (traduction assistée par ordinateur, etc.) et les flux de travail existants.
Suivi de la fiabilité et du rendement : développer des méthodes de suivi de la fiabilité des systèmes d’IA et d’amélioration continue de l’efficacité des modèles.
Collaboration avec l’équipe de développement et d’exploitation : définir les besoins en matière d’infrastructure, dont les besoins matériels et logiciels, pour soutenir les solutions d’IA.
Optimisation des flux de travail : travailler avec les parties prenantes pour améliorer les flux de travail alimentés par l’IA aux fins d’une automatisation et d’une efficacité optimales.
Définition des récits d’utilisateur et des besoins : consigner les besoins techniques et les récits d’utilisateur pour guider l’équipe d’ingénierie dans le développement des solutions.

CE DONT VOUS AUREZ BESOIN :
Expertise en IA et en traitement automatique du langage naturel (TALN) : minimum de trois ans d’expérience avec les GML, la traduction automatique et les solutions alimentées par l’IA.
Apprentissage machine : très bonne connaissance des opérations d’apprentissage machine pour établir et gérer le pipeline d’apprentissage machine propre à chaque cas d’utilisation.
Bagage technique : très bonne connaissance des méthodes d’entraînement, de mise au point et de mise en œuvre des modèles d’IA.
Évaluation des modèles d’IA : expérience dans la mise en place et l’évaluation de modèles d’IA aux fins d’un rendement en tout temps conforme aux normes.
Expérience en intégration : expérience pratique dans l’intégration de solutions d’IA aux plateformes existantes en recourant à des API et à des scripts d’automatisation.
Analyse des données et du rendement : capacité à analyser le rendement des modèles, à optimiser les ensembles de données et à mettre en œuvre des améliorations continues.
Collaboration et communication : grande capacité à travailler de façon interfonctionnelle avec des équipes techniques et non techniques pour l’élaboration et l’exécution de stratégies d’IA.
Aptitudes en résolution de problèmes : compétences en résolution de problèmes liés à l’IA et en optimisation du rendement aux fins d’extensibilité.

CE POSTE POURRA VOUS CONVENIR SI VOUS :
avez de l’expérience avec des cadres d’applications IA comme TensorFlow, PyTorch, Hugging Face, Azure, OpenAI API ou des boîtes à outils d’IA similaires;
êtes au fait des pratiques de développement et d’exploitation aux fins de mise en œuvre de l’IA (opérations d’apprentissage machine, infrastructures d’IA en nuage, etc.);
maîtrisez les méthodes Agile et Scrum et des outils comme Jira et Confluence;
comprenez l’éthique de l’IA et les stratégies d’atténuation des biais;
connaissez le secteur de la localisation ou de la gestion de contenus;
maîtrisez les outils et les systèmes comme Python, les systèmes de gestion de la traduction, les outils de traduction assistée par ordinateur (TAO) et les flux de gestion de contenus et de localisation.

POURQUOI POSTULER?
Pour travailler dans un environnement où se côtoient IA et systèmes de gestion de contenus et façonner l’avenir des services de gestion de contenus.
Pour joindre une équipe dynamique et novatrice qui développe des solutions d’IA de pointe.
Pour participer à la création de flux de travail alimentés par l’IA de grandes organisations internationales.",[]
Ingénieur(e) en Intelligence Artificielle/ AI Engineer,Potloc,"Montreal, Quebec, Canada",Hybrid,"About the job
English version below 

A PROPOS DE POTLOC 

Grâce à Potloc, les plus grands cabinets de conseil et fonds de capital-investissement au monde transforment les enquêtes en informations stratégiques. Notre plateforme d’enquête complète est conçue pour être l’outil le plus rapide et fiable afin de comprendre les dynamiques du marché.

Avec une qualité d’échantillonnage inégalée, une analyse propulsée par l’IA et une gestion complète de la recherche, nous offrons à nos clients un avantage concurrentiel.

Depuis 2014, nous avons aidé plus de 500 entreprises internationales à collecter des données dynamiques à partir de plus de 343 millions de réponses B2B et B2C, couvrant tous les secteurs et régions.

Opérant à un niveau international, nous avons des bureaux en Amérique du Nord et en Europe!

Nous encourageons l’évolution de carrière et accompagnons nos équipes à travers nos 4 valeurs fondamentales: Excellence, Travail d'équipe, Honnêteté & Adaptabilité.

Êtes-vous prêt à rejoindre notre équipe ? On a vraiment hâte de faire votre connaissance !

LA MISSION

Nous recherchons un(e)  Ingénieur(e) en Intelligence Artificielle passionné(e) pour rejoindre notre équipe Data et contribuer activement au développement, au déploiement et à l’optimisation de fonctionnalités alimentées par l’IA.

Le/la candidat(e) idéal(e) possède une solide expertise en apprentissage automatique, en infrastructure cloud et en ingénierie logicielle, avec un focus particulier sur le développement et l’optimisation de modèles d’IA au-delà des simples intégrations API. 

Ce rôle est essentiel pour faire progresser nos solutions propriétaires grâce au fine-tuning, à la modélisation sur mesure et à la gestion de la propriété intellectuelle.

Au sein de notre  équipe Data — composée d’analystes BI, d’ingénieures data et DevOps — vous collaborerez étroitement avec les équipes d’ingénierie logicielle, de DevOps et de gestion produit  afin de concevoir, optimiser et déployer des modèles d’IA de pointe.

Ce poste offre une opportunité unique d’élargir votre expertise tout en jouant un rôle clé dans la construction de l’avenir de l’IA chez Potloc. Vous serez un moteur d’innovation, repoussant les frontières de l’IA, et développerez des solutions concrètes à fort impact .

VOS RESPONSABILITÉS 

 Concevoir, ajuster et déployer des fonctionnalités basées sur l’IA afin d’enrichir nos offres produits.
 Assurer la scalabilité et la disponibilité de nos services IA.
 Implémenter des workflows de versioning, monitoring et réentraînement des modèles selon les meilleures pratiques MLOps.
 Développer une infrastructure efficace et évolutive pour l’inférence de modèles (via APIs ou traitements asynchrones).
 Collaborer avec l’équipe Infrastructure pour renforcer notre stack d’observabilité (Cloudwatch, Sentry, Elastic) afin de suivre les performances des modèles, tout en garantissant leur adoption par les utilisateurs.
 Maintenir une documentation claire et complète des modèles IA, de l’architecture et des workflows afin d’ assurer transparence et reproductibilité.

LES QUALITÉS REQUISES 

Techniques

 3+ ans d’expérience en ingénierie IA/ML , avec un focus sur le développement, le fine-tuning et le déploiement de modèles.
 Maîtrise de Python et des frameworks comme PyTorch, TensorFlow ou Hugging Face.
 Expérience en fine-tuning et déploiement de LLMs (OpenAI, Gemini, Llama, etc.) ainsi que des techniques associées ( RAG, quantization, RLHF ).
 Bonne connaissance d’AWS et de ses services (SageMaker, Bedrock, EC2, Lambda, S3).
 Solides bases en ingénierie data (pré-traitement, feature engineering, pipelines).
 Atout : expérience avec bases vectorielles et RAG. 

 Soft Skills 

 Esprit analytique, autonome et orienté vers la résolution de problèmes.
 Aisance en travail collaboratif (Ingénieur Data, BI, DevOps).
 Curiosité et veille continue sur les avancées en IA.
 Capacité à vulgariser des concepts complexes d’IA 
 Maîtrise de l’anglais (le français est un plus).

POURQUOI NOUS REJOINDRE? 

📈 Une entreprise dynamique avec des objectifs ambitieux, un fort esprit d’équipe et un environnement stimulant où chacun peut contribuer au succès collectif

💸 Un package salarial compétitif, comprenant des stocks options, pour vous associer à notre réussite

📊 Un parcours de carrière structuré, avec des évaluations de performance tous les 6 mois pour vous accompagner dans votre développement

🌞 Un espace de travail moderne et rénové, lumineux et collaboratif, au cœur du Mile-End

🏡 Politique de travail hybride flexible, avec la possibilité de travailler jusqu’à 2 mois par an depuis l’étranger

🏖 4 semaines de vacances et 5 journées personnelles

📅 Jours de congé supplémentaires pour des évènements importants de votre vie (déménagement, naissance, mariage, etc.).

🏥 Une couverture santé compétitive, pour vous et votre famille, afin de garantir votre bien-être au quotidien

PROCESSUS DE RECRUTEMENT 

 Entretien téléphonique avec l’équipe Talent (30 min)
 Entretien avec le Directeur Data (45 min)
 Test à domicile + présentation au bureau (60 min)
 Entretien de fit avec l’équipe (30 min)
 Offre d’embauche 🙌

ABOUT POTLOC 

The world’s consulting and private equity powerhouses turn survey questions into strategic revelations with Potloc. Our all-in survey platform is designed to be the fastest, most reliable asset for understanding market shifts.

With unrivaled sample quality, AI-powered analysis, and end-to-end research oversight, it all adds up to a competitive advantage.

Since 2014, we’ve helped 500+ global firms collect dynamic insights from 343M+ B2B and B2C responses across industries and geographies.

Our team is dedicated to being the best end-to-end service provider for our clients globally. To do this, we have offices in North America and Europe!

We encourage professional development and provide support to our teams through our 4 core values: Excellence, Teamwork, Honesty & Adaptability.

THE MISSION

We are looking for a passionate AI Engineer to join our Data team and drive the development, deployment, and optimization of AI-powered features. The ideal candidate has strong expertise in machine learning, cloud infrastructure, and software engineering, with a focus on developing and optimizing AI models beyond API integrations .

This role is pivotal in advancing our proprietary AI solutions through fine-tuning, custom modeling, and ownership of intellectual property.

As part of our Data team , which includes BI Analysts, Data Engineers, and DevOps professionals, you will collaborate closely with Software Engineering, DevOps, and Product Management to build, optimize, and deploy cutting-edge AI models.

Based in Montreal, this role offers a unique opportunity to expand your expertise while actively shaping the future of AI at Potloc. You will play a key role in driving innovation , pushing the boundaries of AI capabilities, and developing impactful AI-powered solutions that make a real difference.

YOUR RESPONSIBILITIES

 Design, fine-tune and deployAI-powered features to enhance our product offerings
 Ensure the scalability and availability of our AI services.
 Implement model versioning, monitoring, and retraining workflows, following best MLOps practices.
 Build infrastructure for scalable and efficient model inference , including API-based and asynchronous processing systems.
 Collaborate with the Infrastructure Development team to strengthen our observability stack (Cloudwatch, Sentry, Elastic) to continuously evaluate our models' performance and ensure user adoption.
 Maintain comprehensive documentation of AI models, architecture, and workflows to ensure transparency and reproducibility.

REQUIRED SKILLS

Technical Skills

 3+ years of experience in AI/ML engineering , with a strong focus on model development, fine-tuning, and deployment.
 Strong programming skills in Python . Experience with frameworks such as PyTorch, TensorFlow, or Hugging Face Transformers.
 Experience with fine-tuning and deploying LLMs (e.g., OpenAI, Gemini, Llama, Falcon, Mistral) and leveraging techniques such as RAG, quantization, reinforcement learning from human feedback ( RLHF ).
 Hands-on experience with cloud platforms (AWS preferred) and services such as SageMaker, Bedrock, EC2, Lambda, and S3.
 Knowledge of data engineering best practices, including data preprocessing, feature engineering, and pipeline automation.
 Experience working with vector databases and retrieval-augmented generation (RAG) is a plus.

 Soft Skills 

 Problem-solving mindset with the ability to work autonomously and handle complex challenges.
 Strong collaboration skills , with experience working cross-functionally with Data Engineers, BI Analysts, and DevOps teams.
 A continuous learning mindset , staying up to date with AI advancements and best practices.
 Ability to communicate complex AI concepts to non-technical stakeholders.
 Fluent in English (French is a plus).

WHAT’S IN IT FOR YOU

📈 A dynamic company with ambitious goals, a strong team spirit, and a stimulating environment where everyone can contribute to collective success

💸 A competitive salary package, including stock options, to allow you to share in our success

📊 A structured career path, with performance evaluations every 6 months to support your development

🌞 A modern, renovated, bright, and collaborative workspace, located in the heart of Mile-End

🏡 A flexible hybrid work policy, with the possibility to work up to 2 months per year from abroad.

🏖 4 weeks of vacation and 5 personal days

📅 Additional leave for key moments in your life (moving, childbirth, marriage, etc.)

🏥 A comprehensive health coverage plan, for you and your family, to ensure your well-being every day

RECRUITMENT PROCESS

 Phone interview with HR (30 min)
 Interview with Data Director (45 min)
 Take home test and presentation in office (60 min)
 Team fit (3060 min)
 Job Offer 🙌

Politique de confidentialité des candidats / Candidate Privacy Notice ⬇️

En postulant, vous acceptez que Potloc traite vos données personnelles comme décrit dans leur  Politique de Confidentialité des Candidats , notamment pour rechercher et identifier des profils pertinents, présélectionner les candidats, évaluer leur adéquation aux postes, et mesurer leurs compétences professionnelles. Potloc partagera vos informations avec d'autres entités de Potloc, des prestataires de services tiers, et d'autres destinataires autorisés, y compris en dehors de votre région. Vous pouvez contacter Potloc à tout moment pour exercer vos droits ou pour toute autre question.



By applying, you agree to Potloc processing your personal data as described in their  Candidate Privacy Notice , particularly to search and identify relevant profiles, pre-select candidates, assess suitability for job roles, and measure professional skills. Potloc will disclose your information to other Potloc entities, third-party services providers, and other authorized recipients, including outside of your region. You may contact Potloc at any time to exercise your rights or for any other questions.

RESSOURCES

Our website

Candidate Handbook

Potloc | Glassdoor

Welcome to the jungle page

Potloc raises 35 million

Forbes 30 Under 30

Potloc named Winner of Deloitte's Technology Fast 50 Program",[]
"Sr. ML Compiler Engineer, AWS Neuron, Annapurna Labs",Amazon Web Services (AWS),,,"About the job
Description

The Annapurna Labs team at Amazon Web Services (AWS) builds AWS Neuron, the software development kit used to accelerate deep learning and GenAI workloads on Amazon’s custom machine learning accelerators, Inferentia and Trainium.

The Product: The AWS Machine Learning accelerators (Inferentia/Trainium) offer unparalleled ML inference and training performances. They are enabled through state-of-the-art software stack - the AWS Neuron Software Development Kit (SDK). This SDK comprises an ML compiler, runtime, and application framework, which seamlessly integrate into popular ML frameworks like PyTorch. AWS Neuron, running on Inferentia and Trainium, is trusted and used by leading customers such as Snap, Autodesk, and Amazon Alexa.

The Team: Annapurna Labs was a startup company acquired by AWS in 2015, and is now fully integrated. If AWS is an infrastructure company, then think Annapurna Labs as the infrastructure provider of AWS. Our org covers multiple disciplines including silicon engineering, hardware design and verification, software, and operations. AWS Nitro, ENA, EFA, Graviton and F1 EC2 Instances, AWS Neuron, Inferentia and Trainium ML Accelerators, and in storage with scalable NVMe, are some of the products we have delivered over the last few years.

Within this ecosystem, the Neuron Compiler team is developing a deep learning compiler stack that takes state of the art LLM, Vision, and multi-modal models created in frameworks such as TensorFlow, PyTorch, and JAX, and makes them run performantly on our accelerators. The team is comprised of some of the brightest minds in the engineering, research, and product communities, focused on the ambitious goal of creating a toolchain that will provide a quantum leap in performance.

The Neuron team is hiring systems and compiler engineers in order to solve our customers toughest problems. Specifically, the performance team in Toronto is focused on analysis and optimization of system-level performance of machine learning models on AWS ML accelerators. The team conducts in-depth profiling and works across multiple layers of the technology stack - from frameworks and compilers to runtime and collectives - to meet and exceed customer requirements while maintaining a competitive edge in the market. As part of the Neuron Compiler organization, the team not only identifies and implements performance optimizations but also works to crystallize these improvements into the compiler, automating optimizations for broader customer benefit.

This is an opportunity to work on innovative products at the intersection of machine-learning, high-performance computing, and distributed architectures. You will architect and implement business-critical features, publish innovative research, and mentor a brilliant team of experienced engineers. We operate in spaces that are very large, yet our teams remain small and agile. There is no blueprint. We're inventing. We're experimenting. It is a very unique learning culture. The team works closely with customers on their model enablement, providing direct support and optimization expertise to ensure their machine learning workloads achieve optimal performance on AWS ML accelerators.

Explore the product and our history!

https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-cc/index.html

https://aws.amazon.com/machine-learning/neuron/

https://github.com/aws/aws-neuron-sdk

https://www.amazon.science/how-silicon-innovation-became-the-secret-sauce-behind-awss-success

Key job responsibilities

Role

Our performance engineers collaborate across compiler, runtime, and framework teams to optimize machine learning workloads for our global customer base. Working at the intersection of machine learning, high-performance computing, and distributed systems, you'll bring a passion for performance analysis, distributed systems, and machine learning. In this role, you will:

 Analyze and optimize system-level performance of machine learning models across the entire technology stack, from frameworks to runtime
 Conduct detailed performance analysis and profiling of ML workloads, identifying and resolving bottlenecks in large-scale ML systems
 Work directly with customers to enable and optimize their ML models on AWS accelerators, understanding their specific requirements and use cases
 Design and implement compiler optimizations, transforming manual performance improvements into automated compiler passes
 Collaborate across teams to develop innovative optimization techniques that enhance AWS Neuron SDK's performance capabilities
 Work in a startup-like development environment, where you’re always working on the most important stuff

A day in the life

As You Design And Code Solutions To Help Our Team Drive Efficiencies In Software Architecture, You’ll Create Metrics, Implement Automation And Other Improvements, And Resolve The Root Cause Of Software Defects. You’ll Also

Build high-impact solutions to deliver to our large customer base.

Participate in design discussions, code review, and communicate with internal and external stakeholders.

Work cross-functionally to help drive business decisions with your technical input.

Work in a startup-like development environment, where you’re always working on the most important stuff.

About The Team

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge-sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects that help our team members develop your engineering expertise so you feel empowered to take on more complex tasks in the future.

Diverse Experiences

AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.

About AWS

Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture

Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.

Work/Life Balance

We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.

Mentorship & Career Growth

We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Basic Qualifications

 5+ years of non-internship professional software development experience
 5+ years of programming with at least one software programming language experience
 5+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
 Experience as a mentor, tech lead or leading an engineering team

Preferred Qualifications

 5+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
 Bachelor's degree in computer science or equivalent
 Experience in compiler design for CPU/GPU/Vector engines/ML-accelerators.
 Experience with System Level performance analysis and optimization
 Experience with LLVM and/or MLIR
 Experience with the following technologies: PyTorch, OpenXLA, StableHLO, JAX, TVM, deep learning models, and algorithms.

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - Amazon Development Centre Canada ULC

Job ID: A3008849",[]
Machine Learning Engineer - Enterprise,Boson AI,,,"About the job
About Boson AI: At Boson AI, we are not just building AI solutions; we are pioneering the future of enterprise AI. Driven by a passion for cutting-edge AI research, particularly in the transformative areas of large language models and agentic systems, our mission is to tackle the most complex real-world problems for businesses and unlock significant value. We are a dynamic and collaborative team of researchers and engineers who thrive on pushing the boundaries of what's possible, dedicated to delivering high-quality, reliable products that seamlessly integrate into the fabric of enterprise workflows and set new industry standards.

About the Role: We are seeking a skilled, detail-oriented, and passionate Machine Learning Engineer to join our enterprise team. In this pivotal role, you will be at the forefront of developing and deploying groundbreaking AI solutions. This involves integrating advanced language/voice/vision models, mastering fine-tuning techniques, building sophisticated workflows and platforms, and pioneering innovative agentic approaches. You will immerse yourself in challenging problems that demand a deep understanding of model behavior, meticulous implementation, and an unwavering commitment to quality and reliability in enterprise environments. A key and exciting aspect of this role is contributing to the architecture and implementation of intelligent systems where AI agents can perform complex tasks autonomously, interacting with diverse data sources and tools, as we collectively move towards building truly cohesive and powerful AI capabilities for our clients.

Responsibilities

Deliver solutions end to end that meet the needs of our customers - understanding user pain points, scoping product specs, and designing and building LLM-powered software
Benchmark the model, and help write evals for customers to identify model weaknesses
Develop and deploy modern search systems (e.g., RAG, DeepSearch) to enhance model performance, grounding, and the ability to utilize enterprise-specific knowledge
Implement and optimize techniques for fine-tuning and align large models on domain-specific data
Ensure the quality, reliability, security, and scalability of models and agentic systems through meticulous attention to detail, diligent execution, and continuous monitoring in demanding enterprise settings
Integrate individual AI components into a scalable platform



Qualifications

Bachelor's or Master's degree in Computer Science, Machine Learning, Artificial Intelligence, or a related quantitative field, or equivalent practical experience
Strong contribution record on GitHub. Please include your GitHub link in your application
Experience working with large language or multimodal models and their applications
Experience implementing and working with search systems
Proven ability to pay close attention to detail and prioritize quality, reliability, and security in technical work
Proficiency in programming languages (e.g., Python, Rust, TypeScript or Go) and relevant ML frameworks (e.g., PyTorch, JAX)
Demonstrated ability to design, chain, or orchestrate multiple models (especially LLMs) to create multi-step pipelines or workflows for task automation



Bonus Points

Experience developing or contributing to agentic AI products or systems
Experience with cloud platforms (AWS, GCP, Azure) and MLOps practices
Familiarity with distributed training and inference techniques
Experience with system design, API development, and building scalable infrastructure for deploying and managing AI models or agentic systems
Understanding of enterprise software integration patterns and data security considerations
Solid understanding of HTTP protocol and real-time communication protocols (e.g., WebRTC) for voice AI. 
Excellent problem solving skills
Ability to work independently and drive projects forward in a fast-paced environment",[]
Machine Learning Engineer,Valence,"Toronto, ON",Hybrid,"About the job
Valence has built the first-to-market AI native coaching platform for enterprise, offering personalized, expert, and human-like guidance & support to any leader or employee. At Valence, we're not just talking about the future of work – we're actively shaping it.

From your first interaction with us, you'll notice we're different. By working here you won't just implement solutions for our clients; you'll be helping to architect the future of leadership in the age of generative AI. And we'll be honest – this is not for everyone. But for those with an insatiable desire to work fast on complex, unsolved challenges with some of the best talent in tech, this could be the career-defining opportunity you've been waiting for.

The Role

This role is a Machine Learning Engineer role for our conversational AI coaching product designed for Fortune 500 enterprises, reporting into our Head of AI. In this role you will implement, and optimize machine learning models that power our coaching insights and recommendations. This role is focused on the development and optimization of machine learning models and algorithms, optimizing the underlying ML infrastructure and model development. This role will directly impact our product's core and shape the future of AI-driven leadership coaching for Fortune 500 enterprises.

About Valence

We're a Series A B2B SaaS company, backed by Insight Partners, that's pioneering the first generative AI leadership coach for large enterprises. Our mission is to transform how the world's biggest companies approach learning and development, helping teams work better together. We've been featured in Harvard Business Review, and our client list reads like a Who's Who of global business, including Coca-Cola, Nestlé, General Mills, ServiceNow, AstraZeneca, Prudential, Citi, CVS and Bristol Myers Squibb.

What You'll Do

You will develop scalable data pipelines, optimize models for performance and accuracy, and evaluate them to ensure they are production-ready. 
Develop, design and implement improvements in user experience in conversational interactions leveraging LLMs in new ways to advance product goals
Work with the product team to analyze user behavior and prioritize evolving requirements
Experiment at a high velocity, conducting statistical analyses, to optimize the end user experience 
Research and development on new Conversational AI approaches leveraging cutting edge LLM/NLP advancements
Documentation of models, prompts, and processes to increase replicability and drive quality improvements. 
Stay current with the latest leading research advancements in ML, LLMs, and Conversational AI
Support other coding and feature development where required


What We're Looking For

Bachelor's degree in Computer Science, Engineering, Mathematics, related field, or equivalent experience
3+ years of professional experience (or equivalent) in software engineering, AI/ML development (ideally including a Master's or Ph.D. in Computer Science, ML, Data Science, or a related field)
Practical experience and theoretical knowledge of language technologies such as: dialogue/conversational systems, NLP, and Information Retrieval
Strong foundation in data structures, algorithms, and software engineering principles
Proficiency in Python and relevant deep learning frameworks; training (e.g. PyTorch, Tensorflow, JAX, Hugging Face Transformers/Adapters), serving (e.g., Hugging Face TGI//outlines, vLLM)
Experience with LLM model development and deployment ideally including experience with model distillation, supervised fine-tuning using RLHF/DPO, and automatic prompt tuning (e.g. DSPy, TextGrad) 
Experience with cloud deployment of ML systems (e.g., AWS, GCP, Azure) including and open systems (e.g. Docker and Kubernetes) and associated ML services
Strong analytical and problem-solving skills
Experience structuring and running data-backed experiments
Strong written and verbal communication skills
Exposure to early-stage startups, preferably B2B SaaS


What You'll Get

Ownership of projects and strategic priorities regardless of seniority
Strong ties to the executive team, a culture of transparency and engagement with strategic decisions
Options from day one, which means you will be on the ownership track right away
Competitive salary and equity packages
Comprehensive health coverage (medical, dental, and vision) from day 1
Provision of anything you need to be successful - learning tools, hardware, office equipment, software
Generous PTO, company-wide R&R shutdowns and paid leave for parents. 
A WFH stipend, phone stipend and support to work in a We Work or other space as preferred


Learn More About Us And Meet Our Team Here

Location and Work Environment

If candidates are based in NYC or Toronto they can work hybrid in our offices, otherwise this role can be remote. Candidates must be comfortable working with colleagues in different time zones (UK), and have valid travel documents without work authorization restrictions in the US.

Diversity and Inclusion

We are dedicated to creating a diverse and inclusive environment where everyone feels valued and supported. We encourage applications from candidates of all backgrounds and offer accommodations upon request throughout the hiring process. If you have any questions, please reach out to Allison Langille, Head of People, at jobs@valence.co.",[]
Machine Learning Engineer II - Core Experience,Instacart,Canada,Remote,"About the job
We're transforming the grocery industry

At Instacart, we invite the world to share love through food because we believe everyone should have access to the food they love and more time to enjoy it together. Where others see a simple need for grocery delivery, we see exciting complexity and endless opportunity to serve the varied needs of our community. We work to deliver an essential service that customers rely on to get their groceries and household goods, while also offering safe and flexible earnings opportunities to Instacart Personal Shoppers.

Instacart has become a lifeline for millions of people, and we’re building the team to help push our shopping cart forward. If you’re ready to do the best work of your life, come join our table.

Instacart is a Flex First team 

There’s no one-size fits all approach to how we do our best work. Our employees have the flexibility to choose where they do their best work—whether it’s from home, an office, or your favorite coffee shop—while staying connected and building community through regular in-person events. Learn more about our flexible approach to where we work.

Overview

Join Instacart’s mission to revolutionize the grocery industry through cutting-edge technologies. As a Machine Learning Engineer focused on Core Experience, you will help create seamless shopping experiences by leveraging advanced machine learning techniques to improve search relevance and discovery on Instacart's platform. This is an exciting opportunity to work on meaningful challenges at the intersection of AI and e-commerce, directly impacting how millions of users interact with the platform daily.

About The Role

We are seeking a highly motivated Machine Learning Engineer to join our Core Experience team. In this role, you’ll work alongside world-class engineers, data scientists, and product managers to shape the future of search technology at Instacart. You will collaborate on building models that enhance search relevance, ranking, and personalization, delivering highly relevant results to users across the Instacart ecosystem. This is a role where your contributions will not only drive immediate impact but also present exciting opportunities to showcase your work through publications and conferences (recent publications 1, 2, 3).

About The Team

The Core Experience ML team at Instacart is at the forefront of applying cutting-edge AI technologies, including large language models (LLMs), to revolutionize how customers find products. Working alongside world-class engineers, data scientists, and product managers, we're building sophisticated machine learning and AI systems that power the future of search and recommendations at Instacart. Our team leverages state-of-the-art transformer architectures, multimodal AI, and generative models to enhance the relevance across all shopping surfaces. We're constantly innovating with advanced neural retrieval methods, LLM-powered ranking algorithms, and AI-driven personalization systems that deliver highly contextual and intuitive results to users throughout the Instacart ecosystem. As part of our team, you'll tackle one of the most critical aspects of the business—helping customers connect with exactly the right products through AI. We're solving complex, large-scale search challenges using the latest in deep learning, natural language understanding, and LLM fine-tuning techniques to create intelligent systems that truly understand user intent and shopping behavior. Our commitment to AI innovation is reflected in our recent publications and research contributions to the field.

About The Job

Design, develop, and deploy advanced AI and machine learning solutions, including LLMs and neural networks, to solve complex challenges in our dynamic marketplace environment.
Architect and implement state-of-the-art deep learning systems that leverage transformer models, multimodal AI, and generative techniques to create intelligent, adaptive solutions.
Collaborate closely with product managers, data scientists, and backend engineers to translate business requirements into cutting-edge AI applications that deliver measurable impact.
Pioneer the application of foundation models, prompt engineering, and fine-tuning methodologies to create AI systems that understand context and user intent at unprecedented levels.
Engage with diverse stakeholders to ensure our AI solutions are ethically implemented, well-integrated with existing systems, and fully aligned with strategic business objectives.
Drive continuous innovation in our AI infrastructure by researching, testing, and implementing the latest advancements in machine learning, from embeddings and vector databases to reinforcement learning from human feedback (RLHF).
Push the boundaries of operational efficiency through intelligent automation, predictive modeling, and algorithmic optimization powered by our custom-trained AI systems.

About You

MINIMUM QUALIFICATIONS

Master’s degree in Computer Science, Machine Learning, or related fields
Strong programming skills in Python and fluency in data manipulation (SQL, Spark, Pandas) and machine learning (Pytorch, Tensorflow) tools
Strong analytical skills and problem-solving ability
Strong communicator who can collaborate with diverse stakeholders across all levels

Preferred Qualifications

3+ years of experience building and deploying machine learning models in production environments
PhD in Machine Learning, Artificial Intelligence, or related fields
Previous experience working on search or recommendation systems at scale
Strong publication track record in top-tier AI/ML conferences
Familiarity with A/B testing and experimentation methodologies for search relevance improvement

Instacart provides highly market-competitive compensation and benefits in each location where our employees work. This role is remote and the base pay range for a successful candidate is dependent on their permanent work location. Please review our Flex First remote work policy here. Currently, we are only hiring in the following provinces: Ontario, Alberta, British Columbia, and Nova Scotia.

Offers may vary based on many factors, such as candidate experience and skills required for the role. Additionally, this role is eligible for a new hire equity grant as well as annual refresh grants. Please read more about our benefits offerings here.

For Canadian based candidates, the base pay ranges for a successful candidate are listed below.

CAN

$153,000—$170,000 CAD",[]
Senior Chatbot LLM Engineer,SEW-Eurodrive Canada,,,"About the job
Location: This is an in-person position based in Vaughan, Ontario, with occasional travel to our Brampton facility and our Headquarters in Bruchsal Germany.
Division: Innovation Hub Canada – Innovation Services

About Us

At SEW-EURODRIVE, we are shaping the future of automated manufacturing through cutting-edge drive technology and intelligent automation solutions. Our global Innovation Hubs are at the forefront of digital transformation, delivering scalable, high-impact solutions that enhance operational efficiency and productivity. We foster a culture of creativity, collaboration, and technical excellence.

Position Overview

We are seeking a highly skilled Senior Chatbot LLM Engineer to design, develop, and optimize AI-powered chatbot solutions using Large Language Models (LLMs). In this role, you will work closely with cross-functional teams to enhance conversational AI capabilities, improve user interactions, and integrate intelligent solutions across various platforms. Your work will directly contribute to SEW’s digital transformation and customer experience strategies.
 Key Responsibilities

Design, develop, and deploy LLM-based chatbots for customer support, automation, and conversational AI applications.
Optimize chatbot performance using prompt engineering, fine-tuning, and reinforcement learning techniques.
Implement advanced Natural Language Processing (NLP) algorithms to improve contextual understanding and response accuracy.
Participate in AI architecture design decision processes.
Integrate chatbots with third-party APIs, databases, and enterprise systems.
Conduct A/B testing and performance evaluations to continuously improve chatbot efficiency and user satisfaction.
Collaborate with UX designers, product managers, and data scientists to refine conversational flows and user experiences.
Stay current with the latest advancements in LLMs, NLP, and AI technologies to drive innovation.
 Qualifications

· Bachelor’s or Master’s degree in Computer Science, Artificial Intelligence, or a related field.
· Strong programming skills and hands-on experience with LLM frameworks (e.g., OpenAI, Hugging Face, LangChain).
· Expertise in NLP, machine learning, and deep learning techniques.
· Experience with enterprise-grade contact-center automation platforms.
· Familiarity with multi-turn dialogue systems and reinforcement learning for chatbot training.
· Knowledge of speech-to-text and text-to-speech technologies.
· Proficiency in Python or SQL for advanced data analysis and model integration.
· Understanding of ethical AI principles and bias mitigation in LLMs.
· Strong problem-solving skills and a passion for building AI-driven solutions.
· Hands-on experience with regional conversation style finetuning in genAI context.
· Excellent communication and collaboration skills, especially in agile and cross-functional environments.
 What We Offer

· Competitive salary and comprehensive benefits package
· Opportunities for career growth and professional development
· A collaborative, innovative, and inclusive work environment
· Exposure to global projects and cutting-edge technologies",[]
Senior Machine Learning Engineer,Replicant,Canada,Remote,"About the job
At Replicant, we believe AI should work for people, starting with customer service. That’s why we built a platform that helps contact centers resolve more requests, proactively identify issues, and improve agent performance with AI-powered conversation intelligence and AI agents that act like your best reps.

Our AI agents handle millions of calls every month for Fortune 500 companies and high-growth innovators. From processing payments to booking appointments and authenticating users, they help customers get what they need instantly, 24/7. Meanwhile, our real-time conversation insights help contact center leaders coach better and improve every interaction.

We’re leading the shift from legacy systems to AI-first service, powered by large language models (LLMs)and designed for enterprise scale, security, and empathy. If you’re excited by the potential of LLMs, voice AI, and building category-defining technology with a kind, ambitious team, you’ll love it here.

The Machine Learning team empowers enterprise customers and developers on Replicant’s platform to help create delightful conversations that provide fast and effective resolutions to their clients through contact center automation. We define and build the next generation of bot building paradigms for complex enterprise customer service and contact center automation scenarios. You will be part of a cross-functional group of engineers that are applying the latest research in Generative AI and NLP - including LLMs and other advancements in research into our core product lines.

What You'll Do

Leading the exploration and application of Large Language Models and Generative AI, venturing into new areas within these fields 
Translating the latest research into high-performing systems and models that can be practically applied to enhance user experiences 
Help set the team's strategic direction, cultivating an environment that encourages innovation and professional growth
Actively engaging in all aspects of development, from ideation and experimentation to implementation and deployment
Collaborating with various teams and product managers to develop and implement ML based solutions, ensuring performance optimization and alignment with broader business goals

What You'll Bring

5+ years of software development experience in ML infra, ML tooling, or products with ML usage
Preferred if experienced with the ML ecosystem (e.g. python, pytorch, faiss, elastic search)
Excellent communication skills and a vivid imagination
Passion about engineering and team culture
You love tackling ambiguous technical problems and developing solutions to problems with significant impact
You are an independent thinker and like to own and solve complex problems
You are interested in exploring the nuance and aesthetic of conversations

For All Full-time Employees, We Offer

🏠 Remote working environment that respects time zone differences

💸 Highly competitive salaries, equity, and for US Employees, a 401(k) plan

🏥 Top of the line healthcare (medical, vision, and dental)

🏋️ Health and Wellness Perk

🖥️ Equipment Stipend

🌴 Flexible vacation policy

✈️ Amazing team trips & offsites where you can find our CEO baking bread for the team

🌺 Replicants are eligible for a 5-week sabbatical after being at the company for 4.5 years

Our Values

Replicant has three core values. It is critical that everyone who joins the team feels excited and moved by these values as every new team member makes an impact on our culture.

Blade Runners: We take ownership and pride to influence the outcomes of our goals. We are successful, and like a Blade Runner, use the tools at our disposal to reach our objectives. We value open and honest communication and proactively seek feedback along the way. We are a company driven to grow and achieve both individually and as a team.

Bread Makers: We are humble and strive toward an egalitarian culture. No task is too big or too small. We work together to achieve our goals and develop our company mission. We believe that the whole is greater than the sum of its parts in everything that we do.

Självdistans (Self-Distance): Självdistans is Swedish for self-distance. It's the ability to critically reflect on oneself and one's relations from an external perspective. With this in mind, we act with objectivity and always remember that we are not our work. There's no perfect science to growing a team or business, but we trust everyone at Replicant to point out our blind spots and humbly admit their own.

Replicant is proud to be an equal opportunity employer. We are committed to fostering an inclusive, diverse and equitable workplace that is built on trust, support and respect. We welcome all individuals and do not discriminate on the basis of gender identity and expression, race, ethnicity, disability, sexual orientation, colour, religion, creed, gender, national origin, age, marital status, pregnancy, sex, citizenship, education, languages spoken or veteran status. Accommodation is available upon request at any point during our recruitment process. If you require an accommodation, please speak to your talent acquisition partner or email us at talent@replicant.ai and we’ll work to meet your needs.",[]
Senior Machine Learning Engineer - Insights,Cresta,,,"About the job
Cresta is on a mission to turn every customer conversation into a competitive advantage by unlocking the true potential of the contact center. Our platform combines the best of AI and human intelligence to help contact centers discover customer insights and behavioral best practices, automate conversations and inefficient processes, and empower every team member to work smarter and faster. Born from the prestigious Stanford AI lab, Cresta's co-founder and chairman is Sebastian Thrun, the genius behind Google X, Waymo, Udacity, and more. Our leadership also includes CEO, Ping Wu, the co-founder of Google Contact Center AI and Vertex AI platform, and co-founder, Tim Shi, an early member of Open AI.

Join us on this thrilling journey to revolutionize the workforce with AI. The future of work is here, and it's at Cresta.

About The Role

At Cresta, the Insights Team is dedicated to leveraging Large Language Models (LLMs) and AI techniques to extract actionable intelligence from conversations. We develop models and systems that analyze customer interactions, identify key topics, and provide structured insights that impact business outcomes. Our work enables organizations to make data-driven decisions and optimize customer experience through AI-powered exploration and interactive workflows.

A key focus of this role is developing agentic workflows that empower users to dynamically interact with AI-driven insights, refining and guiding the discovery process in an interactive and iterative manner. Additionally, this role will involve designing and implementing LLM evaluation frameworks to assess model performance, reliability, and usability in real-world applications. Our goal is to provide users with intelligent, context-aware AI agents that surface the most relevant insights and allow for deeper exploration of conversational data.

As a Machine Learning Engineer, you will be at the forefront of applying state-of-the-art NLP and LLM techniques to understand conversations at scale. Your work will focus on developing robust, scalable AI solutions that extract meaning, evaluate LLM effectiveness, and provide real-time insights to our customers through intuitive, agent-driven workflows.

Responsibilities

Build and optimize agentic AI workflows that enable users to dynamically explore and refine insights from conversational data.
Research and implement cutting-edge NLP and LLM-based approaches to extract meaningful insights from unstructured text data.
Develop LLM evaluation frameworks to assess accuracy, coherence, and usability of models in production environments.
Design, develop, and deploy machine learning models for conversation analysis, topic discovery, and structured insight generation.
Collaborate with UX designers, product managers, and engineers to integrate AI-driven insights into Cresta’s products.
Optimize ML pipelines to efficiently process conversational data at scale.

Qualifications We Value

Master’s or Ph.D. in Computer Science, Machine Learning, AI, or a related field.
5+ years of hands-on experience in NLP, LLMs, or agentic AI workflows in production settings.
Strong knowledge of ML frameworks and NLP libraries (e.g., PyTorch, TensorFlow, Hugging Face, spaCy, NLTK).
Strong passion for AI-driven innovation, outstanding work ethic, and high self-motivation to drive impactful solutions.
Experience with text analysis, embeddings, transformer-based architectures, and developing AI-driven, agentic workflows.

Perks & Benefits

We offer Cresta employees a variety of medical, dental, and vision plans, designed to fit you and your family’s needs
Paid parental leave to support you and your family
Monthly Health & Wellness allowance
Work from home office stipend to help you succeed in a remote environment
Lunch reimbursement for in-office employees 
PTO: 3 weeks in Canada 

Compensation for this position includes a base salary, equity, and a variety of benefits. Actual base salaries will be based on candidate-specific factors, including experience, skillset, and location, and local minimum pay requirements as applicable. We are actively hiring for this role in the US and Canada. Your recruiter can provide further details.

We have noticed a rise in recruiting impersonations across the industry, where scammers attempt to access candidates' personal and financial information through fake interviews and offers. All Cresta recruiting email communications will always come from the @cresta.ai domain. Any outreach claiming to be from Cresta via other sources should be ignored. If you are uncertain whether you have been contacted by an official Cresta employee, reach out to recruiting@cresta.ai",[]
Senior Machine Learning Engineer AI/RL,St-Amour,"Montreal, QC",Hybrid,"About the job
Our partner is a pioneer in AI-driven drug discovery and development, harnessing cutting-edge generative AI and deep learning technologies to accelerate the creation of novel therapeutics. Our Pharma.AI platform combines biology, chemistry, and clinical data to transform the drug discovery process from target identification and molecule generation to clinical trial optimization.
Join the team and help push the boundaries of AI in healthcare, bringing life-saving treatments to patients faster.

Role Overview
We are seeking a motivated Machine Learning Engineer/AI Developer to develop and optimize large language models (LLMs) for our Pharma.AI platform. This role focuses on building AI solutions tailored to the needs of biopharmaceutical partners, enabling faster drug discovery and collaborative R&D. You will work closely with cross-functional teams of AI researchers, scientists, and software engineers to deploy scalable, industry-leading AI tools.

Key Responsibilities
Design, train, and fine-tune LLMs for biomedical text analysis, knowledge extraction, and multi-modal data integration.
Collaborate with domain experts to translate pharma R&D challenges into AI-driven solutions (e.g., literature mining, target validation, predictive modeling).
Stay updated on SOTA LLM architectures (e.g., Transformer variants, retrieval-augmented models) and adapt them for biomedical use cases.
Optimize model performance for deployment in B2B environments, ensuring scalability, latency, and regulatory compliance.
Write clean, maintainable code and contribute to ML pipelines.
Participate in code reviews, model validation, and documentation.
Support the integration of LLMs into end-to-end Pharma.AI platform.

Qualifications
Education: PhD in Computer Science, Machine Learning, Bioinformatics, or related fields. Exceptional Master’s graduates with relevant experience will also be considered.
Technical Skills:
Strong understanding of LLM architectures (Transformer, BERT, GPT, etc.) and NLP techniques (tokenization, embeddings, attention mechanisms).
Proficiency in Python and ML frameworks (PyTorch, TensorFlow, JAX).
Experience with distributed training, model optimization, or LLM deployment is a plus.


Domain Knowledge:
Prior exposure to biomedical/healthcare data (e.g., scientific literature, clinical trials, omics) is highly preferred.
Familiarity with B2B AI product development cycles (requirement gathering, prototyping, enterprise deployment) is a strong advantage.
Mindset: Curiosity about AI-driven drug discovery, adaptability to fast-paced R&D, and a collaborative spirit.

Preferred Qualifications
Publications or projects in NLP/LLMs applied to life sciences.
Experience with cloud platforms (AWS, GCP) and containerization (Docker, Kubernetes).
Contributions to open-source ML projects.",[]
Senior Data Scientist,BDO Canada,"Halifax, NS",Remote,"About the job
Putting people first, every day

BDO is a firm built on a foundation of positive relationships with our people and our clients. Each day, our professionals provide exceptional service, helping clients with advice and insight they can trust. In turn, we offer an award-winning environment that fosters a people-first culture with a high priority on your personal and professional growth.

Your Opportunity

Innovation and Change team at BDO Canada is looking to onboard a Senior Data Scientist with the ability to work from anywhere in Canada. As a Data Scientist you will be responsible for collecting, analyzing, and interpreting large datasets to drive data-driven decision-making. In addition, you will collaborate with cross-functional teams & service lines to develop, enhance and implement ML predictive models, GEN AI, AI Agent solutions to facilitate in decision making, actionable insights thus achieving productivity and revenue gains and indirectly contributing to the organization's strategic goals.

Job Responsibilities:

Collect, clean, and transform large, complex datasets for analysis.
Build custom machine learning models and natural language processing systems using state-of-the-art techniques.
Leverage tools like TensorFlow, PyTorch, Kubernetes, and Nvidia Triton Servers to develop specialized large language models tailored to business needs.
Train, evaluate, and optimize models for accuracy, explainability, and ethical alignment.
Clearly communicate technical analysis and results to stakeholders using data visualizations, reports, and presentations.
Continuously monitor models and data pipelines in production to ensure quality and reliability.
Stay up to date on the latest advancements in deep learning, NLP, reinforcement learning, and other AI methods.


How do we define success for your role?

You demonstrate BDO's core values through all aspect of your work: Integrity, Respect and Collaboration
You understand your client’s industry, challenges, and opportunities; client describe you as positive, professional, and delivering high quality work
You identify, recommend, and are focused on effective service delivery to your clients
You share in an inclusive and engaging work environment that develops, retains and attracts talent
You actively participate in the adoption of digital tools and strategies to drive an innovative workplace
You grow your expertise through learning and professional development 


Your Experience And Education

M.S. or Ph.D. in Computer Science, Data Science, or related quantitative field.
5+ years’ experience in building and deploying machine learning models in a production environment.
Expertise in Python data science libraries like Pandas, matplotlib, NumPy, and Scikit-Learn.
Proficiency in programming languages such as Python, R, or Scala. Experience with SQL and NoSQL databases is essential.
Knowledge graph
Use Git for version control and collaborative development, ensuring all code is well-documented and follows best practices.
Experience training custom transformer models like Llama and Mistral.
Knowledge of cloud platforms like Azure, AWS, or GCP for model deployment.
Strong verbal and written communication skills.
Passion for translating complex data into actionable insights.


Why BDO?

Our people-first approach to talent has earned us a spot among Canada’s Top 100 Employers for 2025. This recognition is a milestone we’re thrilled to add to our collection of awards for both experienced and student talent experiences.

Our firm is committed to providing an environment where you can be successful in the following ways:

We enable you to engage with how we change and evolve, being a key contributor to the success and growth of BDO in Canada. 
We help you become a better professional within our services, industries, and markets with extensive opportunities for learning and development. 
We support your achievement of personal goals outside of the office and making an impact on your community.


Giving back adds up: Where company meets community. BDO is actively involved in our communities by supporting local charity initiatives. We support staff with local and national events where you will be given the opportunity to contribute to your community.

Total rewards that matter: We pay for performance with competitive total cash compensation that recognizes and rewards your contribution. We provide flexible benefits from day one, and a market leading personal time off policy. We are committed to supporting your overall wellness beyond working hours and provide reimbursement for wellness initiatives that fit your lifestyle.

Everyone counts: We believe every employee should have the opportunity to participate and succeed. Through leadership by our Diversity, Equity and Inclusion Leader, we are committed to a workplace culture of respect, inclusion, and diversity. We recognize and celebrate the valuable differences among each of us, including race, religious beliefs, physical or mental disabilities, age, place of origin, marital status, family status, gender or gender identity and sexual orientation. If you require accommodation to complete the application process, please contact us.

Flexibility: All BDO personnel are expected to spend some of their time working in the office, at the client site, and virtually unless accommodations or alternative work arrangements are in place.

Our model is a blended approach designed to support the flexible needs of our people, the firm and our clients. It’s about creating work experiences that meet everyone’s needs and providing flexibility to adjust when, where and how we work to meet the expectations of our role.

Code of Conduct: Our Code of Conduct sets clear standards for how we conduct business. It reflects our shared values and commitments and includes guiding principles to help us make ethical decisions and maintain trust with each other, our clients, and the public.

With your consent, BDO Canada may use AI technology (Microsoft Copilot) to transcribe during preliminary conversations, solely for the purpose of note-taking and not for other purposes, such as resume review, evaluation or selection of candidates.

More information on BDO Canada’s Privacy Policy can be found here: Privacy Policy | BDO Canada

Ready to make your mark at BDO? Click “Apply now” to send your up-to-date resume to one of our Talent Acquisition Specialists.

To explore other opportunities at BDO, check out our careers page.",[]
Research Engineer – Machine Learning,Huawei Canada,,,"About the job
Huawei Canada has an immediate 12-month contract opening for a Research Engineer. 

About the team:

The Human-Machine Interaction Lab unites global talents to redefine the relationship between humans and technology. Focused on innovation and user-centered design, the lab strives to advance human-computer interaction research. Our team includes researchers, engineers, and designers collaborating across disciplines to develop novel interactive systems, sensing technologies, wearable and IoT systems, human factors, computer vision, and multimodal interfaces. Through high-impact products and cutting-edge research, we aim to enhance user experiences and interactions with technology.

About the job:

Design, develop, train, evaluate, and optimize Machine Learning models, emphasizing on-device performance and efficiency
Implement Machine Learning algorithms from scratch or leverage existing libraries and frameworks (e.g., TensorFlow, PyTorch, scikit-learn, Keras)
Choose appropriate algorithms and techniques based on problem requirements, data characteristics, and business needs
Enhance model performance through feature engineering, selection, and transformation
Manage and process large datasets, including cleaning, pre-processing, and transformation
Build and maintain data pipelines for model training and inference
Work with data engineers to ensure data quality, availability, and scalability
Deploy Machine Learning models to production environments and maintain model retraining and versioning strategies

Job requirements

About the ideal candidate:

Ph.D. or Master's degree in Computer Science, Machine Learning, NLP, or a related field with a focus on Machine Learning
Minimum 3 years of Machine Learning research and development experience, with a strong portfolio of applied projects or publications
Proficiency in Machine Learning frameworks (e.g., TensorFlow, PyTorch)
On-device model deployment experience is highly valued
Experience contributing to relevant open-source projects is an asset
Experience building commercial agent/conversational systems is an asset",[]
Machine Learning Researcher - LLM/RAG,Huawei Canada,,,"About the job
Huawei Canada has an immediate 12-month contract opening for a Researcher.

About the team:

Founded in 2012, the Noah’s Ark lab has evolved into a prominent research organization with notable achievements in academia and industry. The lab’s mission focuses on advancing artificial intelligence and related fields to benefit the company and society. Driven by impactful, long-term projects, the aim is to enhance state-of-the-art research while integrating innovations into the company's products and services, including LLMs, RL, NLP, computer vision, AI theory, and Autonomous driving.

About the job:

Build the benchmark and testbed for advanced LLMs based on Transformer, Mamba.
Build the testbed for retrieval-augmented generation (RAG) and optimize the efficiency of the database system.
Work closely with the researchers, promptly implement and test the new algorithms and new architectures proposed by the researchers.
Research and develop innovative DL architecture and algorithms for large language models (LLM).
Contribute to the design, implementation, test, and maintenance of research and development frameworks.

Job requirements

About the ideal candidate:

Hold a Master or PhD (preferred) in computer science, software or electric engineering or related subjects.
Deep understanding of fundamentals and state-of-the-art techniques in NLP and ML.
Expertise in NLP using machine learning or deep learning.
Strong coding skills mainly in Python, with a focused expertise in PyTorch.
Excellent oral and written communication skills.
You are curious, like to think outside the box and appreciate complex challenges.",[]
"Member of Technical Staff, Model Serving Infrastructure",Cohere,"Toronto, ON",Hybrid,"About the job
Who are we?

Our mission is to scale intelligence to serve humanity. We’re training and deploying frontier models for developers and enterprises who are building AI systems to power magical experiences like content generation, semantic search, RAG, and agents. We believe that our work is instrumental to the widespread adoption of AI.

We obsess over what we build. Each one of us is responsible for contributing to increasing the capabilities of our models and the value they drive for our customers. We like to work hard and move fast to do what’s best for our customers.

Cohere is a team of researchers, engineers, designers, and more, who are passionate about their craft. Each person is one of the best in the world at what they do. We believe that a diverse range of perspectives is a requirement for building great products.

Join us on our mission and shape the future!

Why this role?

Are you energized by building high-performance, scalable and reliable machine learning systems? Do you want to help define and build the next generation of AI platforms powering advanced NLP applications? We are looking for Members of Technical Staff to join the Model Serving team at Cohere. The team is responsible for developing, deploying, and operating the AI platform delivering Cohere's large language models through easy to use API endpoints. In this role, you will work closely with many teams to deploy optimized NLP models to production in low latency, high throughput, and high availability environments. You will also get the opportunity to interface with customers and create customized deployments to meet their specific needs.

You May Be a Good Fit If You Have

5+ years of engineering experience running production infrastructure at a large scale
Experience designing large, highly available distributed systems with Kubernetes, and GPU workloads on those clusters
Experience with Kubernetes dev and production coding and support
Experience with GCP, Azure, AWS, OCI, multi-cloud on-prem / hybrid serving 
Experience in designing, deploying, supporting, and troubleshooting in complex Linux-based computing environments
Experience in compute/storage/network resource and cost management
Excellent collaboration and troubleshooting skills to build mission-critical systems, and ensure smooth operations and efficient teamwork
The grit and adaptability to solve complex technical challenges that evolve day to day
Familiarity with computational characteristics of accelerators (GPUs, TPUs, and/or custom accelerators), especially how they influence latency and throughput of inference.
Strong understanding or working experience with distributed systems.
Experience in Golang, C++ or other languages designed for high-performance scalable servers).

If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply! If you want to work really hard on a glorious mission with teammates that want the same thing, Cohere is the place for you.

We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants from all backgrounds and are committed to providing equal opportunities. Should you require any accommodations during the recruitment process, please submit an Accommodations Request Form, and we will work together to meet your needs.

Full-Time Employees At Cohere Enjoy These Perks

🤝 An open and inclusive culture and work environment

🧑‍💻 Work closely with a team on the cutting edge of AI research

🍽 Weekly lunch stipend, in-office lunches & snacks

🦷 Full health and dental benefits, including a separate budget to take care of your mental health

🐣 100% Parental Leave top-up for 6 months for employees based in Canada, the US, and the UK

🎨 Personal enrichment benefits towards arts and culture, fitness and well-being, quality time, and workspace improvement

🏙 Remote-flexible, offices in Toronto, New York, San Francisco and London and co-working stipend

✈️ 6 weeks of vacation

Note: This post is co-authored by both Cohere humans and Cohere technology.",[]
"Senior Member of Technical Staff, MLE",Cohere,"Toronto, ON",Hybrid,"About the job
Who are we?

Our mission is to scale intelligence to serve humanity. We’re training and deploying frontier models for developers and enterprises who are building AI systems to power magical experiences like content generation, semantic search, RAG, and agents. We believe that our work is instrumental to the widespread adoption of AI.

We obsess over what we build. Each one of us is responsible for contributing to increasing the capabilities of our models and the value they drive for our customers. We like to work hard and move fast to do what’s best for our customers.

Cohere is a team of researchers, engineers, designers, and more, who are passionate about their craft. Each person is one of the best in the world at what they do. We believe that a diverse range of perspectives is a requirement for building great products.

Join us on our mission and shape the future!

Why this role?

As a Senior Member of Technical Staff on our Applied ML team in NYC or SF, you will work directly with customers to quickly understand their greatest problems and design and implement solutions using Large Language Models.

You’ll apply your problem-solving ability, creativity, and technical skills to close the last-mile gap in Enterprise AI adoption. You’ll be able to deliver products like early startup CTOs/CEOs do and disrupt some of the most important industries and institutions globally!

As a Senior Member Of Technical Staff, You Will

Plan and execute large-group projects that carry through from ideation to production.
Bring cross-functional alignment across engineering, product and other disciplines. 
Mentor a distributed team of engineers in subject matter expertise. 
Identify opportunities and gaps in existing models and strategize what to work on.
Work closely with product teams to develop solutions.
Engage in collaborations with our partner organizations.
Assist our legal teams with preparation of patents on developed IP.
Join us at a pivotal moment, shape what we build and wear multiple hats!

You May Be a Good Fit If You Have

Prior experience in leading ML teams in applied research and production.
Prior experience in setting as well as executing technical direction to build new or to refine existing products.
Prior experience in working cross-discipline in matrixed organizations. 
Proficiency in Python and related ML frameworks such as Tensorflow, TF-Serving, JAX, and XLA/MLIR.
Experience using large-scale distributed training and inference.
Strong mentorship, communication, and problem-solving skills.
A demonstrated passion for applied ML models and products.
Bonus: experience working for B2B companies in the ML space. 
 This is neither an exhaustive nor necessary set of attributes. Even if none of these apply to you, but you believe you will contribute to Cohere, please reach out. We have a wide variety of backgrounds at Cohere.

If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply! If you want to work really hard on a glorious mission with teammates that want the same thing, Cohere is the place for you.

We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants from all backgrounds and are committed to providing equal opportunities. Should you require any accommodations during the recruitment process, please submit an Accommodations Request Form, and we will work together to meet your needs.

Full-Time Employees At Cohere Enjoy These Perks

🤝 An open and inclusive culture and work environment

🧑‍💻 Work closely with a team on the cutting edge of AI research

🍽 Weekly lunch stipend, in-office lunches & snacks

🦷 Full health and dental benefits, including a separate budget to take care of your mental health

🐣 100% Parental Leave top-up for 6 months for employees based in Canada, the US, and the UK

🎨 Personal enrichment benefits towards arts and culture, fitness and well-being, quality time, and workspace improvement

🏙 Remote-flexible, offices in Toronto, New York, San Francisco and London and co-working stipend

✈️ 6 weeks of vacation

Note: This post is co-authored by both Cohere humans and Cohere technology.",[]
"Senior Applied Scientist, Alexa Enterprise Products (AEP)",Amazon,,,"About the job
Description

Are you looking for an opportunity to build an LLM-based enterprise-grade, highly available, large scale solution? Does it excite you to find patterns and build generic, composable solutions to solve complex problems? Are you looking for inventing newer and simpler ways of building solutions? If so, we are looking for you to fill a challenging position in Alexa Enterprise (AE) team. AE brings the power of Alexa voice assistant to enterprise partners in industries such as hospitality and senior living. We tackle pressing challenges like workforce shortage. We are inventing Large Language Models (LLM)-driven interactions to create memorable moments for users while simultaneously boosting partner revenues and reinforcing brand identity. Beyond managed properties, AE extends Alexa's reach to premium third-party devices, seamlessly integrating with household names like Samsung, LG, and Sonos, thus amplifying its impact across diverse ecosystems.

AE team is looking for a passionate, highly skilled and inventive Senior Applied Scientist, with a strong machine learning background, to lead the development and implementation of state-of-the-art ML systems for Alexa Enterprise use cases.

As a Senior Applied Scientist in the team, you will play a critical role in driving the development of conversational assistants, in particular those based on Large Language Models (LLM's), that meet enterprise standards. You will handle Amazon-scale use cases with significant impact on our customers' experiences.

Key job responsibilities

 You will analyze, understand and improve user experiences by leveraging Amazon’s heterogeneous data sources and large-scale computing resources to accelerate advances in artificial intelligence
 You will work on core LLM technologies, including developing best-in-class modeling, prompt optimization algorithms to enable Conversation AI use cases
 Build and measure novel online & offline metrics for personal digital assistants and customer scenarios, on diverse devices and endpoints
 Create, innovate, and deliver deep learning, policy-based learning, and/or machine learning-based algorithms to deliver customer-impacting results
 Perform model/data analysis and monitor metrics through online A/B testing

Basic Qualifications

 3+ years of building machine learning models for business application experience
 PhD, or Master's degree and 6+ years of applied research experience
 Experience programming in Java, C++, Python or related language
 Experience with neural deep learning methods and machine learning

Preferred Qualifications

 Solid Machine Learning background and familiar with SOTA machine learning techniques

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

The base salary for this position ranges from $195,900/year up to $327,200/year. Salary is based on a number of factors and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. Applicants should apply via our internal or external career site.


Company - Amazon Development Centre Canada ULC - K03

Job ID: A3004104",[]
"Senior Research Scientist (Foundational Research, Machine Learning)",Thomson Reuters,"Toronto, ON",Hybrid,"About the job
Are you a curious and open-minded individual with an interest in state-of-the-art foundational machine learning research? Thomson Reuters Labs is seeking a Senior Research Scientist with a passion for solving challenging machine learning problems in a data-rich, complex academic environment.

What does Thomson Reuters Labs do? We experiment, we build, we deliver. We support the organization and our product teams through foundational research and development of new products and technologies. The Labs innovate collaboratively across our core segments in Legal, Tax & Accounting, Government, and Reuters News.  We undertake a diverse portfolio of projects while investing in long-term research for the future.

As a Senior Research Scientist, you will be part of a diverse global team of experts. We hire world-leading specialists in ML/NLP/GenAI, as well as Engineering, to drive the company’s leading internal AI model development, fueled by an unprecedented wealth of data and powered by state-of-the-art technical infrastructure. You will have the opportunity to publish your research findings as well as contribute to our proprietary AI model research & development. Thomson Reuters Labs is known for consistently delivering successful data-driven Artificial Intelligence solutions in support of high-growth products that serve Thomson Reuters customers in new and exciting ways.

About The Role 

In this opportunity, as Senior Research Scientist you will:

Innovate: You will have the opportunity to try new and/or innovate new ML/NLP/IR/GenAI approaches and enjoy mentoring by world-leading experts. You will contribute ideas and work on solving real-world challenges using a wealth of data not otherwise available. 

Experiment and Develop: You can be involved in the entire research & model development lifecycle, brainstorming, building, testing, and delivering high-quality reports at leading international academic conferences.

Collaborate: Working on a collaborative global team of research engineers both within Thomson Reuters and our academic patterns at world-leading universities.

About You

You're a fit for the role if your background includes:

Required Qualifications:

PhD student or recent graduate with research experience in a technical discipline. 
First-author publications at relevant venues such as NeurIPS, ICML, ICLR, ACL, EMNLP, NAACL, ICLR, or similar. 
Excellent communication skills to report and present research findings and developments clearly, both orally and in writing. 
Curious and innovative disposition capable of devising novel, well-founded algorithmic solutions to relevant problems. 
Self-driven attitude and ability to work with limited supervision. 
Comfortable working in fast-paced, agile environments, managing uncertainty and ambiguity. 


Preferred Qualifications:

Experience working on relevant state-of-the-art research topics in large language models (LLMs) such as alignment, hallucination detection and reduction, model compression, data-centric techniques, efficient fine-tuning, long context length, synthetic data, combination of LLMs with knowledge graphs etc. 
Familiarity with cloud tools such as Amazon AWS, MS Azure, or Google Cloud. 
Previous experience working on large-scale machine learning systems. 
Strong software and/or infrastructure engineering skills, as evidenced by code contributions to popular open-source libraries. 


Other key points: 

Plenty of data, compute, and high-impact problems: Our scientists and engineers get to play with large datasets and discover new capabilities and insights in support of our high-impact products and customers. Thomson Reuters is best known for the globally respected Reuters News agency, but our company is also the leading source of information for legal, corporate, and tax & Accounting professionals. We have over 60,000 TBs worth of legal, regulatory, news, and tax data. We also provide access to all major cloud computing platforms to our researchers and engineers.

What’s in it For You?

Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Industry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Culture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives. 
Making a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.


About Us

Thomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

As a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.

Learn more on how to protect yourself from fraudulent job postings here.

More information about Thomson Reuters can be found on thomsonreuters.com.",[]
"Research Engineer, Data (Foundational Research, Machine Learning)",Thomson Reuters,"Toronto, ON",Hybrid,"About the job
Are you a curious and open-minded individual with an interest in state-of-the-art machine learning engineering and research? Thomson Reuters Labs is seeking a Data Engineer with a passion for solving challenging machine learning problems in a data-rich, complex and innovative environment.

What does Thomson Reuters Labs do? We experiment, we build, we deliver. We support the organization and our product teams through foundational research and development of new products and technologies. The Labs innovate collaboratively across our core segments in Legal, Tax & Accounting, Government, and Reuters News. We undertake a diverse portfolio of projects while investing in long-term research for the future.

As a Research Engineer, you will be part of a diverse global team of experts. We hire worldleading specialists in SWE /Applied ML, as well as Research, to drive the company’s leading internal AI model development, fueled by an unprecedented wealth of data and powered by cutting-edge technical infrastructure. You will have the opportunity to contribute to a data curation & filtering system combining the best of real-world scalable data processing systems combined with the latest insights into what training data leads to the best LLMs. Thomson Reuters Labs is known for consistently delivering successful datadriven Artificial Intelligence solutions in support of high-growth products that serve Thomson Reuters customers in new and exciting ways.

About the Role:

In this opportunity as a Research Engineer - Data, you will:

Innovate: You will work at the very cutting edge of AI Research at an institution with some of the richest data sources in the world. Through your work, you will help us make the best use of this resource, in a dynamic flywheel that connects data collection & annotation with model training and expert evaluation, helping us continuously improve our training data. You will also develop novel performance-driven data sub-selection methods together with the latest training insights from our researchers.
Engineer and Develop: Design, develop, and optimize scalable data pipelines to support LLM training and evaluation. You will also help us develop this in a robust and testable way, through careful source control and a solid back-up system for various data versioning methods.
Collaborate: Working on a collaborative global team of engineers and scientists both within Thomson Reuters and our academic partners at world-leading universities. In addition, you will work closely with world experts in the legal domain, which can provide feedback to your work and/or evaluate your outputs or annotate training data. 


About You:

You're a fit for the role of Research Engineer - Data, if your background includes:

Required qualifications:

Relevant degree in a technical discipline.
Interest in & experience working with (applied) machine learning, e.g. few-shot learning with out-of-the-box language models, training of smaller NLP classifiers, etc.
Excellent programming, debugging and system design skills.
Excellent communication skills to report and present software designs and findings clearly, both orally and in writing.
Curious and innovative disposition capable of devising novel, well-founded algorithmic solutions to relevant problems.
Self-driven attitude and ability to work with limited supervision.
Experience with relational and NoSQL databases (e.g., PostgreSQL, MySQL, MongoDB, Cassandra).
Experience with data pipeline orchestration tools.
Experience with cloud-based data platforms such as AWS, GCP, or Azure (e.g., S3, BigQuery, Azure Data Lake Storage).
Comfortable working in fast-paced, agile environments, managing uncertainty and ambiguity.


Preferred qualifications:

Additional legal knowledge as evidenced by a degree or interest in the legal domain.
Ability to communicate with multiple stakeholders, including non-technical legal subject matter experts.
Experience with big data technologies such as Spark, Hadoop, or similar.
Experience conducting world-leading research, e.g. by contributions to publications at leading ML venues.
Previous experience working on large-scale data processing systems.
Strong software and/or infrastructure engineering skills, as evidenced by code contributions to popular open-source libraries.


What’s in it For You?

Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Industry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Culture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives. 
Making a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.


About Us

Thomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

As a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.

Learn more on how to protect yourself from fraudulent job postings here.

More information about Thomson Reuters can be found on thomsonreuters.com.",[]
"Sr. ML Compiler Engineer, AWS Neuron, Annapurna Labs",Amazon Web Services (AWS),,,"About the job
Description

The Annapurna Labs team at Amazon Web Services (AWS) builds AWS Neuron, the software development kit used to accelerate deep learning and GenAI workloads on Amazon’s custom machine learning accelerators, Inferentia and Trainium.

The Product: The AWS Machine Learning accelerators (Inferentia/Trainium) offer unparalleled ML inference and training performances. They are enabled through state-of-the-art software stack - the AWS Neuron Software Development Kit (SDK). This SDK comprises an ML compiler, runtime, and application framework, which seamlessly integrate into popular ML frameworks like PyTorch. AWS Neuron, running on Inferentia and Trainium, is trusted and used by leading customers such as Snap, Autodesk, and Amazon Alexa.

The Team: Annapurna Labs was a startup company acquired by AWS in 2015, and is now fully integrated. If AWS is an infrastructure company, then think Annapurna Labs as the infrastructure provider of AWS. Our org covers multiple disciplines including silicon engineering, hardware design and verification, software, and operations. AWS Nitro, ENA, EFA, Graviton and F1 EC2 Instances, AWS Neuron, Inferentia and Trainium ML Accelerators, and in storage with scalable NVMe, are some of the products we have delivered over the last few years.

Within this ecosystem, the Neuron Compiler team is developing a deep learning compiler stack that takes state of the art LLM, Vision, and multi-modal models created in frameworks such as TensorFlow, PyTorch, and JAX, and makes them run performantly on our accelerators. The team is comprised of some of the brightest minds in the engineering, research, and product communities, focused on the ambitious goal of creating a toolchain that will provide a quantum leap in performance.

The Neuron team is hiring systems and compiler engineers in order to solve our customers toughest problems. Specifically, the performance team in Toronto is focused on analysis and optimization of system-level performance of machine learning models on AWS ML accelerators. The team conducts in-depth profiling and works across multiple layers of the technology stack - from frameworks and compilers to runtime and collectives - to meet and exceed customer requirements while maintaining a competitive edge in the market. As part of the Neuron Compiler organization, the team not only identifies and implements performance optimizations but also works to crystallize these improvements into the compiler, automating optimizations for broader customer benefit.

This is an opportunity to work on innovative products at the intersection of machine-learning, high-performance computing, and distributed architectures. You will architect and implement business-critical features, publish innovative research, and mentor a brilliant team of experienced engineers. We operate in spaces that are very large, yet our teams remain small and agile. There is no blueprint. We're inventing. We're experimenting. It is a very unique learning culture. The team works closely with customers on their model enablement, providing direct support and optimization expertise to ensure their machine learning workloads achieve optimal performance on AWS ML accelerators.

Explore the product and our history!

https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-cc/index.html

https://aws.amazon.com/machine-learning/neuron/

https://github.com/aws/aws-neuron-sdk

https://www.amazon.science/how-silicon-innovation-became-the-secret-sauce-behind-awss-success

Key job responsibilities

Role

Our performance engineers collaborate across compiler, runtime, and framework teams to optimize machine learning workloads for our global customer base. Working at the intersection of machine learning, high-performance computing, and distributed systems, you'll bring a passion for performance analysis, distributed systems, and machine learning. In this role, you will:

 Analyze and optimize system-level performance of machine learning models across the entire technology stack, from frameworks to runtime
 Conduct detailed performance analysis and profiling of ML workloads, identifying and resolving bottlenecks in large-scale ML systems
 Work directly with customers to enable and optimize their ML models on AWS accelerators, understanding their specific requirements and use cases
 Design and implement compiler optimizations, transforming manual performance improvements into automated compiler passes
 Collaborate across teams to develop innovative optimization techniques that enhance AWS Neuron SDK's performance capabilities
 Work in a startup-like development environment, where you’re always working on the most important stuff

A day in the life

As You Design And Code Solutions To Help Our Team Drive Efficiencies In Software Architecture, You’ll Create Metrics, Implement Automation And Other Improvements, And Resolve The Root Cause Of Software Defects. You’ll Also

Build high-impact solutions to deliver to our large customer base.

Participate in design discussions, code review, and communicate with internal and external stakeholders.

Work cross-functionally to help drive business decisions with your technical input.

Work in a startup-like development environment, where you’re always working on the most important stuff.

About The Team

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge-sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects that help our team members develop your engineering expertise so you feel empowered to take on more complex tasks in the future.

Diverse Experiences

AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.

About AWS

Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture

Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.

Work/Life Balance

We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.

Mentorship & Career Growth

We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Basic Qualifications

 5+ years of non-internship professional software development experience
 5+ years of programming with at least one software programming language experience
 5+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
 Experience as a mentor, tech lead or leading an engineering team

Preferred Qualifications

 5+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
 Bachelor's degree in computer science or equivalent
 Experience in compiler design for CPU/GPU/Vector engines/ML-accelerators.
 Experience with System Level performance analysis and optimization
 Experience with LLVM and/or MLIR
 Experience with the following technologies: PyTorch, OpenXLA, StableHLO, JAX, TVM, deep learning models, and algorithms.

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - Amazon Development Centre Canada ULC

Job ID: A2991510",[]
"Sr. Software Engineer II, Machine Learning",Narvar,Canada,Remote,"About the job
Narvar is growing! We are hiring a Senior Software Engineer II to build new products and improve all aspects of the Narvar platform. Data is at the core of our competitive advantage so the work you do has a large impact across the company, our business partners, and the lives of our end users.

Machine Learning Engineers at Narvar work across the stack. We are ‘full-stack’ ML Engineers. This means that we write production-level code and own machine learning operations for our teams.

Day-to-day

Design and deploy machine learning algorithms for use cases spanning e-commerce, consumer trends, markets, logistics, and new products
Work on real-world consumer data for natural language processing, image classification, time series analysis, outlier detection, user modeling, etc
Work with large unstructured data
Be at the intersection of mathematics, machine learning, business, and computer science and impact millions of users through your work
Multiply the effect of your data science and data team members by building frameworks, tools, and methodologies that the entire team use 
Provide thought leadership to a team through high quality write-ups, reviews, and a strong vision grounded in practical experience and a wider industry view


What We’re Looking For

Strong machine learning skills. 
Fluency in Python, PyTorch, Tensorflow, Pandas, numpy, and machine learning packages
Data Engineering skills and large data experience. You should have dealt with large amounts of data (TB) in a production setting, built world class data pipelines using cutting edge tools (e.g. Spark).
10+ years of hands-on experience shipping models to production, working on a variety of problem spaces (eg: user modeling, spam classification, prediction, clustering etc)
MS in Computer Science, Statistics, Math, Science (physical or social), Engineering or similar quantitative and computation field plus 5+ years of industry experience
Strong software engineering and coding skills with the ability to write production quality code
Strong understanding of probability & statistics, machine learning, and algorithms
Experience with SQL and NoSQL databases
Experience working with Linux, shell scripting
Previous startup experience strongly preferred


Bonus Points

Experience implementing applications on Google Cloud Platform
Experience with deep generative models or graph learning a plus.
Tag your application with your solution to an active / recently concluded Kaggle competition, to get ahead of the list :)
Experience leading a team of data and data scientists; Strong ability to multiply the effect of the team and the team members; excellent written communication; self-starter that can balance sophistication with practicality 


Why Narvar?

We're on a mission to simplify the everyday lives of consumers. Post-purchase is a critical phase of the customer journey. That's why we created Narvar - a platform focused on driving customer loyalty through seamless post-purchase experiences that allow retailers to retain, engage, and delight customers. If you've ever bought something online, there's a good chance you've used our platform!

From the hottest new direct-to-consumer companies to retail’s most renowned brands, Narvar works with GameStop, Neiman Marcus, Sonos, Nike, and 1300+ + other brands. With hubs in San Francisco, Atlanta, London, and Bangalore, we've served over 125 million consumers worldwide across 10+ billion interactions, 38 countries, and 55 languages.

Pioneering the post-purchase movement means navigating into the unknown. Our team thrives on this sense of adventure while nurturing a mindset of innovation. We're a home for big hearts and we leave our egos at the door. We work hard but we always make time to celebrate professional wins, baby showers, birthday parties, and everything in between.

We are an equal-opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Please read our Privacy Policy to learn what personal information we collect in connection with your job application, and how we may use and share it.",[]
Senior Machine Learning Engineer,Klue,"Toronto, ON",Hybrid,"About the job
👋 Klue Engineering is hiring!

We're looking for a Senior Machine Learning Engineer to join our team in Toronto, focusing on building and optimizing state-of-the-art LLM-powered agents that can reason, plan and automate workflows for users. You will be leading the design and development of search and retrieval agent systems that enable users to generate compete insights for their business. In this role, you will own projects end-to-end, guiding architecture decisions, experimentation strategy, and production readiness for LLM-powered retrieval and generation workflows.

💡 FAQ

Q: Klue who?

A: Klue is a VC-backed, capital-efficient growing SaaS company. Tiger Global and Salesforce Ventures led our US$62m Series B in the fall of 2021. We’re creating the category of competitive enablement: helping companies understand their market and outmaneuver their competition. We benefit from having an experienced leadership team working alongside several hundred risk-taking builders who elevate every day.

We’re one of Canada’s Most Admired Corporate Cultures by Waterstone HC, a Deloitte Technology Fast 50 & Fast 500 winner, and recipient of both the Startup of the Year and Tech Culture of the Year awards at the Technology Impact Awards.

Q: What are the responsibilities, and how will I spend my time?

A: You will shape how we integrate retrieval-augmented generation (RAG), dense retrieval, query understanding, and agentic reasoning loops to deliver fast, accurate, and trusted search experiences at scale.

What you’ll do on a Day to day basis:

Architect, design, and implement retrieval pipelines and agentic workflows, including hybrid retrieval, re-ranking, and post-retrieval synthesis. 
Lead the development of evaluation frameworks (offline and human-in-the-loop) to measure and improve relevance, quality, and latency. 
Drive experimentation with query rewriting, expansion, and classification to enhance retrieval effectiveness. 
Optimize LLM workflows by designing prompt structures, retrieval strategies, and caching for low-latency, high-accuracy responses. 
Collaborate cross-functionally with product and infrastructure teams to align technical direction with product goals. 
Mentor and provide technical guidance to team members, establishing best practices for building production-ready ML systems. 
Every day, our services process millions of data points, including news articles, press releases, webpage changes, Slack posts, emails, reviews, CRM opportunities, and user actions. You will own data strategy for retrieval and design pipelines to automatically extract insights about competitors from both public and internal data sources
Evaluate and integrate advancements in LLMs, retrieval architectures, and agentic reasoning into our production systems. 

Q: What experience are we looking for?

5+ years of industry experience building and deploying ML systems, with at least 2+ years working on search, retrieval, or ranking systems. 
Expert-level programming skills in Python, with experience using frameworks such as PyTorch, TensorFlow, or JAX. 
Deep understanding of information retrieval (BM25, dense retrieval, hybrid retrieval) and relevance tuning. 
Experience with LLMs, retrieval-augmented generation pipelines, and prompt engineering. 
Track record of designing and delivering production-grade ML systems at scale, balancing experimentation with reliability. 
Deep understanding of data pipelines, preprocessing, and large-scale data handling. 
Familiarity with evaluation methodologies for search systems (recall, MRR, nDCG) and user-facing evaluations. 
Experience working with vector database infrastructure (FAISS, Milvus, Weaviate, Pinecone, PGVector) and traditional search engines (Elasticsearch, OpenSearch)
Familiarity with scalable cloud ML infrastructure (AWS, GCP, Azure). 
Develop and implement CI/CD pipelines. Automate the deployment and monitoring of ML models. 
Knowledge of query understanding, document summarization and other content enrichment strategies
Ability to lead projects independently while providing technical direction to others. 

Nice to Have

Experience designing agentic LLM systems and multi-step retrieval workflows. 
Background in conversational search
Contributions to open-source search, retrieval, or LLM-related projects. 
Interest in publishing or sharing learnings with the broader community. 

Q: What makes you thrive at Klue?

A: We're looking for builders who:

Take ownership and run with ambiguous problems
Jump into new areas and rapidly learn what's needed to deliver solutions
Bring scientific rigor while maintaining a pragmatic delivery focus
See unclear requirements as an opportunity to shape the solution

Q: What technologies do we use?

LLM platforms: OpenAI, Anthropic, open-source models
ML frameworks: PyTorch, Transformers, spaCy
Search/Vector DBs: Elasticsearch, Pinecone, PostgreSQL
MLOps tools: Weights & Biases, MLflow, Langfuse
Infrastructure: Docker, Kubernetes, GCP
Development: Python, Git, CI/CD

Q: What is your working style at Klue?

Hybrid. Best of both worlds (remote & in-office) You and your team will be in the office 2 days a week. 
Our main Canadian hubs are in Vancouver and Toronto, and most of our teams are located in EST and PST. 

Q: What about Compensation & Benefits:

Competitive base salary
Benefits. Extended health & dental benefits that kick in Day 1
Options. Opportunity to participate in our Employee Stock Option Plan
Time off. Take what you need. Just ensure the required work gets done and clear it with your team in advance. The average Klue team member takes 2-4 weeks of PTO per year. 
Direct access to our leadership team, including our CEO

⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️

Not ticking every box? That’s okay. We take potential into consideration. An equivalent combination of education and experience may be accepted in lieu of the specifics listed above. If you know you have what it takes, even if that’s different from what we’ve described, be sure to explain why in your application.

At Klue, we're dedicated to creating an inclusive, equitable and diverse workplace as an equal-opportunity employer. Our commitment is to build a high-performing team where people feel a strong sense of belonging, can be their authentic selves, and are able to reach their full potential. If there’s anything we can do to make our hiring process more accessible or to better support you, please let us know, we’re happy to accommodate.

We’re excited to meet you and in the meantime, get to know us:

🌈 Pay Up For Progress & 50 - 30 Challenge

✅✅ Win-Loss Acquisition (2023)

🐅 Series B (2021)

🏆 Culture, culture, culture!

🎧 Winning as Women & More!

🐝 About Us

🥅 Product Demo Arena

🔍 Glassdoor

🎥 Youtube

☕️ LinkedIn

🦄 Wellfound (AngelList)

Compensation Range: CA$175K - CA$210K",[]
Staff ML Developer,AlayaCare,"Montreal, QC",Hybrid,"About the job
About AlayaCare: 

At AlayaCare, we're revolutionizing the way that home healthcare is delivered. Our leading cloud-based software allows our customers around the world to manage their employees, scheduling, billing, and enable better delivery of care. We're a fast-growing SaaS company with a team of 550+ team members across Canada, US, Australia, and Brazil. We aim to be the world leader in home healthcare software solutions as we empower providers to deliver better health outcomes to their patients and clients. We pride ourselves on our open and transparent culture, our bias for action, and being committed to a workplace where we can be ourselves. 

About the role: 

Reporting to the Engineering Manager, Staff ML Developers work with researchers, applied scientists, engineers, and product managers to build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences in the AlayaCare platform. Staff ML developers also lay the foundations, research, experiment, and de-risk AI technologies that unlock new products and experiences for our 700+ tenants worldwide. They work with different product delivery teams, guiding them to provide strategic value for AlayaCare while driving technical design and up-levelling the teams in their domain. They are responsible for defining the technical direction of the projects in their department, with a focus on delivering scalable and maintainable solutions.

A deep understanding of all stages of development is essential, as is an understanding of the part each developer plays and how they contribute to the end product. Senior Staff Developers thrive on new challenges and is never intimidated by something unfamiliar to them. They are passionate about their work and gain genuine enjoyment from seeing projects through, from start to finish.

A day in the life:  

Confronted with real-world challenges and datasets, you will need to use your AI/ML expertise and creativity to apply existing methods and develop new ones to solve these problems in a practical and scalable way. 
Research, propose and implement appropriate models/techniques for LLM benchmarking. 
Participate in data collection and synthetic data generation, and generate custom benchmarks to evaluate diverse LLMs capabilities. 
Collaborate daily with a team of like-minded developers, applied research scientists, product managers and quality engineers to produce quality software. 
Contribute to the implementation of tools to facilitate LLMs evaluation and perform model / error analysis. 
Develop innovative patentable ideas that ensure the competitiveness of this product within the domain of similar work being done in the industry. 
Work with product managers to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality & high-impact solutions to our users. 
Spend 50%+ of time coding 
Mentor 2+ Developers 
Provide technical direction for product development teams in your domain, and improve your colleagues' skills through code reviews, technical mentoring, role-modelling, coaching, and knowledge-sharing. 
Stay up to date with new technology and teaching other developers how to incorporate new trends. 
Generate ideas with members of product delivery teams and help them find insightful solutions to complex problems. 
Evaluate existing engineering processes and procedures across domains, identifying areas that need optimization, and leading the optimization effort. 
Delegate tasks to appropriate teams and successfully managing technical projects through all stages of the development lifecycle. 
Fundamentally understand the code and the code structure in connecting areas and quickly assess good or bad development decisions. 
Manage business and technical stakeholders across different levels of the organization, selling your ideas with confidence. 
Design domain and product strategy roadmaps. 

What you bring to the team: 

6+ years of relevant experience with a Bachelor's degree; or 4 years with a Master's degree; or a PhD with no experience; or equivalent work experience. 
Experience in leveraging or critically thinking about how to integrate AI into work processes, decision-making, or problem-solving. This may include using AI-powered tools, automating workflows, analyzing AI-driven insights, or exploring AI's potential impact on the function or industry. 
Solid expertise in Python. 
Solid Machine Learning/Deep Learning theoretical knowledge and hands-on experience. 
Experience with LLM benchmarking and evaluation is required; experience generating synthetic data is a plus. 
Ability to read and experiment with ideas from recent research papers. 
High level of creativity, quick problem-solving abilities, and adaptability. 
Effective communication skills to convey research findings to both technical and non-technical stakeholders, ensuring a clear understanding of the benefits and limitations of LLMs across the organization. 
Bilingual in French and English. 

Location and travel requirements: 

AlayaCare supports a flexible hybrid working model, expecting that our employees have a regular in-office presence at their closest office location while offering flexibility for some remote work. Our team encourages in-person collaboration and with this, the preferred candidate location for this position would be within the Greater Montreal Area.

What Makes AlayaCare a Great Place to Work:

Our products have a positive impact on the lives of countless care workers and care recipients 
Our company has been recognized by the Globe and Mail as one of Canada's Top Growing Companies and as a recipient of Deloitte's Technology Fast 50TM program award for our rapid revenue growth, entrepreneurial spirit and bold innovation 
Equity in a well-funded, high-growth company 
Hybrid working models with beautiful and creative office spaces to enjoy in prime locations 
Virtual and onsite social events for employees centered around collaboration, learning, and fun, including DEIBA committee events, volunteer events, fireside chats, catered team lunches, celebrations, and team building activities 
Comprehensive group benefits program, including telemedicine 
Employee expense program for health, wellness, lifestyle, professional development and productivity-related expenses 
Parental leave top-up program 
Flexible vacation policy 
Company Wellness Day program for extra time to unwind 
Paid Volunteer Time off Program 
Career growth and learning and development opportunities 
An entrepreneurial culture of transparency, collaboration, and innovation 
Access to our employee perk program for discounts at various participating vendors 

If this sounds like the perfect job for you, apply today. As well as joining a great culture and a market-leading company, you will be part of a team making a positive difference in the post-acute care market. If this isn't the job for you, you may know someone who is a perfect fit. Please feel free to share this opportunity. 

If you want to explore AlayaCare further, please visit our website www.alayacare.com. 

Better outcomes, better belonging 

Our team members are unique—like our products and the customer groups that we service. AlayaCare employees bring different strengths, perspectives, and experiences to their roles and to our products that enable better care. We are committed to offering a people-centric culture where all employees belong and feel heard. 

Having a pulse on our employee feedback is important to us as we aim to continuously evolve Diversity, Equity, Inclusion, Belonging, and Accessibility within AlayaCare's policies, total rewards offerings, discussions, learning & development programs, and community partnerships. All qualified applicants will receive equal consideration. 

If you require accommodation as part of the recruitment and selection process, please reach out to talentacquisitionteam@alayacare.com. Please note, we do not accept unsolicited headhunter or agency resumes.",[]
Data Scientist / Machine Learning Specialist,J&M Group,,,"About the job
Role: Data Scientist / Machine Learning Specialist 

 Location: Montreal, QC (3x per week) 

 Background check MANDATORY 

 Duration: 3+ Months 

 JP ID: CGEMJP00269233/CGEMJP00269234 

 R2D2: 14436619/14436616 

Job Description

We are looking for a machine learning and natural language processing specialist to explore, design and develop new Machine Learning solutions for a Firm-wide user base leveraging many tools. The ideal candidate should hold an advanced degree in a quantitative discipline and has experience researching, building, and maintaining data science models at scale in an enterprise environment. The position requires good communication skills, ability to work together in cross-functional technical teams in different areas of the organization.

Key Responsibilities

 Independently work on end-to-end development of Machine Learning and Natural Language Processing models to derive insights from research publications, legal documents, regulatory requirements etc. 
 Technical analysis and software development. 
 Design and implement business solution in agile squads. 
 Engage in Machine Learning project, which includes problem definition, Data Engineering, Machine Learning design and documentation for the model risk management and running all the needed Client tests to ensure reliability. 
 Develop, maintain, and track detailed delivery plans. 
 Strong Data analysis, processing, discovery skills. 

Skills Required

 Master's in mathematics, Statistics, Economics, Data Science, Machine Learning, Operational Research, Physics, and other related quantitative fields. 
 At least 4 years of experience with design and implementation of machine learning, predictive analysis, data science, knowledge bases, recommendation systems, information retrieval. 
 Strong understanding of the foundational concepts and applied experience in Machine Learning and model explain ability (ideally, a combination of excellent academic research and high-impact commercial projects). 
 In depth understanding of common Machine Learning algorithms (e.g., for classification, regression, and clustering). 
 Experience with LLM models and Open AI. 
 In depth knowledge of advanced statistical theories, methodologies, and inference tools. 
 Proven track record in some of the advanced topics such as Bayesian inference, hierarchical models, deep learning, Gaussian processes, and causal inference. 
 Practical experience in preparing data for Machine Learning integrating with big-data platforms and high-performance computing ecosystems. 
 Strong oral and written communication skills. 
 Strong analytical and problem-solving skills. 

Skills Desired

 Modeling using vendor products such as: Microsoft AI Builder (Power Platform) and CO Pilot. 
 Familiar with Azure and AWS framework 
 Experience with non-English Natural Language Processing. 
 Client Libraries H2O, Keras, Tensorflow 
 Experience with Deep Learning 
 Banking / Financial Services experience.",[]
Machine Learning Engineer,ProNavigator,"Toronto, ON",Remote,"About the job
Who is ProNavigator?

ProNavigator helps insurance organizations centralize, manage, and deliver on-demand information to sales, service, underwriting, and brokers/agents. In 2019, we pioneered the first knowledge management platform for insurance. Now, more than 10,000 insurance professionals use ProNavigator to get quick, accurate answers. We continue to push the boundaries of what’s possible by integrating large language models that are accurate and secure.

At ProNavigator, we’re tackling and solving unique challenges. Every day is an exciting new opportunity to collaborate with colleagues as we build a leading-edge platform and support our clients to do their best work. Our culture is built on the values of hard work, creativity, collaboration and high performance. We’re looking for new team members who will try new things, share their opinion, move fast, think creatively and have fun.

What’s this role all about?

Join our Engineering team as they build the next generation of knowledge management products, powered by large language models. In this role you will play a leadership role in the design and development of AI software solutions and features, with a focus on researching, evaluating, training and tuning models to meet our product needs. This role is for you if you are a creative and scrappy problem solver who is looking to translate your technical depth in ML to provide technical direction and execution on language-based AI systems.

Our current technology stack includes JavaScript, React, Python, FastAPI, Docker, AWS and MySQL, however we bring technologies in and out based on newly released tools, changes to requirements or solutions that more elegantly meet our objectives.

Your accountabilities in this role will include:

Delivering AI/ML models from initial planning to data sourcing and preparation, building and training models, and deploying models to production in our cloud environment, ideally using and deploying open source models
Creating AI-based prototypes to evaluate model and design options, working with internal stakeholders to analyze quality and relevance of results
Training and tuning models to optimize outcomes of algorithms
Integrating models to production, working with Engineering team members as needed to integrate models into product architecture
Working with internal stakeholders to understand product needs of AI and to scope potential solutions
Conducting research into relevant AI models and technologies and staying well-connected to trends and developments in this rapidly evolving space 


This is a remote role that can be based from one of the following provinces in Canada: British Columbia, Alberta, Saskatchewan, Manitoba, Ontario, Newfoundland, PEI, New Brunswick, Nova Scotia.

What do you need to be successful?

The experiences, skills and attributes we think are key to your success are listed below. If you’re excited about this role but don’t meet 100% of these qualifications, we still encourage you to apply – we know there is no match for hunger, curiosity and an ability to figure things out in an evolving environment.

5+ years of software development experience with at least 3 years of experience implementing ML and AI technologies
Deep knowledge of data modeling, and current ML and AI technologies with experience working with LLMs in particular to develop language-based solutions
Highly analytical with the ability to think outside of the box, consider potential solutions from many different sources and make decisions with rapidly evolving or ambiguous data points
Creative and scrappy problem solver who is excited about the prospect of creating greenfield solutions using new and evolving technologies 
Strong written and verbal communication skills with the ability to present complex ideas
Highly collaborative with the ability to work cross-functionally to understand needs and execute against ideas
Thrives in a startup environment where speed, agility and high performance are table stakes


If you need accommodations during the hiring process, let us know at any time and we’ll make sure you’re set up for success.

What’s in it for you?

We’re looking for the best of the best to join our team and in return, we invest in the things that are important to our team members including:

4 weeks to give you the time away from work you need to recharge and deliver at 100%
Flexible time off policies to support you when things come up outside of work
Remote-first work environment that gives you the flexibility to work wherever you’re most productive
Annual professional development budget so you can pursue growth in the areas related to your career goals
Competitive total compensation package across salary, variable compensation and benefits",[]
Senior Machine Learning Engineer,Grid Dynamics,Greater Montreal Metropolitan Area,Remote,"About the job
We are looking for experienced Senior Machine Learning Frameworks Engineer to join our team.

Responsibilities

Research how to best use techniques like Supervised Fine Tuning (SFT) and Reinforcement Learning with Human Feedback (RLHF) to align LLMs.
Work with technical and non-technical stakeholders to align LLMs for specific use cases.
Research and implement approaches to ensure LLMs are aligned with product feature goals, including preventing hallucinations.
Collect requirements from data engineering, product feature, research and evaluation teams to develop modeling, prompting and data transformation techniques

Requirements

Required:

Experience in processing and manipulating data using libraries such as Pandas and NumPy. Experience in visualizing data using libraries such as Matplotlib, Seaborn, or Plotly.
Experience with deep learning frameworks - at least one of them - such as TensorFlow, PyTorch, or JAX.
Experience in designing and experimenting with new machine learning algorithms and optimizations.
Experience with LLM fine-tuning techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and parameter-efficient methods like LoRA.
Experience in independently driving a research agenda, identifying key challenges, and proposing innovative solutions in machine learning.
Deep understanding of Large Language Models, including their architectures, training methodologies, and inference optimizations.

Preferred

Experience in optimizing machine learning models and data pipelines for scalability and performance.
Experience with software engineering principles, including version control (Git), CI/CD, and modular code design.
Experience with distributed computing frameworks like Ray, Dask, or Spark for large-scale ML workloads.
Experience with model deployment frameworks such as TensorFlow Serving, TorchServe, or ONNX Runtime.

We offer

Opportunity to work on bleeding-edge projects
Work with a highly motivated and dedicated team
Competitive salary
Flexible schedule
Benefits package - medical insurance, sports
Corporate social events
Professional development opportunities
Well-equipped office

About Us

Grid Dynamics (NASDAQ: GDYN) is a leading provider of technology consulting, platform and product engineering, AI, and advanced analytics services. Fusing technical vision with business acumen, we solve the most pressing technical challenges and enable positive business outcomes for enterprise companies undergoing business transformation. A key differentiator for Grid Dynamics is our 8 years of experience and leadership in enterprise AI, supported by profound expertise and ongoing investment in data, analytics, cloud & DevOps, application modernization and customer experience. Founded in 2006, Grid Dynamics is headquartered in Silicon Valley with offices across the Americas, Europe, and India.",[]
"Member of Technical Staff, Modeling",Boson AI,,,"About the job
Boson AI is an early-stage startup building large language tools for interaction and entertainment. Our founders, Alex Smola, Mu Li, and a team of Deep Learning, Optimization, NLP, AutoML and Statistics scientists and engineers are working on high quality generative AI models for language and beyond.

We are seeking research scientists and engineers to join our team full-time in our Santa Clara office. As part of your role, you will work on modeling and training LLMs, understanding and interpreting model behavior and aligning models to human values. The ideal candidate will possess a strong background in machine learning, and have motivations for developing state-of-the-art models towards AGI.

Responsibilities

Design and verify novel model architectures and training objectives. 
Investigate novel model alignment algorithms
Write efficient and clean code for ML training
Conduct large-scale experiments to verify the modeling choices and identify improvement areas



Experience

Summarize results and clearly communicate the motivations and observations in your work
Proficiency in at least one deep learning framework, such as PyTorch
Participation in at least one research project related to LLM or multimodal models, e.g. experience in training or fine-tuning them. 
Experience in alignment research
Experience in large-scale distributed model training
Experience in writing GPU kernels in CUDA



Qualifications

PhD or Master's degree with solid scientific contributions
Active GitHub repository 
Active scientific track record
Excellent problem-solving skills



Total compensations includes base pay, equity, and benefits. We have a 401k plan, HSA, FSA, free food (even dried mangoes).",[]
[Wattpad] Machine Learning Engineer,WEBTOON,"Toronto, ON",Remote,"About the job
Wattpad’s vision is to entertain and connect the world through webnovel stories. Since 2006, we’ve been on a mission to use the power of community and technology to unleash the full potential of stories to the world. Representing a tapestry of cultures and languages, people around the world come to Wattpad every month to share and discover stories they can’t find anywhere else. Come build the future of entertainment and storytelling with our global team, and write your next chapter with us!

Wattpad is part of the WEBTOON family of brands, the largest storytelling platform in the world that enables creators and users to discover, create, and share stories. With over 24 million creators and ~170 million active users per month, we are truly empowering creation by anyone, for everyone. To read more about our family of Brands, check out our website here .

The Data Products & Analytics (DPA) team focuses on supporting and improving Wattpad’s Search, Recommendation and Analytics systems. We are a cross functional team of data scientists, analysts and engineers with the vision to connect millions of readers to the right story at the right time. If you have a passion for building discovery systems at massive scale, come join us to build the next iteration of our ML engines!

What you'll be doing:

Bring knowledge and experience of applied machine learning to the challenges of product development, maintenance and deployment to Wattpad systems (e.g. recommendations, search)
Follow and maintain best practices for machine learning solution development and communicate those to data scientists and engineers to help create processes, standards, business value and impact
Build and maintain iteratively in areas such as but not limited to: feature dashboards and POCs, feature pipelines, recommendation, search and ranking solutions to achieve impact while developing comprehensive knowledge of business objectives, data structures, technical infrastructure and processes, advocating for changes where needed to improve the product 
Work cross functionally to update, build and communicate solutions with with product managers, data scientists and engineers

What we're looking for:

A passion for applying machine learning to business problems
3+ years experience in a ML engineering role with proven results in delivering high impact support and applications with applied machine learning through the lifecycle of development, implementation, serving and evaluation
Bachelor's or Master’s degree in relevant field or equivalent experience
Motivation and excitement to deal with ambiguous problems and challenges
Clear communication about problem requirements, benefits and challenges of approaches with stakeholders
A team player who can collaborate and partner with other teams to achieve results
Proven experience in a software engineering environment developing and deploying data pipelines, models and services.
Experience with Cloud Infrastructure (e.g. AWS), containerization (Docker, Kubernetes), and CI/CD workflows
Experience with Infrastructure as Code (e.g. Terraform) is a plus
Experience working with complex, high dimensional data in SQL, Python and Pyspark (plus)
Experience with applied machine learning frameworks: scikit-learn, PyTorch (plus), Tensorflow (plus), Ray (plus), Dask (plus) and AWS Sagemaker (plus)

What we offer:

Career development; we believe in mentorship and investing in your learning, supporting you to achieve your goals
Health benefits, including vision and dental!
RRSP Contributions (Canada), 401K Contributions (USA)
Generous vacation and Parental Leave Top-up
Corporate discount for gym memberships for you and your family
Winter break shutdown and a whole lot more!

$120,000 - $160,000 a year

Please note the above salary range is in CAD.

Wattpad is conducting all interviews in a distributed manner using applicable third party software where needed and using visual interface tools such as Google Meet and Zoom.

About Wattpad

Who are we? Entrepreneurs and Do-ers. Our vision is to entertain and connect the world through stories, and our mission is to use the power of community and technology to unleash the full potential of stories to the world.

What does that mean? We are visionaries, community builders, passionate problem solvers, storytellers, coffee snobs (tea drinkers, too!), curious by nature, and culturally diverse.

What are we obsessed with? Our users. Solving complex problems and maximizing flow. Learning constantly. Building the next great storytelling product. Finding the greatest stories ever told. Dogs (and cats), coffee, and good snacks.

How do we work? Autonomously, collaboratively, respectfully. Balancing with work, family, and play...and all while having a great time.

Wattpad is a remote friendly company and encourages remote candidates to apply as long as they are located and authorized to work in either the US or Canada (excluding Quebec) as a precondition of employment. We are not able to sponsor applicants for work permits.

If you happen to live near the areas of either Toronto, Ontario or Halifax, Nova Scotia, you may also have the opportunity to work from our beautiful offices - 1 located in Downtown Toronto and the other in Halifax.

Culture and Diversity

Wattpad is an equal opportunity employer. We do not discriminate. Period.

Wattpad welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. We have taken a leadership position on creating a culture and an organization that truly values diversity. We are committed to fostering a global team that reflects the diversity of the Wattpad community. At Wattpad, we believe cultural fit doesn’t mean culturally identical, and diversity of thought helps us to challenge one another to think big and think differently. We consider employment applicants without regard to age, race, colour, national origin, citizenship, religion, creed, sex, sexual orientation, veteran status, marital status, disability status or any other protected status.

If you have any special needs or accessibility requirements, please let us know. We will do our utmost to accommodate, in accordance with applicable local legislation.

Don’t meet all the requirements? Studies show women and people of colour are less likely to apply to jobs if they do not meet all the qualifications. Therefore, in an effort to build a more diverse workplace, we encourage you to apply anyways. You might actually be the right person or you may be a good fit for a number of other openings we currently have.",[]
Search - Workchat - Principal Data Scientist,Elastic,Canada,Remote,"About the job
Elastic, the Search AI Company, enables everyone to find the answers they need in real time, using all their data, at scale — unleashing the potential of businesses and people. The Elastic Search AI Platform, used by more than 50% of the Fortune 500, brings together the precision of search and the intelligence of AI to enable everyone to accelerate the results that matter. By taking advantage of all structured and unstructured data — securing and protecting private information more effectively — Elastic’s complete, cloud-based solutions for search, security, and observability help organizations deliver on the promise of AI.

What is The Role:

The Search Data Science team is responsible for developing and integrating statistical tools and machine learning models within the Search domain in support of semantic search, RAG, agentic search, and chat applications. As a Data Scientist in this area, you will work closely with our Product teams to lead the innovation, incubation, and prototyping phases of how to evolve and transform our AI/ML driven Search experiences and solutions with a focus on quickly bringing new ideas to production and into the hands of our customers. Your primary focus will be driving forward research and development in support of improving semantic search with proprietary models and customized open source models, developing techniques and models for query and document understanding, implementing RAG and LLM-driven search experiences, and developing tooling to help customers design and implement successful end-to-end RAG systems. Furthermore, you’ll be investigating aspects of modern agentic search including reasoning engines, prompt engineering techniques, query understanding, and more. Doing this requires exploring and benchmarking new open source models, and existing proprietary Elastic models, while keeping up to date with the latest major advancements in the fields of NLP and information retrieval.

What You Will Be Doing:

Explore, select and benchmark open source and Elastic proprietary models
Implementing RAG and other LLM-based search experiences
Designing evaluation protocols for semantic search, tool selection, and generation in LLM-based search experiences
Keeping up-to-date with the most significant recent developments in the field of NLP and information retrieval
Engage with the NLP and information retrieval communities (blogs, documentation, Python examples, conference talks, academic papers, etc.)
Collaborate with cross-functional teams of data scientists, engineers, and product managers
Promote knowledge sharing and collaboration in a distributed team

What You Will Bring:

8+ years of confirmed experience building and applying NLP to production use cases
8+ years of professional software development experience in Python
Experience in Generative AI, Retrieval Augmented Generation, and information retrieval
Experience with libraries and frameworks such as PyTorch, transformers, and Pandas
Experience using collaborative notebook-based workflows (e.g. Jupyter) for prototyping and knowledge sharing
Expertise in AI/ML quality evaluation and improvement, including balancing tuning techniques with cost/benefit tradeoffs
Self motivated, collaborative style, open communicator, experience in a distributed team
Good attention to detail and highly organized
Real passion for data, analysis and achieving excellence
Experience with Elasticsearch is useful
An academic background in the domain is also a plus

If this sounds interesting, we would love to hear from you! Please include whatever info you believe is relevant: resume, GitHub profile, code samples, blog posts and writing samples, links to personal projects, etc.

Compensation for this role is in the form of base salary. This role does not have a variable compensation component. The typical starting salary range for new hires in this role is listed below.

These ranges represent the lowest to highest salary we reasonably and in good faith believe we would pay for this role at the time of this posting. We may ultimately pay more or less than the posted range, and the ranges may be modified in the future.

An employee's position within the salary range will be based on several factors including, but not limited to, relevant education, qualifications, certifications, experience, skills, geographic location, performance, and business or organizational needs.

Elastic believes that employees should have the opportunity to share in the value that we create together for our shareholders. Therefore, in addition to cash compensation, this role is currently eligible to participate in Elastic's stock program. Our total rewards package also includes a company-matched Registered Retirement Savings Plan (RRSP) with dollar-for-dollar matching up to 6% of eligible earnings, along with a range of other benefits offered with a holistic emphasis on employee well-being.

The typical starting salary range for this role is:

$128,300—$203,000 CAD

Additional Information - We Take Care Of Our People

As a distributed company, diversity drives our identity. Whether you’re looking to launch a new career or grow an existing one, Elastic is the type of company where you can balance great work with great life. Your age is only a number. It doesn’t matter if you’re just out of college or your children are; we need you for what you can do.

We strive to have parity of benefits across regions and while regulations differ from place to place, we believe taking care of our people is the right thing to do.

Competitive pay based on the work you do here and not your previous salary
Health coverage for you and your family in many locations
Ability to craft your calendar with flexible locations and schedules for many roles
Generous number of vacation days each year
Increase your impact - We match up to $2000 (or local currency equivalent) for financial donations and service
Up to 40 hours each year to use toward volunteer projects you love
Embracing parenthood with minimum of 16 weeks of parental leave

Different people approach problems differently. We need that. Elastic is an equal opportunity employer and is committed to creating an inclusive culture that celebrates different perspectives, experiences, and backgrounds. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, pregnancy, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, disability status, or any other basis protected by federal, state or local law, ordinance or regulation.

We welcome individuals with disabilities and strive to create an accessible and inclusive experience for all individuals. To request an accommodation during the application or the recruiting process, please email candidate_accessibility@elastic.co. We will reply to your request within 24 business hours of submission.

Applicants have rights under Federal Employment Laws, view posters linked below: Family and Medical Leave Act (FMLA) Poster; Pay Transparency Nondiscrimination Provision Poster; Employee Polygraph Protection Act (EPPA) Poster and Know Your Rights (Poster)

Elasticsearch develops and distributes encryption software and technology that is subject to U.S. export controls and licensing requirements for individuals who are located in or are nationals of the following sanctioned countries and regions: Belarus, Cuba, Iran, North Korea, Russia, Syria, the Crimea Region of Ukraine, the Donetsk People’s Republic (“DNR”), and the Luhansk People’s Republic (“LNR”). If you are located in or are a national of one of the listed countries or regions, an export license may be required as a condition of your employment in this role. Please note that national origin and/or nationality do not affect eligibility for employment with Elastic.

Please see here for our Privacy Statement.

Different people approach problems differently. We need that. Elastic is an equal opportunity/affirmative action employer committed to diversity, equity, and inclusion. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, pregnancy, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, disability status, or any other basis protected by federal, state or local law, ordinance or regulation.

We welcome individuals with disabilities and strive to create an accessible and inclusive experience for all individuals. To request an accommodation during the application or the recruiting process, please email candidate_accessibility@elastic.co We will reply to your request within 24 business hours of submission.

Applicants have rights under Federal Employment Laws, view posters linked below:

Family and Medical Leave Act (FMLA) Poster; Equal Employment Opportunity (EEO) Poster; and Employee Polygraph Protection Act (EPPA) Poster.

Please see here for our Privacy Statement.",[]
Senior Machine Learning Engineer,Klue,"Vancouver, BC",Hybrid,"About the job
👋 Klue Engineering is hiring!

We're looking for a Senior Machine Learning Engineer to join our team in Toronto, focusing on building and optimizing state-of-the-art LLM-powered agents that can reason, plan and automate workflows for users. You will be leading the design and development of search and retrieval agent systems that enable users to generate compete insights for their business. In this role, you will own projects end-to-end, guiding architecture decisions, experimentation strategy, and production readiness for LLM-powered retrieval and generation workflows.

💡 FAQ

Q: Klue who?

A: Klue is a VC-backed, capital-efficient growing SaaS company. Tiger Global and Salesforce Ventures led our US$62m Series B in the fall of 2021. We’re creating the category of competitive enablement: helping companies understand their market and outmaneuver their competition. We benefit from having an experienced leadership team working alongside several hundred risk-taking builders who elevate every day.

We’re one of Canada’s Most Admired Corporate Cultures by Waterstone HC, a Deloitte Technology Fast 50 & Fast 500 winner, and recipient of both the Startup of the Year and Tech Culture of the Year awards at the Technology Impact Awards.

Q: What are the responsibilities, and how will I spend my time?

A: You will shape how we integrate retrieval-augmented generation (RAG), dense retrieval, query understanding, and agentic reasoning loops to deliver fast, accurate, and trusted search experiences at scale.

What you’ll do on a Day to day basis:

Architect, design, and implement retrieval pipelines and agentic workflows, including hybrid retrieval, re-ranking, and post-retrieval synthesis. 
Lead the development of evaluation frameworks (offline and human-in-the-loop) to measure and improve relevance, quality, and latency. 
Drive experimentation with query rewriting, expansion, and classification to enhance retrieval effectiveness. 
Optimize LLM workflows by designing prompt structures, retrieval strategies, and caching for low-latency, high-accuracy responses. 
Collaborate cross-functionally with product and infrastructure teams to align technical direction with product goals. 
Mentor and provide technical guidance to team members, establishing best practices for building production-ready ML systems. 
Every day, our services process millions of data points, including news articles, press releases, webpage changes, Slack posts, emails, reviews, CRM opportunities, and user actions. You will own data strategy for retrieval and design pipelines to automatically extract insights about competitors from both public and internal data sources
Evaluate and integrate advancements in LLMs, retrieval architectures, and agentic reasoning into our production systems. 

Q: What experience are we looking for?

5+ years of industry experience building and deploying ML systems, with at least 2+ years working on search, retrieval, or ranking systems. 
Expert-level programming skills in Python, with experience using frameworks such as PyTorch, TensorFlow, or JAX. 
Deep understanding of information retrieval (BM25, dense retrieval, hybrid retrieval) and relevance tuning. 
Experience with LLMs, retrieval-augmented generation pipelines, and prompt engineering. 
Track record of designing and delivering production-grade ML systems at scale, balancing experimentation with reliability. 
Deep understanding of data pipelines, preprocessing, and large-scale data handling. 
Familiarity with evaluation methodologies for search systems (recall, MRR, nDCG) and user-facing evaluations. 
Experience working with vector database infrastructure (FAISS, Milvus, Weaviate, Pinecone, PGVector) and traditional search engines (Elasticsearch, OpenSearch)
Familiarity with scalable cloud ML infrastructure (AWS, GCP, Azure). 
Develop and implement CI/CD pipelines. Automate the deployment and monitoring of ML models. 
Knowledge of query understanding, document summarization and other content enrichment strategies
Ability to lead projects independently while providing technical direction to others. 

Nice to Have

Experience designing agentic LLM systems and multi-step retrieval workflows. 
Background in conversational search
Contributions to open-source search, retrieval, or LLM-related projects. 
Interest in publishing or sharing learnings with the broader community. 

Q: What makes you thrive at Klue?

A: We're looking for builders who:

Take ownership and run with ambiguous problems
Jump into new areas and rapidly learn what's needed to deliver solutions
Bring scientific rigor while maintaining a pragmatic delivery focus
See unclear requirements as an opportunity to shape the solution

Q: What technologies do we use?

LLM platforms: OpenAI, Anthropic, open-source models
ML frameworks: PyTorch, Transformers, spaCy
Search/Vector DBs: Elasticsearch, Pinecone, PostgreSQL
MLOps tools: Weights & Biases, MLflow, Langfuse
Infrastructure: Docker, Kubernetes, GCP
Development: Python, Git, CI/CD

Q: What is your working style at Klue?

Hybrid. Best of both worlds (remote & in-office) You and your team will be in the office 2 days a week. 
Our main Canadian hubs are in Vancouver and Toronto, and most of our teams are located in EST and PST. 

Q: What about Compensation & Benefits:

Competitive base salary
Benefits. Extended health & dental benefits that kick in Day 1
Options. Opportunity to participate in our Employee Stock Option Plan
Time off. Take what you need. Just ensure the required work gets done and clear it with your team in advance. The average Klue team member takes 2-4 weeks of PTO per year. 
Direct access to our leadership team, including our CEO

⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️ ⬇️

Not ticking every box? That’s okay. We take potential into consideration. An equivalent combination of education and experience may be accepted in lieu of the specifics listed above. If you know you have what it takes, even if that’s different from what we’ve described, be sure to explain why in your application.

At Klue, we're dedicated to creating an inclusive, equitable and diverse workplace as an equal-opportunity employer. Our commitment is to build a high-performing team where people feel a strong sense of belonging, can be their authentic selves, and are able to reach their full potential. If there’s anything we can do to make our hiring process more accessible or to better support you, please let us know, we’re happy to accommodate.

We’re excited to meet you and in the meantime, get to know us:

🌈 Pay Up For Progress & 50 - 30 Challenge

✅✅ Win-Loss Acquisition (2023)

🐅 Series B (2021)

🏆 Culture, culture, culture!

🎧 Winning as Women & More!

🐝 About Us

🥅 Product Demo Arena

🔍 Glassdoor

🎥 Youtube

☕️ LinkedIn

🦄 Wellfound (AngelList)

Compensation Range: CA$175K - CA$210K",[]
Senior Data Scientist,BDO Canada,"Ottawa, ON",Remote,"About the job
Putting people first, every day

BDO is a firm built on a foundation of positive relationships with our people and our clients. Each day, our professionals provide exceptional service, helping clients with advice and insight they can trust. In turn, we offer an award-winning environment that fosters a people-first culture with a high priority on your personal and professional growth.

Your Opportunity

Innovation and Change team at BDO Canada is looking to onboard a Senior Data Scientist with the ability to work from anywhere in Canada. As a Data Scientist you will be responsible for collecting, analyzing, and interpreting large datasets to drive data-driven decision-making. In addition, you will collaborate with cross-functional teams & service lines to develop, enhance and implement ML predictive models, GEN AI, AI Agent solutions to facilitate in decision making, actionable insights thus achieving productivity and revenue gains and indirectly contributing to the organization's strategic goals.

Job Responsibilities:

Collect, clean, and transform large, complex datasets for analysis.
Build custom machine learning models and natural language processing systems using state-of-the-art techniques.
Leverage tools like TensorFlow, PyTorch, Kubernetes, and Nvidia Triton Servers to develop specialized large language models tailored to business needs.
Train, evaluate, and optimize models for accuracy, explainability, and ethical alignment.
Clearly communicate technical analysis and results to stakeholders using data visualizations, reports, and presentations.
Continuously monitor models and data pipelines in production to ensure quality and reliability.
Stay up to date on the latest advancements in deep learning, NLP, reinforcement learning, and other AI methods.


How do we define success for your role?

You demonstrate BDO's core values through all aspect of your work: Integrity, Respect and Collaboration
You understand your client’s industry, challenges, and opportunities; client describe you as positive, professional, and delivering high quality work
You identify, recommend, and are focused on effective service delivery to your clients
You share in an inclusive and engaging work environment that develops, retains and attracts talent
You actively participate in the adoption of digital tools and strategies to drive an innovative workplace
You grow your expertise through learning and professional development 


Your Experience And Education

M.S. or Ph.D. in Computer Science, Data Science, or related quantitative field.
5+ years’ experience in building and deploying machine learning models in a production environment.
Expertise in Python data science libraries like Pandas, matplotlib, NumPy, and Scikit-Learn.
Proficiency in programming languages such as Python, R, or Scala. Experience with SQL and NoSQL databases is essential.
Knowledge graph
Use Git for version control and collaborative development, ensuring all code is well-documented and follows best practices.
Experience training custom transformer models like Llama and Mistral.
Knowledge of cloud platforms like Azure, AWS, or GCP for model deployment.
Strong verbal and written communication skills.
Passion for translating complex data into actionable insights.


Why BDO?

Our people-first approach to talent has earned us a spot among Canada’s Top 100 Employers for 2025. This recognition is a milestone we’re thrilled to add to our collection of awards for both experienced and student talent experiences.

Our firm is committed to providing an environment where you can be successful in the following ways:

We enable you to engage with how we change and evolve, being a key contributor to the success and growth of BDO in Canada. 
We help you become a better professional within our services, industries, and markets with extensive opportunities for learning and development. 
We support your achievement of personal goals outside of the office and making an impact on your community.


Giving back adds up: Where company meets community. BDO is actively involved in our communities by supporting local charity initiatives. We support staff with local and national events where you will be given the opportunity to contribute to your community.

Total rewards that matter: We pay for performance with competitive total cash compensation that recognizes and rewards your contribution. We provide flexible benefits from day one, and a market leading personal time off policy. We are committed to supporting your overall wellness beyond working hours and provide reimbursement for wellness initiatives that fit your lifestyle.

Everyone counts: We believe every employee should have the opportunity to participate and succeed. Through leadership by our Diversity, Equity and Inclusion Leader, we are committed to a workplace culture of respect, inclusion, and diversity. We recognize and celebrate the valuable differences among each of us, including race, religious beliefs, physical or mental disabilities, age, place of origin, marital status, family status, gender or gender identity and sexual orientation. If you require accommodation to complete the application process, please contact us.

Flexibility: All BDO personnel are expected to spend some of their time working in the office, at the client site, and virtually unless accommodations or alternative work arrangements are in place.

Our model is a blended approach designed to support the flexible needs of our people, the firm and our clients. It’s about creating work experiences that meet everyone’s needs and providing flexibility to adjust when, where and how we work to meet the expectations of our role.

Code of Conduct: Our Code of Conduct sets clear standards for how we conduct business. It reflects our shared values and commitments and includes guiding principles to help us make ethical decisions and maintain trust with each other, our clients, and the public.

With your consent, BDO Canada may use AI technology (Microsoft Copilot) to transcribe during preliminary conversations, solely for the purpose of note-taking and not for other purposes, such as resume review, evaluation or selection of candidates.

More information on BDO Canada’s Privacy Policy can be found here: Privacy Policy | BDO Canada

Ready to make your mark at BDO? Click “Apply now” to send your up-to-date resume to one of our Talent Acquisition Specialists.

To explore other opportunities at BDO, check out our careers page.",[]
Machine Learning Engineer,Workday,"Vancouver, BC",Hybrid,"About the job
Your work days are brighter here.

At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.

At Workday, we value our candidates’ privacy and data security. Workday will never ask candidates to apply to jobs through websites that are not Workday Careers.

Please be aware of sites that may ask for you to input your data in connection with a job posting that appears to be from Workday but is not.

In addition, Workday will never ask candidates to pay a recruiting fee, or pay for consulting or coaching services, in order to apply for a job at Workday.

About The Team

We're working on making machine learning core to Workday's products by building features and capabilities that can be scaled out to hundreds of use cases within Workday. Illuminate: The next generation of Workday AI is unlocking a whole new level of productivity and human potential by accelerating manual tasks, assisting every employee, and ultimately transforming entire business processes. With more than 70 million users under contract generating more than 800 billion transactions a year on our platform, Illuminate leverages the world’s largest and cleanest HR and Finance dataset. The combination of this data—with Illuminate’s ability to understand the context behind it—enables Workday to unlock value in a way no competitor can. Join us as we change the way millions of people work.

About The Role

We are developing ML-powered Information Retrieval, Recommendation and Agentic services and platforms to modernize and simplify user interactions with Workday. As a machine learning engineer, you will help develop tailored user experiences using advanced Agentic AI, LLMs, Knowledge Graphs, personalization, and predictive analysis. You will collaborate with other engineers to deliver ML solutions across Workday’s product ecosystem and utilize current software and data engineering stacks to enable training, deployment, and lifecycle management of a variety of ML models; supervised and unsupervised, and agentic AI powered by LLMs. Additionally, you will develop and deploy new APIs/microservices using docker/kubernetes at scale and leverage Workday’s vast computing resources on rich datasets to deliver transformative value to our customers. Sound like your kind of challenge?

About You

In addition to contributing to feature and service development, you must have an approach of continuous improvement, passion for quality, scale, and security. You must be curious and prepared to question or challenge choices and practices where they don't make sense to you or could be improved. You also should have a product approach and strong intuition around how ML can drive a better customer experience. Lastly, a strong sense of ownership and teamwork are essential to succeed in this role.

Key Responsibilities:

Own exploration, design and execution of advanced ML models, algorithms and frameworks that deliver value to our users.
Apply machine learning techniques including LLMs, knowledge graphs, deep learning including generative models, natural language understanding, topic modeling, GNNs and named entity recognition to analyze large sets of HR and Finance-related text data, and design and launch pioneering cloud based machine learning architectures.
Own the performance, scalability, metric based deployed evaluation, and ongoing data driven enhancements of your products.
Keep abreast of the latest advancements in NLP research, techniques, and tools and apply this knowledge onto ML Features.

Basic Qualifications:

Bachelor’s (Master’s or PhD preferred) degree in engineering, computer science, physics, math or equivalent
3+ years of professional experience in building information retrieval systems and/or graph-based recommendation systems. 
3+ years of hands-on professional experience in developing text-based or graph-based machine learning models for production, including data processing, model fine-tuning, model deployment and model evaluation
2+ years of professional experience in building services to host machine learning models in production at scale 
2+ years of professional experience working with large language models (LLMs), text generation models, and/or graph neural network models for real-world use cases
2+ years of professional experience in machine learning and deep learning frameworks & toolkits such as Pytorch, TensorFlow, and Sklearn
2+ years of professional experience with data engineering and data wrangling using e.g. Pandas and PySpark and other industry tools used to build scalable machine learning systems, such as Kubernetes and Docker
2+ years of professional experience with cloud computing platforms (e.g. AWS, GCP, etc.)
Deep understanding of statistical analysis, unsupervised and supervised machine learning algorithms, and natural language processing for information retrieval and/or recommendation system use cases

Other Qualifications:

Exposure to advanced techniques such as reinforcement learning and graph neural networks
Standout colleague, strong communication skills, with experience working across functions and teams. Ability to teach, mentor and lead through influence
Bonus points for relevant PhD and/or machine learning related research publications

Workday Pay Transparency Statement 

The annualized base salary ranges for the primary location and any additional locations are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please click here.

Primary Location: CAN.BC.Vancouver

Primary CAN Base Pay Range: $122,400 - $183,600 CAD

Additional CAN Location(s) Base Pay Range: $122,400 - $183,600 CAD

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.

Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.

Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.

Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!

,",[]
Generative AI Engineer,GENIE AI,,,"About the job
This job is sourced from a job board. Learn More
About Company

GENIE is an applied AI lab developing Assistive Intelligence (AI) solutions for businesses, governments, and non-profits. Our focus is on translating the massive potential of GenAI, RPA, and AR/VR technologies into a measurable competitive advantage. We firmly believe in the future of interactive technology and view cognition as its most capable instrument. With a track record of firsts, we've partnered with category-leading businesses to pilot ALBIS Experience Studio™. 

About Team

 GENIE comprises a winning team of Subject Matter Experts with over 20 years of specialization in ML/AI, offering world-class strategy, engineering, and design. Our team includes 42+ executives, business experts, ML engineers, RPA engineers, security engineers, data engineers, product designers, researchers, testers, content creators, and sales professionals.

 About the Product

 ALBIS™ Enterprise-grade no code AI Automation studio designed to enable anyone to create and manage experiences across physical, digital, and virtual spaces. ALBIS takes experience management to a whole new standard by leveraging Gen AI, Robotic Automation, IoT, AR/VR, and other advanced tech to enable actions like real-time data checks, outcome prediction, task automation, and autopilot activation.

What’s in it for you?

Opportunity to lead at the forefront of an AI SaaS platform

Rapid growth driven by cutting-edge technologies

Disruptive impact on global industries

Collaboration with diverse teams worldwide

Hands-on experience in a dynamic, fast-paced environment

Mentorship from seasoned professionals

Engagement in impactful projects

Networking opportunities within the industry

Role: Generative AI Engineer

Probationary period: Due to the fact that Generative AI technology is new, we require a 2 months assessment before providing full time offers.

Location: Remote

Role Summary

We are seeking a talented Generative AI Engineer with expertise in natural language processing (NLP) and generative AI technologies, with experience in end-to-end product deployment. As a key member of our team, you will assist with the design, development, and deployment of innovative solutions within the ALBIS™ platform. The ideal candidate possesses deep expertise in Python programming, proficiency in NLP libraries such as NLTK, spaCy, or Transformers, and a proven track record of delivering successful projects involving generative AI models.

Responsibilities

Manage the design, development, and implementation of cutting-edge solutions to enhance user interactions and experiences

Conduct comprehensive analysis of business processes to identify automation and generative AI opportunities

Architect and maintain AI workflows utilizing Python, NLP libraries, and web-based integration scripts

Collaborate closely with stakeholders to gather requirements and offer technical guidance on generative AI initiatives

Ensure the quality, performance, and security compliance of generative AI solutions

Provide expert technical support and troubleshoot issues related to AI model deployments

Stay abreast of emerging technologies and industry trends in generative AI to drive innovation and continuous improvement

Develop and maintain comprehensive project documentation, including design specifications, test plans, and user manuals

Mentor and guide junior engineers and interns in deploying solutions

Qualifications

Bachelor's degree in Computer Science, Information Technology, or a related field

Minimum of 3 years of experience in generative AI and NLP development and implementation

Proficiency in Python programming language

Strong expertise in NLP libraries such as NLTK, spaCy, or Transformers

Excellent analytical and problem-solving skills

Exceptional communication and interpersonal abilities

Proven ability to work both independently and collaboratively in a team environment

Strong attention to detail and ability to manage multiple tasks effectively

Experience in project management and delivery methodologies is advantageous

If you are passionate about leveraging generative AI and NLP to enhance user experiences through innovative solutions, we invite you to apply for this role.

GENIE AI is committed to fostering an inclusive workplace and encourages applications from all qualified individuals regardless of race, religion, national origin, gender, sexual orientation, age, marital status, veteran status, disability, or other characteristics protected by law.

Please submit your application in English.",[]
Senior AI Engineer,Unblocked,,,"About the job
As a Senior AI Engineer working at Unblocked, you will be at the intersection of backend engineering and machine learning, responsible for designing and building scalable data pipelines and ML services optimized for AI workflows.

About Unblocked
Unblocked is a high-growth, well-funded SaaS company that helps answer questions software development teams have about their applications. This allows them to spend less time in meetings/dealing with interruptions and more time writing code.
We are a small team with a track record of building developer tools that solve real problems. We encourage participation in the entire product development process, and you will have the opportunity to help define Unblocked and shape its roadmap, implement the solutions that deliver the experience customers love, and get firsthand feedback from the teams who use what we have built.

About You
You’ve gained extensive experience as a software engineer with a track record of building and shipping products that customers love. You’ve built pipelines and/or services that solve real customer problems, and have been eagerly researching, experimenting and ideally using emergent ML technologies.

What You’ll Do
As a Senior AI Engineer at Unblocked, you’ll play a critical role in designing, building, and scaling the core AI systems that power Unblocked. You’ll work closely with other experienced engineers to:
Build and optimize scalable data pipelines and machine learning services that ingest and process large volumes of structured and unstructured data.
Design and implement end-to-end AI workflows, applying techniques like Retrieval-Augmented Generation (RAG), tool calling, agentic reasoning, and other novel AI techniques to solve complex user problems.
Integrate the latest advancements from leading LLM providers like OpenAI and Anthropic into our platform, experimenting withs emergent model capabilities to deliver cutting-edge experiences to customers.
Actively contribute ideas to product discussions and roadmap planning, influencing not just the ""how"" but also the ""what"" we build - with a relentless focus on the customer.
Share knowledge openly — mentoring teammates, leading design discussions, and continuously learning from others to raise the technical bar for the whole team.
Stay at the forefront of AI/ML innovation, turning new insights and techniques into advantages for Unblocked customers.

Requirements
Based in Vancouver, British Columbia (and be in the office 4 days a week).
Deep curiosity and practical experience with LLM applications, such as text classification, semantic search, summarization, or agent-based reasoning.
Expert-level software development skills in a modern typesafe development language.
Demonstrated leadership of fellow team members in the delivery of a project.
Experience architecting and shipping complex backend systems, ideally in AI/ML or data-heavy domains.
Experience working with large-scale structured and unstructured data.

Desirable Skills
Hands on experience with the latest OpenAI, Anthropic, or open source LLM models.
Understanding of common LLM patterns, such as RAG, routing, chaining and tool calling.
Experience optimizing ML services using evals and fine-tuning.
Continual awareness of the latest AI developments, trends, and best practices.

Culturally, we’re looking for people who are:
Driven to get things done: Anxious to design, build, and ship solutions on aggressive timelines; Willing to take pen to paper and write/sketch ideas, concepts, interactions; We are looking for makers, doers, creators!
Able to play well with others: Comfortable in collaborative work environments; Solid communication skills; Great presenter, but even a better listener; Humble enough to actively solicit and incorporate feedback.
A passionate, tireless, selfless advocate for the end-user: Unwavering in your desire to provide the best experience; Must be an effective champion for the interests of the customer.
Different: Unique skill sets, methodologies, working styles, and ideas; Able to up-level an already strong team; Inspire the broader team with your expertise; Willingness to work outside your comfort zone and learn from others.
An ambitious malcontent: Dissatisfied with the status quo in the world around you; Constantly aware of the potential for improvement with a keen desire to help technology play a more meaningful role in people’s lives.

What’s in it for you?
A competitive base salary.
Equity in the company for eligible candidates, offering the opportunity to share in our long-term success and growth.
Generous medical and dental benefits.
A very flexible vacation policy.
Your choice of Apple hardware to get you started.
Personal growth. We’re a small company where there’s no shortage of different projects to work on.",[]
"Applied Scientist, Recommendations",eBay,"Toronto, ON",Hybrid,"About the job
At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.

Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.

Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.

Our Recommendations team works on delivering item recommendations at scale and in near real time to our buyers on our website and native app platforms. Recommendations are a core part of how our buyers navigate eBay’s vast and varied inventory. Our team develops state-of-the-art recommendations systems, including deep learning based retrieval systems for personalized recommendations, machine learned ranking models, as well as advanced MLOps in a high volume traffic industrial e-commerce setting.

We are exploring a new generation of recommender systems powered by Large Language Models and other emerging paradigms in AI. We are looking for an Applied Scientist and innovator who can drive state of the art ML modeling and get systems into production at eBay scale as we expand our recommendations to live video auctions for eBay Live.

This Is An Opportunity To

Build data pipelines needed to support user input, recall and ranking, model training and inference, working with architects and other engineering peers.
Track the fast paced world of AI and apply innovative techniques to unique and large data sets of unstructured multimodal data representing eBay's vast and varied inventory, and millions of users.
Develop and deploy innovative models in the context of recommender systems.
Deploy big data technology and large scale data pipelines to create magical AI applications and user experiences.
Have a real impact on how shoppers interact with one of the world's largest ecommerce marketplaces to find what they love every day.
Drive marketplace GMB as well as advertising revenue via organic and sponsored recommendations.


Qualifications

MS in Computer Science or related area with 3 years of relevant work experience (or BS/BA with 5 years) in ML / AI / Data Engineering
Experience in production engineering practices and software development in an OO language (Scala, Java, etc.) 
Experience in AI applied research, preferably in Natural Language Processing (NLP), deep learning, and industrial recommender systems
Experience in big data processing and analysis, e.g. Hadoop, SQL, Spark, Pyspark is required
Experience with using cloud services, big data pipelines and databases


Benefits are an essential part of your total compensation for the work you do every day. Whether you’re single, in a growing family, or nearing retirement, eBay offers a variety of comprehensive and competitive benefit programs to meet your needs. Including maternal & paternal leave, paid sabbatical, and plans to help ensure your financial security today and in the years ahead because we know feeling financially secure during your working years and through retirement is important.

Here at eBay, we love creating opportunities for others by connecting people from widely diverse backgrounds, perspectives, and geographies. So, being diverse and inclusive isn’t just something we strive for, it is who we are, and part of what we do each and every single day. We want to ensure that as an employee, you feel eBay is a place where, no matter who you are, you feel safe, included, and that you have the opportunity to bring your unique self to work. To learn about eBay’s Diversity & Inclusion click here: https://www.ebayinc.com/company/diversity-inclusion/

Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.

Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.",[]
Software Engineer,Autopoiesis Sciences,"Toronto, ON",Remote,"About the job
About The Role

At Autopoiesis Sciences, we're building the foundation for scientific superintelligence, AI that can autonomously advance knowledge across every scientific discipline. We're first developing an AI co-scientist that applies the same systematic doubt and verification that drives human scientific breakthroughs, establishing the reasoning capabilities necessary for true scientific autonomy. This represents the critical first stage toward systems that can eventually operate laboratories autonomously, design their own research programs, and pursue discoveries beyond human imagination. Backed by leading venture capital firms and with thousands of scientists from top universities already requesting early access, we're currently preparing to release our AI co-scientist to the scientific community.

Location

Autopoiesis Sciences is headquartered in San Francisco, and we're expanding our engineering team to Toronto to tap into Canada's exceptional AI and engineering talent ecosystem. This is a fully remote position for candidates based in the Greater Toronto Area.

What You'll Build

You'll work on the core platform that powers our AI co-scientist, focusing on:

Scalable systems supporting advanced reasoning and analysis workflows
Interfaces enabling seamless interaction between researchers and AI systems
Robust databases and APIs for scientific literature and research insights
Novel product features leveraging cutting-edge machine learning models
Intuitive interfaces making AI capabilities accessible to the scientific community
Reliable systems for processing and analyzing scientific information at scale

Responsibilities

Design and implement novel features that leverage the latest language model capabilities, building both backend integration and frontend user experiences
Monitor emerging LLM developments from major providers and translate breakthrough capabilities into full-stack product improvements
Develop scalable web applications from database to user interface, serving researchers using advanced AI capabilities
Create robust backend infrastructure and corresponding frontend interfaces supporting complex analysis and reasoning workflows
Bridge the gap between AI research and practical scientific applications through thoughtful full-stack engineering
Work closely with researchers, product leaders, and designers to identify opportunities and ship complete solutions from API to UI
Optimize both frontend performance and backend reliability to handle demanding computational workloads

Qualifications

Strong full-stack development experience with ability to build complete applications from database design to user interface
Proficiency across our tech stack: Python, React, TypeScript, Docker, GCP, Kubernetes, PostgreSQL
Hands-on experience integrating language models into production applications, including both backend API integration and frontend user experiences
Understanding of model selection tradeoffs and how to surface complex AI capabilities through intuitive user interfaces
2+ years of software engineering experience with a track record of shipping quality products across the full stack
Self-directed approach with strong ownership mindset and ability to drive end-to-end projects from conception to deployment
Passion for building complete product experiences that solve meaningful problems for users
Experience with distributed systems, database design, frontend frameworks, and production deployment strategies

Get To Know Us

We're a dedicated team of scientists, researchers, and engineers who believe deeply in the transformative potential of our work. You'll work closely with our founders, Joseph Reth (Attended University for CS at 14, former DARPA) and Dr. Eike Gerhardt (University of Tübingen PhD, University of Tübingen staff), and our Chief Scientist Dr. Larry Callahan (University of Chicago PhD, former FDA, former NIH).

Application Process: Due to the high volume of automated applications, we only accept applications through LinkedIn as it helps us connect with genuine candidates. We have systems in place to detect automated submissions and strongly advise against using bots or automated tools in your application process. Please be human in your approach.

Equal Opportunity: Autopoiesis Sciences, Inc. is an equal opportunity employer committed to diversity and inclusion. We welcome applications from all qualified candidates regardless of race, gender, age, religion, sexual orientation, or any other legally protected characteristics.",[]
AI / ML Engineer OR Data Scientist,Veracity Software Inc,"Ontario, Canada",Remote,"About the job
Role: AI / ML Engineer OR Data Scientist

Location: Canada / USA - Remote

Long Term Contract

Expi: 3+ years

Bachelor's degree in Computer Science, Engineering, Mathematics, related field, or equivalent experience
3+ years of professional experience (or equivalent) in software engineering, AI/ML development (ideally including a Master's or Ph.D. in Computer Science, ML, Data Science, or a related field)
Practical experience and theoretical knowledge of language technologies such as: dialogue/conversational systems, NLP, and Information Retrieval
Strong foundation in data structures, algorithms, and software engineering principles. 
Proficiency in Python and relevant deep learning frameworks; training (e.g. PyTorch, Tensorflow, JAX, Hugging Face Transformers/Adapters), serving (e.g., Hugging Face TGI//outlines, vLLM)
Experience with LLM model development and deployment ideally including experience with model distillation, supervised fine-tuning using RLHF/DPO, and automatic prompt tuning (e.g. DSPy, TextGrad)
Experience with cloud deployment of ML systems (e.g., AWS, GCP, Azure) including and open systems (e.g. Docker and Kubernetes) and associated ML services. 
Strong analytical and problem-solving skills
Experience structuring and running data-backed experiments
Strong written and verbal communication skills",[]
