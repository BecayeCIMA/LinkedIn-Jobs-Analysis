Job Title,Company,City,Work Mode,Description,Skills
MLOps Engineer,Loopio,"Toronto, ON",Remote,"About the job
Take your career to new heights with Loopio! 🚀✨

We’re looking for a skilled and motivated MLOps Engineer to help scale and productionize the machine learning systems that power Loopio’s intelligent product features. In this role, you’ll work closely with ML Engineers, Data Scientists, and Backend Engineers to build the pipelines, infrastructure, and tooling needed to deliver high-impact ML models to our users; reliably, efficiently, and at scale.

You’ll be a critical part of enabling our AI/ML roadmap, from intelligent search and content suggestions to document automation and agent copilots, by ensuring models can be deployed, monitored, and continuously improved in production environments.

This is a great opportunity to grow your expertise in applied MLOps, contribute to high-leverage systems, and be part of a fast-moving, collaborative team working at the intersection of ML, engineering, and product.

What You’ll Be Doing

Pipeline & Workflow Development: Build and maintain robust ML pipelines for training, evaluation, and deployment. Automate routine workflows and support reproducible, auditable experimentation.
Model Deployment & Inference: Package and deploy models into production environments using tools like Docker, Kubernetes, and SageMaker. Build REST/gRPC services to serve models in real-time or batch.
Monitoring & Reliability: Help implement systems to monitor model health in production, detect drift, and log predictions. Contribute to alerting and dashboarding that helps the team maintain trust in deployed models.
CI/CD for ML: Work within our CI/CD systems to support model validation, promotion, and rollback. Help build safe, automated workflows for taking models from development to deployment.
Collaboration & Support: Partner with ML Engineers and Data Scientists to bring ML systems into production. Contribute to shared libraries, improve developer experience, and help debug operational issues. Partner with Infra and DevOps teams to understand their tooling deeply in order to help implement ML systems and related cloud architecture.

What You’ll Bring To The Team

MLOps Experience: 2+ years of experience working in ML operations, ML engineering, or related infrastructure roles. Familiarity with deploying ML models and automating ML pipelines.
Cloud & Infrastructure Skills: Comfort working with AWS (or similar cloud environments), Docker, and Kubernetes. Experience with workflow orchestration tools like Airflow, Dagster, or Kubeflow is a plus.
Software Engineering Foundation: Strong Python development skills, with a solid understanding of software engineering practices (testing, logging, version control, code review).
Model Deployment & Monitoring Tools: Experience with tools such as MLflow, SageMaker, TensorFlow Serving, or TorchServe. Bonus: hands-on experience implementing model monitoring or drift detection systems.
Team Collaboration: Comfortable working cross-functionally with technical and non-technical stakeholders. Curious, communicative, and open to feedback. Willing to learn from others and share what you know.
Growth Mindset: You’re excited about learning the ins and outs of ML systems in production. You bring energy, ownership, and a desire to build things that are both elegant and effective.

Where You’ll Work 📍

Loopio is a remote-first workplace because we recognize the advantages of working flexibly. We are HQ’d in Canada, with established hub regions around the world where we hire from.
Our employees (or Loopers, as we call ourselves!) live and work in 🇨🇦 Canada (British Columbia and Ontario), 🇬🇧 London, and 🇮🇳 India (specifically in Gujarat, Maharashtra, and Bengaluru).
The majority of our team is based in ON and BC, which means these employees live and work remotely within a 300km radius of Toronto (within Ontario) and Vancouver (Within BC). 
We offer flexible co-working locations available to Loopers in ON and BC. Those based in ON have the option of working out of our convenient co-working space located in the heart of Downtown Toronto and a 12-minute walk from Union Station. BC Loopers have the option to work centrally in Vancouver. It is whatever works best for you!
You’ll collaborate with your teams virtually across the UK, India, and North America (we’re just a Zoom call and Slack message away!) with core sync hours and focus time for headsdown work 🙇🏾 during the workday
We encourage asynchronous collaboration to effectively work as a global #OneTeam!

Why You’ll ♥️ Working at Loopio

Your manager supports your development by providing ongoing feedback and regular 1-on-1s, we leverage Lattice for our 1:1s and performance conversations 
You will have the opportunity to elevate 🪄 your craft and the opportunity to explore your creativity, with a dedicated professional mastery allowance for more learning support! We encourage experimentation and innovative thinking to drive business impact.
We offer a wide range of health and wellness benefits to support your physical and mental well-being, starting day 1️⃣ with Loopio.
We’ll set you up to work remotely with a MacBook laptop 🍏, a monthly phone and internet subsidy, and a work-from-home budget to help get your home office all set up. 
You’ll be joining a supportive culture that has thoughtfully built out opportunities for connections in a remote first environment.
Participate in 🎤 townhalls, AMA (Ask-Me-Anything), and quarterly celebrations to celebrate the big wins and milestones as #oneteam!
Our four active Employee Resource Groups offer opportunities for employees to learn and connect year-round. 
You’ll be a part of an award-winning workplace 🏆with an opportunity to make a big impact on the business.

Questioning your qualifications? Read this ‼️ Hi there, we recognize that all too often, potential candidates don’t apply for a position simply because they don’t hit every single criteria included in the job description—particularly members of underrepresented groups.

Whether or not your experience ✅ checks off all the boxes on a job posting, we still encourage you to apply to ensure that your application receives a review from our team. We understand that a resume can only showcase so much during the applicant stage, so we've created prompts in the application for you to share more about yourself. If you've made a career transition (or a few!), you’re self taught in a new role, or you have skills/experience you’d like to highlight, we want to hear more about what you could bring to the table.

AI in Recruitment 👩🏻‍💻  At Loopio, we leverage artificial intelligence (AI) technology to enhance our recruitment process. These tools assist with tasks such as resume screening, drafting preliminary job descriptions, generating initial interview questions, and occasionally sourcing prospective candidates. However, AI is never used to make final hiring decisions; our use of AI serves to support repetitive and administrative tasks in order to streamline our hiring and recruitment workflows. We are committed to the responsible use of AI in our hiring practices, prioritizing both an improved candidate experience and operational efficiency. Our standardized hiring practices remain focused on reducing biases, with all key hiring decisions solely made by our team. We continuously review and refine our hiring practices to align with industry best practices and evolving legal guidelines

Loopio is an equal opportunity employer that is deeply committed to building equitable workplaces that are diverse and inclusive. We actively encourage candidates from all backgrounds and lifestyles to consider us as a future employer. Please contact a member of our Talent Experience team (work@loopio.com) should you require accommodations at any point during our virtual interview processes.",[]
ML Operations Engineer,Benevity,,,"About the job
Meet Benevity 

Benevity is the way the world does good, providing companies (and their employees) with technology to take social action on the issues they care about. Through giving, volunteering, grantmaking, employee resource groups and micro-actions, we help most of the Fortune 100 brands build better cultures and use their power for good. We’re also one of the first B Corporations in Canada, meaning we’re as committed to purpose as we are to profits. We have people working all over the world, including Canada, Spain, Switzerland, the United Kingdom, the United States and more!

We’re seeking an experienced MLOperations Engineer to lead operational excellence and infrastructure development within our AI team, focusing on the full machine learning lifecycle across classical ML and deep learning systems. You’ll be instrumental in designing, deploying, and managing scalable ML pipelines and platforms in our B2B SaaS environment, ensuring that our ML services are production-ready, secure, reliable, and observable.

This role operates within a Scrum team and involves close collaboration with ML researchers, data scientists, platform engineers, and DevOps teams to build robust ML solutions integrated into Benevity’s product ecosystem.

 What You’ll Do 

 ML/AI Platform Engineering & Operations 

Design and manage cloud-native infrastructure for ML model training, evaluation, deployment, and monitoring on platforms like Azure ML, SageMaker, Vertex AI, or Databricks.
Build and maintain Infrastructure-as-Code (IaC) using tools such as Terraform to support reproducible, scalable, and auditable ML deployments.
Develop end-to-end MLOps pipelines supporting continuous integration and delivery (CI/CD), model versioning, automated testing, and retraining workflows.
Implement observability practices including logging, monitoring, and alerting to ensure model and system performance in production.
Optimize infrastructure for cost-efficiency, model latency, throughput, and reliability.
Ensure security of ML pipelines and services through authentication, authorization, rate-limiting, and auditing mechanisms.

 Operational Excellence & Observability 

Instrument ML systems with metrics, traces, logs, and dashboards to support performance monitoring and issue detection.
Participate in incident management, including on-call rotations, writing operational runbooks, and conducting postmortems to drive continuous improvement.
Apply security and compliance best practices to data handling, model outputs, and system operations, aligning with regulatory standards.

 Integration & Collaboration 

Work closely with data scientists to move models from experimentation to production.
Collaborate with software engineers to integrate ML capabilities into core products such as recommendation engines, personalization, or predictive analytics.
Partner with DevOps, Security, and SRE teams to maintain compliance (e.g., SOC2, GDPR) and platform readiness.
Engage in architectural reviews and contribute to design decisions around machine learning infrastructure and APIs.

 Scrum Delivery & Continuous Improvement 

Actively participate in scrum ceremonies, including sprint planning, standups, and retrospectives.
Provide effort estimates, contribute to backlog grooming, and deliver quality features and improvements in a continuous delivery cycle.
Maintain clear documentation of ML infrastructure, processes, and decisions for transparency and collaboration.

 Innovation & Learning 

Stay current with advancements in GenAI infrastructure, large language models, and emerging patterns like Retrieval-Augmented Generation (RAG), vector search, and agent-based architectures.
Stay informed about emerging trends in MLOps, model deployment, monitoring, and data-centric AI practices.
Contribute to the evaluation and benchmarking of deployed models for accuracy, fairness, and efficiency.
Share insights, tools, and methodologies to support the broader AI/ML engineering community at Benevity.

 What You’ll Bring 

A degree in Computer Science, Engineering, or a related field.
3+ years of experience in DevOps, MLOps, or SRE roles with hands-on responsibility for ML model deployment and lifecycle management.
Experience with cloud ML platforms such as AWS SageMaker, GCP Vertex AI, Azure ML, or Databricks.
Proficiency in IaC tools (Terraform, CloudFormation) and workflow orchestration (Airflow, Kubeflow, or MLflow).
Strong Python skills for scripting, automation, and interaction with ML APIs and orchestration tools.
Familiarity with observability tools like Prometheus, Grafana, Datadog, or cloud-native monitoring (CloudWatch, GCP Monitoring, Azure Monitor).
Experience implementing CI/CD pipelines for ML using GitHub Actions, Jenkins, ArgoCD, or similar.
Solid understanding of data security, model governance, and compliance in the context of ML systems.
Ability to diagnose complex issues across infrastructure, models, and data flows.
Excellent communication skills and a collaborative mindset to work cross-functionally in scrum teams.

 Technical Skills & Expertise 

Cloud Platforms: Azure ML, GCP Vertex AI, AWS SageMaker, Databricks
MLOps Tooling: MLflow, Kubeflow Pipelines, Airflow, TFX, DVC, Docker, Kubernetes, Triton Inference Server
CI/CD & Infrastructure: Terraform, GitHub Actions, Jenkins, ArgoCD, GitOps
Monitoring & Observability: Prometheus, Grafana, OpenTelemetry, Datadog, cloud-native monitoring tools
Languages: Python (primary), Bash. Bonus: Go, Rust, or Java for backend systems
APIs & Streaming: REST, gRPC, Kafka, Pub/Sub, Kinesis
Security & Compliance: IAM, Kubernetes RBAC, audit logging, TLS/SSL, VPC configurations, KMS, OPA, and compliance standards like SOC2, GDPR, and HIPAA

 Discover your purpose at work 

We’re not employees, we’re Benevity-ites. From all locations, backgrounds and walks of life, who deserve more …

Innovative work. Growth opportunities. Caring co-workers. And a chance to do work that fills us with a sense of purpose.

If the idea of working on tech that helps people do good in the world lights you up ... If you want a career where you’re valued for who you are and challenged to see who you can become …

It’s time to join Benevity. We’re so excited to meet you.

 Where we work 

At Benevity, we embrace a flexible hybrid approach to where we work that empowers our people in a way that supports great work, strong relationships, and personal well-being. For those located near one of our offices, while there’s no set requirement for in-office time, we do value the moments when coming together in person helps us build connection and collaboration. Whether it’s for onboarding, project work, or a chance to align and bond as a team, we trust our people to make thoughtful decisions about when showing up in person matters most.

 Join a Company Where DEIB Isn’t a Buzzword 

Diversity, equity, inclusion and belonging are part of Benevity’s DNA. You’ll see the impact of our massive investment in DEIB daily — from our well-supported employee resources groups to the exceptional diversity on our leadership and tech teams.

We know that diverse backgrounds, experiences, skills and passions are what move our business and our people forward, so we're committed to creating a culture of belonging with equal opportunities for everyone to shine.

That starts with a fair and accessible hiring process. If you want to feel seen, heard and celebrated, you belong at Benevity.

Candidates with disabilities who may require accommodations throughout the hiring or assessment process are encouraged to reach out to accommodations@benevity.com.",[]
Staff MLOps Engineer,Inworld AI,"British Columbia, Canada",Remote,"About the job
About Inworld
At Inworld, we believe the processes of building, scaling, and evolving applications are monsters that consume value before it can reach users. Our mission is to solve evolution and transform static software into AI systems that autonomously evolve to better serve their users. We are building an intelligent runtime to conquer these monsters and make this vision a reality.

We are backed by investors such as Intel Capital, Microsoft’s M12 fund, Lightspeed Venture Partners, Section 32, BITKRAFT Ventures, Kleiner Perkins, Founders Fund, and First Spark Ventures. Our technology is used by industry leaders like NVIDIA, Epic Games and Microsoft Xbox. Inworld has been recognized by CB Insights as one of the 100 most promising AI companies globally and has been named one of LinkedIn's Top 10 Startups in the USA.

About The Role
At Inworld, we’re building the AI framework behind the next generation of real-time, immersive applications. As a Staff MLOps Engineer, you’ll design, build and scale the infrastructure that powers intelligent AI agents across massive consumer experiences while ensuring performance, reliability, and speed at every level.

What You’ll Do
Build and scale MLOps systems to streamline the end-to-end ML model lifecycle on the Inworld AI platform, from training to deployment.
Design and implement robust model training, evaluation, and release pipelines.
Collaborate cross-functionally with ML and backend teams to design, deploy, and maintain scalable secure infrastructure for Inworld’s AI Engine and Studio.
Facilitate a ""you build it, you run it"" culture by providing the necessary tools and processes for monitoring the reliability, availability, and performance of services.
Manage CI/CD pipelines to ensure smooth and efficient code integration and deployment.
Identify and implement opportunities to enhance engineering speed and efficiency.
Provide technical leadership in ML engineering best practices, raise the technical bar, and mentor junior engineers in MLOps principles.

Expected Experience
7+ years of software engineering experience, with 5+ years of infrastructure-as-code
Proficiency in managing Kubernetes clusters and applications, including creating Helm charts/Kustomize manifests for new applications.
Experience in creating and maintaining CI/CD pipelines for both applications and infrastructure deployments (using tools like Terraform/Terragrunt, ArgoCD, GitHub Actions, Ansible, etc.).
Deep knowledge of at least one major cloud provider (Google Cloud Platform, Microsoft Azure, Oracle Cloud).
Proficient in at least one backend programming/scripting languages such as Golang, Python, and Bash.
Knowledge of SLURM or similar job schedulers for distributed training.
Experience with data pipeline and workflow management tools
Familiarity with open source LLM and open source serving solution (e.g. vLLM or llama.cpp, kserve, etc) is a plus.
Experience with bare metal GPUs (optional).
Desire to work at a fast-growing Series A startup, comfortable with uncertainty, owning and scaling new products, and embracing an experimental and iterative development process.

The base salary range for this full-time position is CAD $150,000 - $240,000. In addition to base pay, total compensation includes equity and benefits. Within the range, individual pay is determined by work location, level, and additional factors, including competencies, experience, and business needs. The base pay range is subject to change and may be modified in the future.",[]
Technology Lead – Analytics,Infosys,,,"About the job
Job Description

Infosys is seeking a MLOPS Engineer with strong background in designing and deploying machine learning models using MLOPS framework. Ideal candidate will work with clients to understand the issues they face, diagnose problems, design solutions and facilitate solution deployment on Azure ML. One will also have the opportunity to shape value-adding consulting solutions for clients by connecting various functions of cloud components. Ideally the candidate uses understanding of the problem to arrive at multiple solution alternatives keeping in mind the various stakeholders and assess the pros and cons of all the alternatives to arrive at the optimal solution.

Required Qualifications

 Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education. 
 All applicants authorized to work in the United States are encouraged to apply. 
 Candidate must live within commuting distance of Toronto, ONTARIO or Infosys Hub Locations ins Canada or be willing to relocate. 
 At least 3 years of experience in Information Technology 
 At least 2 years of experience in Information Technology in MLOPS 
 At least 2 years of experience Python Programming for ML Model deployment with Clean code standards 
 At least 2 years of experience in AZURE or GCP Cloud environment 
 Azure Certified – DP100, AZ/AI900 or GCP equivalent including DevOps certification 
 Professional experience setting up MLOPs Framework, monitoring and dashboarding of MLOPs runs 
 At least 2 years of implementation experience in DevOps 
 At least 2 years of experience in MLOPS Framework, industry standards and operations KPI 

Preferred Qualifications:

 Experienced in Agile way of working, manage team effort and track through JIRA 
 High Impact client communication 
 Domain experience in Retail, CPG and Logistics 
 Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs 

The job may entail extensive travel. The job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face.

Estimated annual compensation range for the candidate based in the below location will be:

Ontario: $ 89004 to $ 115491.

About Us

Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.

Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.",[]
MLOps Engineer - Machine Learning Platform - Toronto,Goldman Sachs,,,"About the job
Job Description

What We Do 

At Goldman Sachs, our Engineers don’t just make things – we make things possible.  Change the world by connecting people and capital with ideas.  Solve the most challenging and pressing engineering problems for our clients.  Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action.  Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.

Engineering, which is comprised of our Technology Division and global strategists’ groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions.  Want to push the limit of digital possibilities?  Start here.

 Who We Look For

We are seeking a skilled and motivated engineer to join our Artificial Intelligence Platforms organization as an MLOps Engineer on our Machine Learning Services team. In this role, you will be part of an expert team responsible for our firmwide model registry and real-time serving products in the cloud. A key focus of this position will be on the implementation and optimization of Large Language Models (LLMs) which are pivotal in achieving our Generative AI agenda.

Key Responsibilities

Deliver scalable, efficient, secure and automated processes for building, deploying and monitoring Machine Learning models

Enable solutions that provide business customers with the ability to leverage the latest and greatest AI/ML infrastructure, frameworks, and tooling to deliver high impact outcomes

Develop and demonstrate deep subject matter expertise on how to optimize machine learning model deployments to scale to the specific needs of each business customer

Deliver high quality, production ready code leveraging CI/CD best practices

Author and maintain high quality documentation for both the engineering team as well as for business customers

Remain up to date with the latest advancements in AI/ML frameworks and related technologies

Basic Qualifications

2+ years of experience in building production software using Python

1+ years of experience as an ML Ops Engineer supporting the production implementation of models

1+ years of experience working with containers (e.g. Docker)

1+ years of experience with Unix-based systems

1+ years of experience delivering solutions in a public cloud (e.g. AWS, GCP)

Strong desire to keep learning and stay up to date with the latest and greatest developments in the model inference domain, especially for Large Language Models (LLMs)

Strong problem-solving skills and the ability to work effectively in a fast-paced and collaborative environment

Preferred Qualifications

Strong understanding of the end-to-end Model Development Lifecycle (MDLC)

Strong understanding of Python frameworks, packages and tools

Experience building Machine Learning models with frameworks such as PyTorch and TensorFlow

Experience building containerized runtime environments for model serving (e.g. vLLM, SGLang, TensorRT, Triton, AWS Multi Model Server)

Experience with infrastructure-as-code tools, such as Terraform or CloudFormation

Experience with Kubernetes and other container orchestration platforms in the public cloud (e.g. AWS, GCP)

Excellent communication skills and the ability to articulate complex technical concepts to both technical and non-technical stakeholders.",[]
Sr MLOps Engineer,Fidelity Canada,,,"About the job
Job Description

You will be working on a flexible hybrid schedule as part of Fidelity’s dynamic working arrangement.

Current work authorization for Canada is required for all openings.

At Fidelity, we’ve been helping Canadian investors build better financial futures for over 35 years. We offer individuals and institutions a range of trusted investment portfolios and services - and we’re constantly seeking to find new and better ways to help our clients. As a privately owned company, we boldly embrace innovation in all areas as we continue to grow our business into the future. Working with us means you’ll be part of a diverse and dedicated group of people who make a real difference for our clients and communities every day. You’ll have a wide range of opportunities to grow and develop your career in an inclusive environment where you’ll feel valued and supported to be your best - both personally and professionally.

How You’ll Make An Impact

The Sr MLOps Engineer is responsible for having a strong aptitude for understanding complex business problems and translating their technical knowledge into practical, implementable solutions that will drive high impact business value. The Engineer works closely with other team members to ensure application availability and system maintenance. This individual acts as the technical developer and lead on all assigned projects.

What You Will Do

Design, build, and maintain end-to-end Machine Learning pipelines in AWS
Develop CI/CD workflows for deploying ML models, including LLMs
Manage and optimize ML model training, evaluation, and deployment at scale
Automate Model monitoring, drift detection, and retraining workflows
Work with data engineers to build and maintain feature stores and data pipelines
Optimize model inference for latency and scalability in cloud environments
Implement MLOps best practices for reproducibility, versioning, and governance
Collaborate with ML engineers and data scientists to deploy LLM-based applications efficiently
Secure ML workloads with appropriate access controls and compliance standards

Required Skills & Qualifications

8+ years of experience in software development with ML Ops, DevOps, or Cloud Engineering with a focus on ML pipelines
Strong expertise in AWS services (SageMaker, Lambda, S3, Step Functions, ECS, EKS, etc.)
Experience with ML model lifecycle management and monitoring frameworks
Proficiency in Python and ML frameworks like TensorFlow, PyTorch, Hugging Face Transformers
Experience deploying LLMs and optimizing them for inference
Hands-on experience with Kubernetes, Docker, and serverless architectures
Familiarity with GitOps, Terraform, or other IaC tools
Experience with feature engineering and real-time inference
Knowledge of MLOps frameworks like MLflow, Kubeflow, or Vertex AI
Strong problem-solving skills and ability to work in agile, cross-functional teams

The Expertise You Bring

Strong organization and planning skills
Communication skills (verbal and written). Ability to effectively communicate technical jargon to business users
Analytical skills. Ability to generate options to solve complex and/or multidimensional problems in a timely manner
Ability to manage multiple priorities
Ability to work independently as well as part of a team
Leadership skills. Ability to lead and influence others
Excellent technical skills

Education

Completed University degree (preferably in computer science) or equivalent working experience

Some of the ways we’ll help you feel valued and supported as part of our team

Flexible working arrangements - 100% remote, hybrid, and in office options
Competitive total compensation, including company contributions to your group RRSP without a matching requirement from you
Comprehensive health benefits that start on your first day, with 100% employer-paid premiums, that include up to $5000 annually for mental health services and therapy
Parental leave top-up to 100% of your salary for a period of 25 weeks
Up to $650 for home office equipment
Generous time off policy, including 2 paid days annually to volunteer at a charity of your choice
Diversity and inclusion programs, including an active network of Employee Resource Groups
Extensive professional development opportunities, including access to over 11,000 training and development courses, tuition reimbursement, and monetary rewards for completing a required designation 
We care a lot about fostering a compassionate, people-centric culture, and are proud to have been named one of Canada’s Top 100 employers for the last five years

Fidelity Canada is an equal opportunity employer 

Fidelity Canada is committed to fostering a diverse and inclusive workplace. We will consider all qualified applicants for employment regardless of race, color, religion, sex, sexual orientation, gender identity or expression, national or ethnic origin, age, disability, family status, protected veterans’ status, Aboriginal/Native American status or any other legally-protected ground.

Accommodation during the application process

Fidelity Canada welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in the selection process. If you require an accommodation, please email us at FidelityCanadaStaffing@fidelity.ca.

No telephone inquiries or agencies please. We thank all applicants for their interest, please be advised that only those selected for an interview will be contacted.

Why Work at Fidelity?

We are proud to be recipients of the following

Awards

 Canada's Top 100 Employers 
 Greater Toronto's Top Employers
 Canada's Top Family-Friendly Employers
 Canada's Top Employers for Young People
 Great Place To Work® Certified 
 Best Workplaces for Inclusion
 Best Workplaces for Mental Wellness
 Best Workplaces for Today's Youth
 Best Workplaces for Women
 Best Workplaces in Financial Services & Insurance
 Best Workplaces in Ontario
 Best Workplaces with Most Trusted Executive Teams
 LinkedIn Top Companies in Canada
 Human Resource Director (HRD) - Best Place To Work 
 HRD - 5-Star Benefit Program
 HRD - 5-Star Diversity & Inclusion Employer

Designations

 Canadian Compassionate Companies – Certified
 Benefits Canada's Workplace Benefits Award - Future of Work Strategy
 TalentEgg National Recruitment Excellence Award - Special Award for Diversity & Inclusion in Recruiting
 Canadian HR Reporter's Most Innovative HR Team",[]
ML Engineer,Sanofi,"Toronto, ON",Hybrid,"About the job
Reference No. R2791160

Position Title: MLOps Engineer

Department: MLOps Engineering

Location: Downtown Toronto, Ontario, Hybrid (3 days onsite)

About The Job

Our Hubs are a crucial part of how we innovate, improving performance across every Sanofi department and providing a springboard for the amazing work we do. Build a career and you can be part of transforming our business while helping to change millions of lives. Ready?

Sanofi has recently embarked on a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions, to accelerate R&D, manufacturing and commercial performance and bring better drugs and vaccines to patients faster, to improve health and save lives.

We are an innovative global healthcare company with one purpose: to chase the miracles of science to improve people’s lives. We’re also a company where you can flourish and grow your career, with countless opportunities to explore, make connections with people, and stretch the limits of what you thought was possible. Ready to get started?

About You

You are a dynamic MLOps Engineer interested in challenging the status quo to ensure seamless AI/ML Engineering Operations that scale up Sanofi's AI solutions for the patients of tomorrow. You are an influencer and a future leader who has deployed AI/ML solutions with technically robust lifecycle management and infrastructural support. You are deeply interested in improvement opportunities and always thrive to demonstrate ability to deliver using AI/ML Engineering skills while working across the full stack and moving fluidly between programming languages and technologies.

Main Responsibilities

Work in an agile development pod to design, build and maintain cloud hosted AI/ML products with automated pipelines that run, monitor, and retrain ML Models 
Implement automated ML pipelines (e.g., training and inference) working closely with other peers e.g., data scientists and data engineers 
Support life cycle management of deployed AI/ML apps (e.g., new releases, change management, monitoring and troubleshooting) 
Work as subject matter expert in MLOps (e.g., develop and maintain enterprise standards, user guides, release notes, FAQs) 
Build processes and reusable components supporting seamless ML Operations (e.g., app monitoring, troubleshooting, life cycle management and customer support) 
Walk stakeholders and solution partners through solutions and reviewing product change and development needs 
Maintain effective relationships with app userbase to develop education and communication content as per life cycle events 
Research and gain expertise on emerging tools and technologies. An enthusiasm to ask questions and try and learn new things is essential 

Key Technical Skills

University degree (Bachelor, Master or PhD) in Computer Science, Information Systems, Software Engineering, or another quantitative field. 
Minimum 2 years of experience in building, deploying, monitoring and maintaining AI/ML applications utilizing cloud technologies (e.g., AWS, GCP, Azure, Snowflake etc.). 
Ability to work across the full stack and move fluidly between programming languages (e.g., Python) and MLOps technologies (e.g. Github, Argo, Metaflow, WandB, Snowflake, AWS SageMaker) 
Experience in implementing CI/CD pipelines for AI/ML driven app development 
Experience in building and deploying apps with large scale data and ML pipelines 
Ability to assess new technologies and compile architecture decision records (ADRs) 
Experience working in an agile team supporting and working with cross-functional teams 
Knowledge of relational (e.g., Postgres SQL) and non-relational databases (e.g., Graph database, Vector Database etc.) 
Experience in visualization technologies (e.g. Python DASH, Tableau, PowerBI) 
Experience in developing and maintaining backend APIs (e.g. REST) 
Experience in provisioning cloud infrastructure leveraging Infrastructure as a code tools (e.g.: Docker, Kubernetes, Terraform) 
Experience in cloud-based ML engineering in an industrial setting within a global organization (technology company preferred) 
Experience in working within compliance (e.g. quality, regulatory - data privacy, GxP, SOX) and knowledge in cybersecurity is a plus 

Why Choose Us? 

Bring the miracles of science to life alongside a supportive, future-focused team.
Discover endless opportunities to grow your talent and drive your career, whether it’s through a promotion or lateral move, at home or internationally.
Enjoy a thoughtful, well-crafted rewards package that recognizes your contribution and amplifies your impact.
Take good care of yourself and your family, with a wide range of health and wellbeing benefits including high-quality healthcare, prevention and wellness programs

This position is for a current vacant role that we are actively hiring for.

Sanofi is an equal opportunity employer committed to diversity and inclusion. Our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. We welcome and encourage applications from all qualified applicants. Accommodations for persons with disabilities required during the recruitment process are available upon request.

#GD-SP

#DBBCA

All compensation will be determined commensurate with demonstrated experience. Employees may be eligible to participate in Company employee benefit programs, and additional benefits information can be found here.

Les employés peuvent être admissibles à participer aux programmes d'avantages sociaux de l'entreprise. Des informations supplémentaires sur les avantages sociaux peuvent être trouvées ici.

Pursue Progress. Discover Extraordinary.

Join Sanofi and step into a new era of science - where your growth can be just as transformative as the work we do. We invest in you to reach further, think faster, and do what’s never-been-done-before. You’ll help push boundaries, challenge convention, and build smarter solutions that reach the communities we serve. Ready to chase the miracles of science and improve people’s lives? Let’s Pursue Progress and Discover Extraordinary – together.

At Sanofi, we provide equal opportunities to all regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, protected veteran status or other characteristics protected by law.",[]
Senior MLOps Engineer,Clio,"Vancouver, BC",Hybrid,"About the job
Clio is more than just a tech company–we are a global leader that is transforming the legal experience for all by bettering the lives of legal professionals while increasing access to justice.

Summary:

We are currently seeking a Senior MLOps Engineer to join our Engineering team. This role is available to candidates across Canada. If you are local to one of our hubs (Burnaby, Calgary, or Toronto) you will be expected to be in office minimum two days per week for our Anchor Days.

What your team does:

Our MLOps team builds and operates the scalable infrastructure and robust platforms that power GenAI solutions across the company. We blend deep AI and ML expertise with strong software engineering and cloud infrastructure skills to enable the entire lifecycle of machine learning and generative AI - spanning experimentation, deployment, monitoring, and continuous improvement. By applying best practices in CI/CD, observability, cost optimization, and model governance, and leveraging state-of-the-art tools and frameworks, we ensure our AI systems are reliable, performant, and aligned with business goals. We partner closely with data scientists, engineers, and product teams to accelerate the delivery of impactful AI capabilities.

What a day in the life might look like:

Build and deploy LLM-based solutions that help Clio’s clients save time and improve operational efficiency.
Collaborate cross-functionally with engineering, product management, operations, and data science to identify and develop new ML-driven features.
Work agilely alongside MLOps, MLE, and full stack developers on diverse projects spanning multiple engineering teams across three countries.
Evaluate and integrate new ML tools and frameworks to accelerate experimentation and optimize operations.
Troubleshoot and resolve production issues such as data drift and model latency using observability tools and logs.
Participate in design reviews and contribute to architectural decisions shaping Clio’s AI platforms.
Engage in code reviews within your team and across the company, providing and receiving constructive feedback to maintain high standards.
Continuously learn, challenge yourself, and grow as a machine learning expert while mentoring and collaborating with teammates.

What you may have:

Strong Python or Ruby development skills, with experience building production-grade applications, services, or ML tooling.
Expertise in cloud infrastructure (AWS, GCP, or Azure), including Kubernetes, and infrastructure-as-code (Terraform, Helm, or similar).
Experience with CI/CD and automating model training, testing, and deployment pipelines.
Solid understanding of machine learning and GenAI concepts, workflows, and lifecycle management.
Demonstrated leadership skills, with the ability to mentor and guide team members effectively. 
Demonstrated ability to fully own the design and delivery of robust, scalable solutions from concept through implementation.
You excel at breaking down complex, challenging problems into manageable parts and iterating toward effective solutions.
You are naturally curious and love to dig deep into problems, constantly asking, “Why?”.
You communicate clearly and concisely, regardless of the medium (text, voice, or in-person).
You value collaboration and proactively seek to build context to power your decisions.
You have a team-first mentality and will naturally support co-workers when you sense they are facing difficulty.

Serious bonus points if you have:

Familiarity with GenAI observability tools (logging, metrics, tracing) to monitor and debug AI systems.
Awareness of ML governance, responsible AI, and best practices for secure, compliant AI operations.
Proficient in developing and utilizing guardrails to ensure safe, reliable, and compliant GenAI operations.

What you will find here:

Compensation is one of the main components of Clio’s Total Rewards Program. We have developed a series of programs and processes to ensure we are creating fair and competitive pay practices that form the foundation of our human and high-performing culture.

Some highlights of our Total Rewards program include: 

Competitive, equitable salary with top-tier health benefits, dental, and vision insurance 
Hybrid work environment, with expectation for local Clions (Vancouver, Calgary, Toronto, and Dublin) to be in office minimum 2 days per week on our Anchor Days. 
Flexible time off policy, with an encouraged 20 days off per year.
$2000 annual counseling benefit
RRSP matching and RESP contribution 
Clioversary recognition program with special acknowledgement at 3, 5, 7, and 10 years 

The full salary range* for this role is $152,600 to $179,500 to $206,400 CAD.Please note salary bands may differ based on location and local currency. Additionally, benefit offerings may differ depending on the employee's location.

We aim to hire all candidates between the minimum and the midpoint of the full salary range. We reserve the midpoint to the maximum of the salary band for internal employees who demonstrate sustained high performance and impact at Clio. The final offer amount for this role will be dependent on individual experience and skillset of the candidate. Please note there are a separate set of salary bands for other regions based on local currency.

Diversity, Inclusion, Belonging and Equity (DIBE) & Accessibility 

Our team shows up as their authentic selves, and are united by our mission. We are dedicated to diversity, equity and inclusion. We pride ourselves in building and fostering an environment where our teams feel included, valued, and enabled to do the best work of their careers, wherever they choose to log in from. We believe that different perspectives, skills, backgrounds, and experiences result in higher-performing teams and better innovation. We are committed to equal employment and we encourage candidates from all backgrounds to apply.

Clio provides accessibility accommodations during the recruitment process. Should you require any accommodation, please let us know and we will work with you to meet your needs.

Learn more about our culture at clio.com/careers

Disclaimer: We only communicate with candidates through official @clio.com email addresses.",[]
MLOps Engineer,Sanofi,"Toronto, ON",Hybrid,"About the job
Reference No. R2798735

Position Title: MLOps Engineer

Department: MLOps Engineering

Location:  Downtown Toronto, Ontario, Hybrid (3 days onsite)

About The Job

Our Hubs are a crucial part of how we innovate, improving performance across every Sanofi department and providing a springboard for the amazing work we do. Build a career and you can be part of transforming our business while helping to change millions of lives.

Sanofi has recently embarked on a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions, to accelerate R&D, manufacturing and commercial performance and bring better drugs and vaccines to patients faster, to improve health and save lives.

Our vision for AI

Join us on our journey in enabling Sanofi’s Digital Transformation through becoming an AI first organization. This means:

AI Factory: An extensive portfolio of AI products driving every stage of the company's value chain, from R&D and trials to manufacturing, supply chain, and commercial operations.

State-of-the-art Tech Stack: Globally deployed products using a state-of-the-art technology stack.

World-Class Mentorship and Training: Collaborate with renowned leaders and academics in AI/ML to enhance your skills and expertise.

You are a dynamic MLOps Engineer interested in challenging the status quo to ensure seamless AI/ML Engineering Operations that scale up Sanofi's AI solutions for the patients of tomorrow. You are an influencer and a future leader who has deployed AI/ML solutions with technically robust lifecycle management and infrastructural support. You are deeply interested in improvement opportunities and always thrive to demonstrate ability to deliver using AI/ML Engineering skills while working across the full stack and moving fluidly between programming languages and technologies.

We are an innovative global healthcare company with one purpose: to chase the miracles of science to improve people’s lives. We’re also a company where you can flourish and grow your career, with countless opportunities to explore, make connections with people, and stretch the limits of what you thought was possible. Ready to get started?

Main Responsibilities

Work in an agile development pod to design, build and maintain cloud hosted AI/ML products with automated pipelines that run, monitor, and retrain ML Models 
Implement automated ML pipelines (e.g., training and inference) working closely with other peers e.g., data scientists and data engineers 
Support life cycle management of deployed AI/ML apps (e.g., new releases, change management, monitoring and troubleshooting) 
Work as intermediate level subject matter expert in MLOps (e.g., develop and maintain enterprise standards, user guides, release notes, FAQs) 
Build processes and reusable components supporting seamless ML Operations (e.g., app monitoring, troubleshooting, life cycle management and customer support) 
Walk stakeholders and solution partners through solutions and reviewing product change and development needs 
Maintain effective relationships with app userbase to develop education and communication content as per life cycle events 
Research and gain expertise on emerging tools and technologies. An enthusiasm to ask questions and try and learn new things is essential 

About You

Key Technical Skills

University degree (Bachelor, Master or PhD) in Computer Science, Information Systems, Software Engineering, or another quantitative field
Minimum 3 years of experience in building, deploying, monitoring and maintaining AI/ML applications utilizing cloud technologies (e.g., AWS, GCP, Azure, Snowflake etc.). 
Ability to work across the full stack and move fluidly between programming languages (e.g., Python) and MLOps technologies (e.g. Github, Argo, Metaflow, WandB, Snowflake) 
Experience in implementing CI/CD pipelines for AI/ML driven app development 
Experience in building and deploying apps with large scale data and ML pipelines 
Ability to assess new technologies and compile architecture decision records (ADRs) 
Experience working in an agile team supporting and working with cross-functional teams 
Knowledge of relational (e.g., Postgres SQL) and non-relational databases (e.g., Graph database, Vector Database etc.) 
Experience in visualization technologies (e.g. Python DASH, Tableau, PowerBI) 
Experience in developing and maintaining backend APIs (e.g. REST) 
Experience in provisioning cloud infrastructure leveraging Infrastructure as a code tools (e.g.: Docker, Kubernetes, Terraform) 
Experience in cloud-based ML engineering in an industrial setting within a global organization (technology company preferred) 
Experience in working within compliance (e.g. quality, regulatory - data privacy, GxP, SOX) and knowledge in cybersecurity is a plus 

Soft Skills

Excellent communication skills in English (both verbal and written as your work will require daily communication with teams around the globe). 
Structured, goal-oriented, and highly motivated. 
Able to work in a fast-paced, constantly evolving environment and manage multiple priorities. 
Interpersonal skills to work with technical leaders to define and enhance standards of development in AI engineering. 

Why Choose Us? 

Bring the miracles of science to life alongside a supportive, future-focused team.
Discover endless opportunities to grow your talent and drive your career, whether it’s through a promotion or lateral move, at home or internationally.
Enjoy a thoughtful, well-crafted rewards package that recognizes your contribution and amplifies your impact.
Take good care of yourself and your family, with a wide range of health and wellbeing benefits including high-quality healthcare, prevention and wellness programs
Play an instrumental part in creating best practice within our manufacturing facility 

This position is for a current vacant role that is now open for applications.

Sanofi is an equal opportunity employer committed to diversity and inclusion. Our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. We welcome and encourage applications from all qualified applicants. Accommodations for persons with disabilities required during the recruitment process are available upon request.

#GD-SP

#DBBCA

All compensation will be determined commensurate with demonstrated experience. Employees may be eligible to participate in Company employee benefit programs, and additional benefits information can be found here.

Les employés peuvent être admissibles à participer aux programmes d'avantages sociaux de l'entreprise. Des informations supplémentaires sur les avantages sociaux peuvent être trouvées ici.

Pursue Progress. Discover Extraordinary.

Join Sanofi and step into a new era of science - where your growth can be just as transformative as the work we do. We invest in you to reach further, think faster, and do what’s never-been-done-before. You’ll help push boundaries, challenge convention, and build smarter solutions that reach the communities we serve. Ready to chase the miracles of science and improve people’s lives? Let’s Pursue Progress and Discover Extraordinary – together.

At Sanofi, we provide equal opportunities to all regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, protected veteran status or other characteristics protected by law.",[]
Senior MLOps Engineer,Clio,"Calgary, AB",Hybrid,"About the job
Clio is more than just a tech company–we are a global leader that is transforming the legal experience for all by bettering the lives of legal professionals while increasing access to justice.

Summary:

We are currently seeking a Senior MLOps Engineer to join our Engineering team. This role is available to candidates across Canada. If you are local to one of our hubs (Burnaby, Calgary, or Toronto) you will be expected to be in office minimum two days per week for our Anchor Days.

What your team does:

Our MLOps team builds and operates the scalable infrastructure and robust platforms that power GenAI solutions across the company. We blend deep AI and ML expertise with strong software engineering and cloud infrastructure skills to enable the entire lifecycle of machine learning and generative AI - spanning experimentation, deployment, monitoring, and continuous improvement. By applying best practices in CI/CD, observability, cost optimization, and model governance, and leveraging state-of-the-art tools and frameworks, we ensure our AI systems are reliable, performant, and aligned with business goals. We partner closely with data scientists, engineers, and product teams to accelerate the delivery of impactful AI capabilities.

What a day in the life might look like:

Build and deploy LLM-based solutions that help Clio’s clients save time and improve operational efficiency.
Collaborate cross-functionally with engineering, product management, operations, and data science to identify and develop new ML-driven features.
Work agilely alongside MLOps, MLE, and full stack developers on diverse projects spanning multiple engineering teams across three countries.
Evaluate and integrate new ML tools and frameworks to accelerate experimentation and optimize operations.
Troubleshoot and resolve production issues such as data drift and model latency using observability tools and logs.
Participate in design reviews and contribute to architectural decisions shaping Clio’s AI platforms.
Engage in code reviews within your team and across the company, providing and receiving constructive feedback to maintain high standards.
Continuously learn, challenge yourself, and grow as a machine learning expert while mentoring and collaborating with teammates.

What you may have:

Strong Python or Ruby development skills, with experience building production-grade applications, services, or ML tooling.
Expertise in cloud infrastructure (AWS, GCP, or Azure), including Kubernetes, and infrastructure-as-code (Terraform, Helm, or similar).
Experience with CI/CD and automating model training, testing, and deployment pipelines.
Solid understanding of machine learning and GenAI concepts, workflows, and lifecycle management.
Demonstrated leadership skills, with the ability to mentor and guide team members effectively. 
Demonstrated ability to fully own the design and delivery of robust, scalable solutions from concept through implementation.
You excel at breaking down complex, challenging problems into manageable parts and iterating toward effective solutions.
You are naturally curious and love to dig deep into problems, constantly asking, “Why?”.
You communicate clearly and concisely, regardless of the medium (text, voice, or in-person).
You value collaboration and proactively seek to build context to power your decisions.
You have a team-first mentality and will naturally support co-workers when you sense they are facing difficulty.

Serious bonus points if you have:

Familiarity with GenAI observability tools (logging, metrics, tracing) to monitor and debug AI systems.
Awareness of ML governance, responsible AI, and best practices for secure, compliant AI operations.
Proficient in developing and utilizing guardrails to ensure safe, reliable, and compliant GenAI operations.

What you will find here:

Compensation is one of the main components of Clio’s Total Rewards Program. We have developed a series of programs and processes to ensure we are creating fair and competitive pay practices that form the foundation of our human and high-performing culture.

Some highlights of our Total Rewards program include: 

Competitive, equitable salary with top-tier health benefits, dental, and vision insurance 
Hybrid work environment, with expectation for local Clions (Vancouver, Calgary, Toronto, and Dublin) to be in office minimum 2 days per week on our Anchor Days. 
Flexible time off policy, with an encouraged 20 days off per year.
$2000 annual counseling benefit
RRSP matching and RESP contribution 
Clioversary recognition program with special acknowledgement at 3, 5, 7, and 10 years 

The full salary range* for this role is $152,600 to $179,500 to $206,400 CAD.Please note salary bands may differ based on location and local currency. Additionally, benefit offerings may differ depending on the employee's location.

We aim to hire all candidates between the minimum and the midpoint of the full salary range. We reserve the midpoint to the maximum of the salary band for internal employees who demonstrate sustained high performance and impact at Clio. The final offer amount for this role will be dependent on individual experience and skillset of the candidate. Please note there are a separate set of salary bands for other regions based on local currency.

Diversity, Inclusion, Belonging and Equity (DIBE) & Accessibility 

Our team shows up as their authentic selves, and are united by our mission. We are dedicated to diversity, equity and inclusion. We pride ourselves in building and fostering an environment where our teams feel included, valued, and enabled to do the best work of their careers, wherever they choose to log in from. We believe that different perspectives, skills, backgrounds, and experiences result in higher-performing teams and better innovation. We are committed to equal employment and we encourage candidates from all backgrounds to apply.

Clio provides accessibility accommodations during the recruitment process. Should you require any accommodation, please let us know and we will work with you to meet your needs.

Learn more about our culture at clio.com/careers

Disclaimer: We only communicate with candidates through official @clio.com email addresses.",[]
Senior Cloud Infrastructure Developer - MLOps,Coveo,"Quebec, Canada",Hybrid,"About the job
*Please note our roles are open hybrid, in Montreal and Quebec city locations, as well as remote across the Quebec province, under certain conditions.

Support the scale and growth of our AI platform
As a senior infrastructure developer on the ML Platform team, you will contribute to design and implement cloud infrastructure systems to support the scale and growth of our AI platform. Our team has built a mission-critical platform that trains thousands of models and serves over 100M model queries daily. This is your chance to accelerate AI innovation at Coveo by enhancing our ML platform’s capabilities to safely deploy, serve, and test models at scale.
This is your chance to contribute to AI innovation at Coveo by expanding the capabilities of our platform and supporting the shift toward agentic AI.

Here’s what you’ll be responsible for:
Design and implement cloud and infrastructure systems and support them in production while ensuring it meets the requirements for scalability, reliability, costs and performance.
Advise ML developers and ML scientists across the ML unit and provide expert guidance on cloud best practices.
Help us modernize, improve and support the entire ML model lifecycle from model development to vector search, model building orchestration and ML developer tooling
Evaluate and integrate latest industry ML tools and technologies to provide a best-in-class ML development experience to our team of applied scientists

Here is what will qualify you for the role: 
5+ years of experience as a cloud developer.
Advanced knowledge of AWS, cloud systems and Infrastructure as code.
Exceptional resourcefulness and growth mindset.

Here is what will make you stand out:
Experience developing and supporting cloud systems in production
Experience building AI systems, infrastructure or tooling used by applied science teams
Experience with the following tools and technologies: vector database such as OpenSearch, Terraform, AWS SageMaker, AWS Bedrock, ML Flow

Do you think you can bring this role to life?
You don’t need to check every single box; passion goes a long way, and we appreciate that skillsets are transferable. Send us your CV, we want to get to know you! Join the #Coveolife!

We encourage all qualified applications regardless of, for example, age, gender, disability, gaps in CV, national or ethnic background. We know that applying for a new role is a lot of work and we really appreciate your time.

#li-hybrid",[]
MLOps Engineering Manager,Workday,"Vancouver, BC",Hybrid,"About the job
Your work days are brighter here.

At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.

At Workday, we value our candidates’ privacy and data security. Workday will never ask candidates to apply to jobs through websites that are not Workday Careers.

Please be aware of sites that may ask for you to input your data in connection with a job posting that appears to be from Workday but is not.

In addition, Workday will never ask candidates to pay a recruiting fee, or pay for consulting or coaching services, in order to apply for a job at Workday.

About The Team

This is an opportunity to be part of a growth team focused on MLOps. We build ML capabilities into our products, and you would be building part of the next generation of Workday technology. We believe predictive products can be as ground-breaking to the next interation of technology as mobile was to the last.

About The Role

We are seeking a highly skilled and experienced Machine Learning Manager to lead our dynamic team of machine learning engineers. The ideal candidate will be a hands-on technical leader with a consistent track record of building and deploying machine learning platforms and integrating them with other services. You will be responsible for driving the development and implementation of our machine learning strategy, ensuring the delivery of high-quality, scalable, and robust solutions.

Responsibilities:

Lead and develop a team of software development engineers, fostering a collaborative, innovative environment.
Drive the design, development, and deployment of end-to-end machine learning systems, from data ingestion and preprocessing to model training, evaluation, and deployment.
Oversee the building/development and maintenance of our ML platform, ensuring its scalability, reliability, and performance.
Lead the integration of machine learning solutions with other company services and systems.
Collaborate with multi-functional teams, including product management, data engineering, and software development, to define project requirements and deliver solutions that meet business needs.
Stay up-to-date with the latest advancements in machine learning, cloud computing, and related technologies, and drive the adoption of standard methodologies.
Ensure the quality, security, and compliance of all machine learning solutions.
Mentor and develop team members, providing technical guidance and fostering their professional growth.
Manage project timelines, resources, and budgets effectively.
Contribute to the overall AI/ML strategy of the organization.

About You

Basic Qualifications:

Bachelor's degree in Computer Science, Machine Learning; Master's degree preferred.
Minimum of 5 years of experience in a management role, leading machine learning or software engineering teams.
Minimum of 10 years of hands-on experience in software engineering, with a strong focus on machine learning.
Deep understanding of machine learning principles, algorithms, and techniques.
Extensive experience with cloud platforms (e.g., AWS, GCP), including machine learning services (e.g., SageMaker, Vertex AI, Databricks).
Proven experience with data engineering concepts and tools, including data warehousing, ETL processes, and big data technologies (e.g., Spark).
Proficiency in Python and experience with machine learning libraries and frameworks (e.g.,PyTorch, TensorFlow, scikit-learn).
Proven understanding of software development standard processes, including version control (Git), CI/CD, and testing.
Strong experience with containerization and orchestration technologies (e.g., Docker, Kubernetes).
Experience with data platforms and databases (SQL and NoSQL).
Experience with MLOps practices and tools, ideally Kubeflow ecosystem.

Other Qualifications:

Excellent communication, collaboration, and leadership skills.
Strong problem-solving and analytical abilities.
Ability to thrive in a fast-paced, dynamic environment.
Proven ability to deliver high-quality machine learning solutions in a production setting.
Contributions to open-source machine learning projects.
Experience with specific machine learning domains (e.g., natural language processing, recommendation systems)

Workday Pay Transparency Statement 

The annualized base salary ranges for the primary location and any additional locations are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please click here.

Primary Location: CAN.ON.Toronto

Primary CAN Base Pay Range: $132,000 - $198,000 CAD

Additional CAN Location(s) Base Pay Range: $132,000 - $198,000 CAD

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.

Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.

Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.

Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!

,",[]
"Technical Specialist, MLOps Engineer",University Health Network,"Toronto, ON",Hybrid,"About the job
Company Description

UHN is Canada’s #1 hospital and the world’s #1 publicly funded hospital. With 10 sites and more than 44,000 TeamUHN members, UHN consists of Toronto General Hospital, Toronto Western Hospital, Princess Margaret Cancer Centre, Toronto Rehabilitation Institute, The Michener Institute of Education and West Park Healthcare Centre. As Canada's top research hospital, the scope of biomedical research and complexity of cases at UHN have made it a national and international source for discovery, education and patient care. UHN has the largest hospital-based research program in Canada, with major research in neurosciences, cardiology, transplantation, oncology, surgical innovation, infectious diseases, genomic medicine and rehabilitation medicine. UHN is a research hospital affiliated with the University of Toronto.

UHN’s vision is to build A Healthier World and it’s only because of the talented and dedicated people who work here that we are continually bringing that vision closer to reality.

www.uhn.ca

Job Description

Union: Non-Union

Number of Vacancies: 1

Site: 200 Elizabeth St, Toronto, ON M5G 2C4

Department: AI Collaborative Centre

Reports to: Chief AI Scientist

Work Model: Hybrid (3 days on site)

Hours: 37.5 Per Week

Shifts: Monday to Friday

Status: Temporary Full-Time

Closing Date: August 5, 2025

Position Summary

Join the forefront of AI-driven health care innovation as a Technical Specialist, MLOps Engineer at the University Health Network (UHN) AI Hub, where cutting-edge technology meets life-changing impact. Work alongside top scientists, clinicians, and researchers to design and develop sophisticated ML pipelines, agent systems, and deployment platforms, driving advancements in cancer care and beyond. In this dynamic role, you’ll apply MLOps methodologies to solve complex health challenges, optimize hospital operations, and pioneer groundbreaking AI solutions. If you're passionate about transforming data into responsible AI-driven breakthroughs, this is your opportunity to lead the way!

Duties

Develop and manage data processing, ML pipelines and agent systems to support AI-driven health care innovations. This involves pre-processing, cleaning, and organizing multi-modal data for data pipelines and AI integration.
TECDeploy, monitor, and optimize machine learning models in clinical environments and processes to ensure seamless integration and efficiency. Set up monitoring tools to monitor AI performance and track various metrics, such as response time, errors and resource utilization.
Collaborate with clinicians and researchers to design secure data pipelines and implement responsible AI applications. Regularly document your findings and methodologies. Publish in peer-reviewed journals and present at conferences.
Apply MLOps methodologies to enhance hospital efficiency, streamline workflows, and improve patient care.
Ensure compliance with ethical AI standards and contribute to the development of safe and responsible AI practices in healthcare.
Provide technical expertise and mentorship to research teams, students, and clinicians working on AI-related projects.
Stay ahead of emerging AI trends by continuously learning and integrating cutting-edge technologies into UHN’s AI ecosystem.


Qualifications

Undergraduate degree, graduate would be an asset, in engineering, computer science, or related disciplines.
Minimum 5 years related experience required.
Excellent communication skills and ability to utilize a collaborative approach to solving challenging problems.
Experience with MLOps, enterprise application development, implementing and maintaining ML and NLP models, IT administration and support.
Experience with Python (scikit-learn, Pandas, etc.) and deep learning frameworks (TensorFlow or PyTorch).
Experience with healthcare data types, topics, and scientific challenges and approaches.
Familiarity with HPC environment and running applications in HPC clusters.
Demonstrate ability to mentor others and work collaboratively with clinicians.


Additional Information

Why join UHN?

In addition to working alongside some of the most talented and inspiring healthcare professionals in the world, UHN offers a wide range of benefits, programs and perks. It is the comprehensiveness of these offerings that makes it a differentiating factor, allowing you to find value where it matters most to you, now and throughout your career at UHN.

Competitive offer packages
Government organization and a member of the Healthcare of Ontario Pension Plan (HOOPP https://hoopp.com/)
Close access to Transit and UHN shuttle service
A flexible work environment
Opportunities for development and promotions within a large organization
Additional perks (multiple corporate discounts including: travel, restaurants, parking, phone plans, auto insurance discounts, on-site gyms, etc.)


Current UHN employees must have successfully completed their probationary period, have a good employee record along with satisfactory attendance in accordance with UHN's attendance management program, to be eligible for consideration.

All applications must be submitted before the posting close date.

UHN uses email to communicate with selected candidates. Please ensure you check your email regularly.

Please be advised that a Criminal Record Check may be required of the successful candidate. Should it be determined that any information provided by a candidate be misleading, inaccurate or incorrect, UHN reserves the right to discontinue with the consideration of their application.

UHN is an equal opportunity employer committed to an inclusive recruitment process and workplace. Requests for accommodation can be made at any stage of the recruitment process. Applicants need to make their requirements known.

We thank all applicants for their interest, however, only those selected for further consideration will be contacted.",[]
Analyste développeur - Intelligence artificielle MLOps,Beneva,"bec, QC",Hybrid,"About the job
Titre interne officiel:

Analyste développeur - Intelligence artificielle MLOps

Statut:

Temporaire (Durée déterminée)

Sommaire:

Relevant de la directrice – Hyperautomatisation et intelligence artificielle, le développeur MLOps œuvre dans les pratiques du développement de « Machine Learning », dès la capture du besoin d’affaires, en passant par la préparation de données et de modèles en intelligence artificielle jusqu’à son déploiement en production. Il participe activement à la compréhension des requis affaires et des processus à optimiser. Il agit à titre d’expert de pointe dans le domaine technologique de l’intelligence artificielle pour la conception, le développement, l’évaluation et la maintenance de solutions d’intelligence artificielle pour des activités d’affaires diversifiées telles que les affaires numériques, le marketing et ventes, l’actuariat, et les équipes opérationnelles. Sa contribution touche l’ensemble des champs d’activités Beneva tels que l’assurance de dommages, l’assurance collective, l’assurance voyage, l’assurance individuelle et les produits d’investissement. Le développeur MLOps assume ainsi un rôle transversal de bout en bout pour l'ensemble des secteurs d’activités de Beneva dans la mise en place de solutions d’intelligence artificielle.

Responsabilités générales

Participe à la capture du besoin d’affaires et amène son expertise dans l’optimisation des processus par une vision des capacités offertes dans le domaine de pointe de l’intelligence artificielle
Contribuer à la conception / au développement / à l’évaluation / à la maintenance de solutions d’intelligence artificielle
Prendre les décisions et assurer la mise en œuvre de la cible d’architecture technologique MLOps nécessaire à l’opérationnalisation des solutions d’intelligence artificielle
Agir comme référence pour les technologies Anaconda Entreprise, AWS Sagemaker, MLFlow et Python/R/SQL nécessaire pour concevoir et opérationnaliser les solutions basées sur l’intelligence artificielle
Prendre en charge les travaux de préparation de données (structurées et non-structurées) complexes avec le framework d’ingénierie de données DWA
Explorer et mettre en œuvre l’utilisation des services API disponibles sur un Cloud ou des librairies open-source pour développer les solutions d’intelligence artificielle
Collaborer aux différents projets de veille, expérimentation et amélioration des technologies, modèles d’intelligence artificielle, langages, logiciels et outils de développement utilisés par l’équipe
Exercer un rôle-conseil en tant que référent sur les technologies MLOps ; être garant de l’application des règles d’architecture préalablement définies et la bonne utilisation des technologies
Assurer la formation et le coaching des nouveaux équipiers : « pair programming », formation sur l’architecture MLOps, encadrement et suivi de l’évolution de leurs travaux techniques
Être responsable de dossiers spéciaux : CI/CD, déploiement, environnements, preuve de concept, autres
Veiller au bon fonctionnement, à l’évolution, à la cohérence et à la performance de l’écosystème MLOps incluant les modèles d’intelligence artificielle
Participe à la coordination des activités en assurant, entre autres, le lien avec les autres parties prenantes de l’écosystème au besoin : autres équipes de réalisation TI, équipes opérationnelles, sécurité, conformité, réseau, infrastructure, etc. 

Qualifications

1 à 8 années d’expérience en tant que développeur Intelligence Artificielle ou données (selon le niveau du candidat recherché)
Maitriser l’anglais et le français tant à l’oral et qu’à l’écrit
Baccalauréat en informatique, mathématique ou l’équivalent dans les domaines de l’intelligence artificielle
Maîtrise un atout

Qualifications Spécifiques

Avoir de l’expérience dans la réalisation de projets en intelligence artificielle
Avoir des connaissances approfondies des concepts d’intelligence artificielle : concepts de régression linéaire, de série chronologique, de réseau de neurones, d’arbres de classification/régression, d’inférence bayésienne, de machine à vecteurs de support et autres techniques de machine learning
Comprendre les enjeux liés à la préparation de données pour l’intelligence artificielle
Avoir une bonne maîtrise des bonnes pratiques en ingénierie logicielle pour structurer du code source
Avoir des connaissances importantes en ingénierie de données
Détenir une bonne connaissance des langages Python et/ou R
Avoir une bonne maîtrise de AWS Sagemaker ou Anaconda (version Entreprise)
Avoir de l’expérience avec l’opérationnalisation de modèles d’intelligence artificielle avec MLFlow
Démontrer les connaissances approfondies avec des outils et des pratiques de DevOps (GitHub, jenkins) et de la contenarisation (Kubernetes)
Avoir une expérience pratique dans le développement et la maintenant d’API REST
Détenir une expérience avec des services « cognitives » ou analytiques disponible sur le Cloud

Beneva souscrit au programme d’accès à l’égalité en emploi et encourage les membres des groupes visés à savoir les femmes, les personnes handicapées, les autochtones et les minorités visibles, à soumettre leur candidature. 

Raison d'être : Les gens sont au cœur de nos actions. Nous les accompagnons dans leurs projets de vie en leur apportant la tranquillité d'esprit et nous contribuons au bien-être de la collectivité. 

Suivez-nous sur Instagram ! 

@beneva.ca",[]
Analyste développeur - Intelligence artificielle MLOps,Beneva,"Chicoutimi, QC",Hybrid,"About the job
Titre interne officiel:

Analyste développeur - Intelligence artificielle MLOps

Statut:

Temporaire (Durée déterminée)

Sommaire:

Relevant de la directrice – Hyperautomatisation et intelligence artificielle, le développeur MLOps œuvre dans les pratiques du développement de « Machine Learning », dès la capture du besoin d’affaires, en passant par la préparation de données et de modèles en intelligence artificielle jusqu’à son déploiement en production. Il participe activement à la compréhension des requis affaires et des processus à optimiser. Il agit à titre d’expert de pointe dans le domaine technologique de l’intelligence artificielle pour la conception, le développement, l’évaluation et la maintenance de solutions d’intelligence artificielle pour des activités d’affaires diversifiées telles que les affaires numériques, le marketing et ventes, l’actuariat, et les équipes opérationnelles. Sa contribution touche l’ensemble des champs d’activités Beneva tels que l’assurance de dommages, l’assurance collective, l’assurance voyage, l’assurance individuelle et les produits d’investissement. Le développeur MLOps assume ainsi un rôle transversal de bout en bout pour l'ensemble des secteurs d’activités de Beneva dans la mise en place de solutions d’intelligence artificielle.

Responsabilités générales

Participe à la capture du besoin d’affaires et amène son expertise dans l’optimisation des processus par une vision des capacités offertes dans le domaine de pointe de l’intelligence artificielle
Contribuer à la conception / au développement / à l’évaluation / à la maintenance de solutions d’intelligence artificielle
Prendre les décisions et assurer la mise en œuvre de la cible d’architecture technologique MLOps nécessaire à l’opérationnalisation des solutions d’intelligence artificielle
Agir comme référence pour les technologies Anaconda Entreprise, AWS Sagemaker, MLFlow et Python/R/SQL nécessaire pour concevoir et opérationnaliser les solutions basées sur l’intelligence artificielle
Prendre en charge les travaux de préparation de données (structurées et non-structurées) complexes avec le framework d’ingénierie de données DWA
Explorer et mettre en œuvre l’utilisation des services API disponibles sur un Cloud ou des librairies open-source pour développer les solutions d’intelligence artificielle
Collaborer aux différents projets de veille, expérimentation et amélioration des technologies, modèles d’intelligence artificielle, langages, logiciels et outils de développement utilisés par l’équipe
Exercer un rôle-conseil en tant que référent sur les technologies MLOps ; être garant de l’application des règles d’architecture préalablement définies et la bonne utilisation des technologies
Assurer la formation et le coaching des nouveaux équipiers : « pair programming », formation sur l’architecture MLOps, encadrement et suivi de l’évolution de leurs travaux techniques
Être responsable de dossiers spéciaux : CI/CD, déploiement, environnements, preuve de concept, autres
Veiller au bon fonctionnement, à l’évolution, à la cohérence et à la performance de l’écosystème MLOps incluant les modèles d’intelligence artificielle
Participe à la coordination des activités en assurant, entre autres, le lien avec les autres parties prenantes de l’écosystème au besoin : autres équipes de réalisation TI, équipes opérationnelles, sécurité, conformité, réseau, infrastructure, etc. 

Qualifications

1 à 8 années d’expérience en tant que développeur Intelligence Artificielle ou données (selon le niveau du candidat recherché)
Maitriser l’anglais et le français tant à l’oral et qu’à l’écrit
Baccalauréat en informatique, mathématique ou l’équivalent dans les domaines de l’intelligence artificielle
Maîtrise un atout

Qualifications Spécifiques

Avoir de l’expérience dans la réalisation de projets en intelligence artificielle
Avoir des connaissances approfondies des concepts d’intelligence artificielle : concepts de régression linéaire, de série chronologique, de réseau de neurones, d’arbres de classification/régression, d’inférence bayésienne, de machine à vecteurs de support et autres techniques de machine learning
Comprendre les enjeux liés à la préparation de données pour l’intelligence artificielle
Avoir une bonne maîtrise des bonnes pratiques en ingénierie logicielle pour structurer du code source
Avoir des connaissances importantes en ingénierie de données
Détenir une bonne connaissance des langages Python et/ou R
Avoir une bonne maîtrise de AWS Sagemaker ou Anaconda (version Entreprise)
Avoir de l’expérience avec l’opérationnalisation de modèles d’intelligence artificielle avec MLFlow
Démontrer les connaissances approfondies avec des outils et des pratiques de DevOps (GitHub, jenkins) et de la contenarisation (Kubernetes)
Avoir une expérience pratique dans le développement et la maintenant d’API REST
Détenir une expérience avec des services « cognitives » ou analytiques disponible sur le Cloud

Beneva souscrit au programme d’accès à l’égalité en emploi et encourage les membres des groupes visés à savoir les femmes, les personnes handicapées, les autochtones et les minorités visibles, à soumettre leur candidature. 

Raison d'être : Les gens sont au cœur de nos actions. Nous les accompagnons dans leurs projets de vie en leur apportant la tranquillité d'esprit et nous contribuons au bien-être de la collectivité. 

Suivez-nous sur Instagram ! 

@beneva.ca",[]
DevOps/DataOps/MLOps - Senior Engineer/Lead Engineer,FICO,Canada,Remote,"About the job
The Opportunity 
As a DataOps / DevOps/ MLOps Engineer on our Generative AI team, you’ll be at the cutting edge of language model applications, building innovative solutions across key areas of the FICO platform—including fraud detection, decision automation, workflow orchestration, and system optimization. We're looking for a highly skilled engineer with a strong background in digital product development, a passion for innovation, and hands-on experience in deploying production systems, troubleshooting operational issues, and integrating services at scale. Thrives in fast-paced, agile environments, champions DevOps and CI/CD best practices, and is committed to delivering high-impact, customer-centric solutions. You’ll have the opportunity to make a measurable impact by bringing next-generation AI capabilities into production, collaborating with a world-class team to build robust, scalable infrastructure and accelerate innovation across FICO’s platform. 
 What You’ll Contribute 

Design, build, and maintain scalable, resilient data and ML pipelines, infrastructure, and workflows using tools such as GitHub Actions, Terraform, Helm, ArgoCD, Crossplane and others. 
Automate infrastructure provisioning and configuration management using cloud-native services (preferably AWS) with tools like Terraform, CloudFormation, or Crossplane. 
Design, containerize, and manage Kubernetes (EKS) clusters and/or ECS environments in AWS. Collaborate with development teams to optimize performance, deployment, and cost. 
Partner with DevOps and SRE teams to ensure high availability, observability, scalability, and security of the data and ML infrastructure. 
Work closely with Data Scientists and ML Engineers to operationalize machine learning models, including building CI/CD pipelines for model training, validation, and deployment. 
Implement observability for data pipelines and ML services using tools like Prometheus, Grafana, Datadog, or similar. 
Develop and maintain automated pipelines for model retraining, monitoring drift, and versioning in production. 
Support experimentation and prototyping in areas such as Machine Learning and Generative AI, transitioning successful prototypes into production systems. 
Ensure cloud infrastructure is secure, compliant, and cost-efficient, following best practices in governance, identity, and access management. 
 What We’re Seeking 

8+ years experience in DataOps, MLOps, or related fields, with at least 2+ years focused on ML model operationalization and workflow automation. 
Proficient in AWS services including EC2, S3, IAM, ACM, Route 53, CloudWatch, EKS, and ECS. 
Strong experience with infrastructure as code (IaC) tools such as Terraform, CloudFormation, and Helm. 
Experience with CI/CD for ML pipelines, GitOps practices, and tools like GitHub Actions, Jenkins, or Argo Workflows. 
Strong scripting and automation skills using Bash, Python, or GitHub workflows. 
Understanding of observability and monitoring tools (e.g., Prometheus, Grafana, Datadog, or OpenTelemetry). 
Experience with feature stores (e.g., Feast, Tecton) and knowledge of data mesh, lakehouse architectures, or modern data stack concepts. 
Comfortable working with structured and unstructured data across various storage and pipeline systems. 
Solid understanding of security best practices for cloud and Kubernetes environments, including secrets management, identity & access control, and policy enforcement. 
Familiarity with data governance, lineage, and metadata management is a plus. 
Excellent collaboration and communication skills, with a proven ability to work effectively in cross-functional, globally distributed teams. 
A Bachelor/Master's degree in computer sciences, Engineering, or a related discipline, or equivalent hands-on industry experience. 

About US
FICO, originally known as Fair Isaac Corporation, is a leading analytics and decision management company that empowers businesses and individuals around the world with data-driven insights. Known for pioneering the FICO® Score, a standard in consumer credit risk assessment, FICO combines advanced analytics, machine learning, and sophisticated algorithms to drive smarter, faster decisions across industries. From financial services to retail, insurance, and healthcare, FICO's innovative solutions help organizations make precise decisions, reduce risk, and enhance customer experiences. With a strong commitment to ethical use of AI and data, FICO is dedicated to improving financial access and inclusivity, fostering trust, and driving growth for a digitally evolving world.",[]
Machine Learning Engineer,Loblaw Companies Limited,,,"About the job
Come make your difference in communities across Canada, where authenticity, trust and making connections is valued – as we shape the future of Canadian retail, together. Our unique position as one of the country's largest employers, coupled with our commitment to positively impact the lives of all Canadians, provides our colleagues a range of opportunities and experiences to help Canadians Live Life Well®.

At Loblaw Companies Limited, we succeed through collaboration and commitment and set a high bar for ourselves and those around us. Whether you are just starting your career, re-entering the workforce, or looking for a new job, this is where you belong.

Does working with some of Canada’s most talented minds in innovation supporting retail, digital consumer solutions and analytical platforms excite you? Loblaw Technology powers some of Canada’s most game-changing retail solutions, giving our customers the ability to live their lives well.

Come work with a team that values diverse ideas, fosters a culture of inclusion and develops our talent from within. Loblaw Technology gives you the chance to excel, and helps you to strive for success in a big way. Keep reading to learn more!

Key Responsibilities

 Design, develop, and implement robust Machine Learning (ML) solutions and scalable data pipelines, contributing to the full ML lifecycle from data preparation to deployment and monitoring.
 Collaborate on the architecture and implementation of MLOps pipelines to automate and streamline model deployment, versioning, monitoring, and governance.
 Contribute to the design, implementation, and optimization of scalable, secure, and reliable ML infrastructure, leveraging Google Cloud Platform (GCP).
 Work closely with cross-functional teams including product, engineering, analytics, and business stakeholders to deliver high-quality data and ML solutions supporting analytics, reporting, and GenAI initiatives.
 Ensure data integrity, governance, security, and compliance in all data engineering and ML efforts.
 Provide hands-on technical expertise and contribute to architectural discussions in cloud-native data platforms, distributed systems, and real-time data processing.
 Monitor the performance and quality assurance of ML systems, identifying opportunities for continuous optimization.
 Participate in project delivery and technical planning to ensure successful execution of data and ML projects.

Required Qualifications

 Bachelor’s or master’s degree in computer science, Data Science, Engineering, or a related field.
 5+ years of hands-on experience in Data Science, ML engineering, or a related technical domain.
 Proven experience in designing and implementing data platforms and ML systems on cloud platforms, preferably GCP.
 Strong technical knowledge of data/ML architecture, ML models, ETL/ELT processes, and distributed computing frameworks.
 Proficiency in machine learning frameworks (e.g., TensorFlow, PyTorch, Scikit-learn) and experience with MLOps tools (e.g., MLflow, Kubeflow, Vertex AI Pipelines).
 Excellent communication, problem-solving, and collaboration skills, with the ability to work effectively within a team.

What Loblaw Offers You

We offer flexibility and balance, and an environment that sets you up for success no matter where your workspace is located.

Here, you will find a great team to help you achieve your goals as you help us achieve ours! Work in our fast-paced, exciting Technology environment, helping our stores, colleagues and customers every day.

Loblaw colleagues also enjoy:

Work Perks Program
Basketball & Volleyball courts, Ice Rink, Dry Cleaning services (1PCC Office)
Benefits
Paid Vacation

If you’re up to the challenge, then we would love to hear from you. Apply today, and get the process started. 

Loblaw recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. At Loblaw, we celebrate diversity and strive to build a culture of inclusion where differences are embraced, valued and supported. We are committed to being an equal opportunity employer and encourage people from all backgrounds and identities to apply to our jobs. Accommodation in the recruitment, assessment, and hiring process is available upon request for applicants with disabilities. 

We thank all candidates for their interest but please note, those candidates who meet the minimum requirements for the position will be contacted. 

www.Loblaw.ca/careers

Our commitment to Sustainability and Social Impact is an essential part of the way we do business, and we focus our attention on areas where we can have the greatest impact. Our approach to sustainability and social impact is based on three pillars – Environment, Sourcing and Community – and we are constantly looking for ways to demonstrate leadership in these important areas. Our CORE Values – Care, Ownership, Respect and Excellence – guide all our decision-making and come to life through our Blue Culture. We offer our colleagues progressive careers, comprehensive training, flexibility, and other competitive benefits – these are some of the many reasons why we are one of Canada’s Top Employers, Canada’s Best Diversity Employers, Canada’s Greenest Employers & Canada’s Top Employers for Young People.

If you are unsure whether your experience matches every requirement above, we encourage you to apply anyway. We are looking for varied perspectives which include diverse experiences that we can add to our team.

We have a long-standing focus on diversity, equity and inclusion because we know it will make our company a better place to work and shop. We are committed to creating accessible environments for our colleagues, candidates and customers. Requests for accommodation due to a disability (which may be visible or invisible, temporary or permanent) can be made at any stage of application and employment. We encourage candidates to make their accommodation needs known so that we can provide equitable opportunities.

Please Note:

Candidates who are 18 years or older are required to complete a criminal background check. Details will be provided through the application process.

#EN

#SS #DISTRC #ON",[]
Sr. ML Ops Engineer,Staples Canada,,,"About the job
Job Description

Description for Internal Candidates

Some Of What You Will Do

The Senior ML Ops Developer builds and maintains the infrastructure powering Staples Canada's machine learning initiatives. Translating data science models into scalable, reliable production solutions enables the business to fully leverage its data assets. Collaborating with data scientists and data engineers, you'll streamline deployment and optimize model performance, ensuring seamless integration with business systems. This role drives efficiency and innovation through automation, improved model monitoring, and a robust machine learning ecosystem. You'll also mentor team members, promoting MLOps best practices to positively impact the organization's ability to derive value from machine learning and advance its data-driven culture.

Specifically, You Will

Turn existing data science workflows into scalable, efficient production machine learning pipelines.
Implement Feature Stores for managing and sharing features across multiple models.
Establish and enforce best practices for CI/CD, version control, and automated testing within the ML lifecycle.
Maintain our Neo4j instance, ensuring its performance, scalability, and security.
Set up and maintain monitoring and alerting systems to ensure the health and performance of machine learning models and data pipelines.
Integrate machine learning outputs seamlessly into relevant business systems, dashboards, and APIs.
Document workflows, pipelines, and processes to ensure team members can reuse and maintain them.

Some Of What You Need

Post-secondary education is required.
Proficiency in SQL and Python.
Familiarity with GCP services, especially BigQuery, Vertex AI, and Cloud Functions.
Strong knowledge of CI/CD principles and hands-on experience with tools like Git.
Experience setting up monitoring and alerting systems for production machine learning models.
Strong experience with machine learning deployment and data pipeline frameworks like Airflow and Kubeflow.
5-8 years of experience with big data technologies and machine learning.

Some Of What You Will Get

Associate discount
Health and Dental benefits
RRSP/DPSP
Performance bonuses
Learning & Development programs
And more...

 #MakeAnImpact



About Us

Staples/Bureau en Gros est un employeur qui souscrit au principe de l'égalité d'accès à l'emploi et à la diversité, et nous encourageons tous les candidats qualifiés, y compris les personnes handicapées, à poser leur candidature.",[]
Senior Machine Learning Engineer,Lightspeed Commerce,,,"About the job
As a Senior ML Engineer, on our Data Science Enablement team, you will be responsible for driving the design, development, and maintenance of the platforms and tools used for building, training, and deploying artificial intelligence (AI) and machine learning (ML) models at scale. Your responsibilities will include setting technical direction, mentoring team members, and ensuring the robustness, scalability, and performance of our AI/ML systems and infrastructure. You will work closely with cross-functional teams to align infrastructure capabilities with organizational goals, enabling data scientists and machine learning engineers to deliver impactful solutions efficiently and effectively.

Key Responsibilities

ML System Development: Design and implement scalable and reliable AI/ML infrastructure, including data and ML pipelines, model development environments, and CI/CD. 
Tool Integration: Integrate various AI/ML tools and frameworks into our existing systems, ensuring seamless operation and compatibility.
Cloud Management: Manage cloud-based resources and services for AI/ML workloads, including configuring and optimizing cloud environments to ensure cost-efficiency and performance.
Performance Optimization: Monitor and optimize model performance, identifying and addressing deterioration to ensure high-quality predictions.
Automation: Develop and maintain automation scripts and workflows to streamline model deployment, monitoring, and maintenance processes.
Collaboration: Partner with data scientists and other stakeholders to deeply understand their needs and proactively provide innovative solutions to enhance productivity and model performance.
Mentorship: Act as a mentor to team members and data scientists, guiding best practices for ML workflows at Lightspeed.
Security and Compliance: Implement and enforce best practices for data security, model governance, and compliance with relevant regulations and standards.
Documentation: Create and maintain comprehensive documentation for AI/ML systems, processes, and workflows.
Research: Research & implement industry best practices for AI/ML systems, as appropriate for use cases.
Troubleshooting: Identify and resolve technical issues related to the AI/ML systems, providing support and solutions to ensure minimal disruption.


Qualifications

Education: Bachelor’s or Master’s degree in Computer Science, Engineering, Data Science, or a related field.
Experience: 5-7 years of experience in machine learning engineering, software engineering, or a related role with a focus on AI/ML systems.
Technical Skills:
Extensive experience with AI/ML frameworks and tools such as TensorFlow, PyTorch, Scikit-Learn, etc.
Advanced proficiency in programming languages such as Python, Java, or Scala, with a focus on applying them in AI/ML contexts.
Hands-on experience deploying and optimizing ML models on cloud platforms, leveraging their AI/ML services.
Experience with Kubernetes (K8s) or similar container orchestration platforms, with an understanding of managing or interacting with cloud solutions
Understanding of MLOps practices and CI/CD workflows for ML systems
Solid knowledge of data engineering concepts and tools, including data pipelines and ETL processes
Soft Skills:
Exceptional problem-solving abilities and analytical thinking.
Strong communication skills including the ability to work collaboratively in a team environment, mentor team members and collaborate effectively with cross-functional teams.
Demonstrated ability to prioritize and manage multiple high-impact projects, balancing short-term objectives with long-term goals.
Preferred Qualifications

Experience with MLOps practices and tools.
Knowledge of AI/ML model lifecycle management and monitoring.
Familiarity with infrastructure-as-code tools (e.g., Terraform, Ansible).


What’s in it for you

Join a growing team and help us move to the next level
Amazing benefits & perks, including equity for all Lightspeeders
Constant development of both your skill-set and business acumen with limitless growth opportunities
Lots of autonomy, flexible work culture
Innovation time to explore and learn at work
Shaping the company by joining cultural & technical committees
Tons of growth opportunities into technical or people management roles
Opportunity to join a fast-paced, high-growth company
Opportunity to learn, expand your skill set, forge wonderful relationships and make your mark within the diverse and inclusive Lightspeed family, a true Canadian tech success story


…. And enjoy a range of benefits that will keep you happy, healthy and (not) hungry.

Lightspeed equity scheme (we are all owners).
Flexible paid time off and remote work policies.
Health insurance.
Contributions to your pension plan - RRSP.
Health and wellness benefit of $500 per year.
Paid leave and assistance for new parents.
Mental health online platform and counseling & coaching services.
Training opportunities to grow your skills and career
Volunteer day.
Fully stacked kitchen (hot and cold beverages, meals served) 
Happy hours to build your relationships with colleagues after work 


To all recruitment agencies: Lightspeed does not accept unsolicited agency resumes. If we have not directly engaged your company in writing to supply candidates for a specific vacancy, Lightspeed will not be responsible for any fees related to unsolicited resumes.

Lightspeed is a proud equal opportunity employer and we are committed to creating an inclusive and barrier-free workplace. Lightspeed welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

Where to from here?

Obviously, this has to be mutually beneficial: we want you to step into a role you love, and we want to offer you a place you’re proud to come to every day. For a glimpse into our world check out our career page here.

Lightspeed is building communities through commerce, and we need people from all backgrounds and lived experiences to do that. We were founded in 2005, in Montreal’s gay village and our original members were all part of the LGBTQ+ community. The ethos of our business has been about inclusion from the very beginning, and we strive to provide a workplace where everyone belongs.

Who We Are

Powering the businesses that are the backbone of the global economy, Lightspeed's one-stop commerce platform helps merchants innovate to simplify, scale, and provide exceptional customer experiences. Our cloud commerce solution transforms and unifies online and physical operations, multichannel sales, expansion to new locations, global payments, financial solutions, and connection to supplier networks.

Founded in Montréal, Canada in 2005, Lightspeed is dual-listed on the New York Stock Exchange (NYSE: LSPD) and Toronto Stock Exchange (TSX: LSPD). With teams across North America, Europe, and Asia Pacific, the company serves retail, hospitality, and golf businesses in over 100 countries.

Lightspeed handles your information in accordance with our Applicant Privacy Statement.",[]
Senior Cloud Infrastructure Developer - MLOps,Coveo,"Montreal, QC",Hybrid,"About the job
Support the scale and growth of our AI platform

As a senior infrastructure developer on the ML Platform team, you will contribute to design and implement cloud infrastructure systems to support the scale and growth of our AI platform. Our team has built a mission-critical platform that trains thousands of models and serves over 100M model queries daily. This is your chance to accelerate AI innovation at Coveo by enhancing our ML platform’s capabilities to safely deploy, serve, and test models at scale.

This is your chance to contribute to AI innovation at Coveo by expanding the capabilities of our platform and supporting the shift toward agentic AI.

Here’s What You’ll Be Responsible For

Design and implement cloud and infrastructure systems and support them in production while ensuring it meets the requirements for scalability, reliability, costs and performance.
Advise ML developers and ML scientists across the ML unit and provide expert guidance on cloud best practices.
Help us modernize, improve and support the entire ML model lifecycle from model development to vector search, model building orchestration and ML developer tooling
Evaluate and integrate latest industry ML tools and technologies to provide a best-in-class ML development experience to our team of applied scientists

Here Is What Will Qualify You For The Role

5+ years of experience as a cloud developer.
Advanced knowledge of AWS, cloud systems and Infrastructure as code.
Exceptional resourcefulness and growth mindset.

Here Is What Will Make You Stand Out

Experience developing and supporting cloud systems in production
Experience building AI systems, infrastructure or tooling used by applied science teams
Experience with the following tools and technologies: vector database such as OpenSearch, Terraform, AWS SageMaker, AWS Bedrock, ML Flow

Do you think you can bring this role to life?

You don’t need to check every single box; passion goes a long way, and we appreciate that skillsets are transferable. Send us your CV, we want to get to know you! Join the #Coveolife!

We encourage all qualified applications regardless of, for example, age, gender, disability, gaps in CV, national or ethnic background. We know that applying for a new role is a lot of work and we really appreciate your time.",[]
Senior ML Engineer,Loblaw Companies Limited,,,"About the job
Come make your difference in communities across Canada, where authenticity, trust and making connections is valued – as we shape the future of Canadian retail, together. Our unique position as one of the country's largest employers, coupled with our commitment to positively impact the lives of all Canadians, provides our colleagues a range of opportunities and experiences to help Canadians Live Life Well®.

At Loblaw Companies Limited, we succeed through collaboration and commitment and set a high bar for ourselves and those around us. Whether you are just starting your career, re-entering the workforce, or looking for a new job, this is where you belong.

Senior ML Engineer, Brampton, ON

Loblaw Technology and Analytics is looking for an experienced, dedicated Senior ML Engineer to join our fast-growing team of Data Scientists, Engineers, Front-End Developers and Designers to build and enhance Loblaw's price optimization platform.

In addition to knowledge of cutting-edge machine learning models and techniques, you will bring experience in cloud-based development, engineering best practices and end-to-end product development. This includes the design and implementation of AI/ML algorithms, data pipelines, and ML infrastructure. You will assist teams of Data Scientists, ML Engineers, and Data Engineers in collaboration with an accomplished team of Product Managers and Designers to implement ML/AI solutions at scale. Our price optimization platform is critical to Loblaw’s long-term strategy, directly impacting revenue and customer satisfaction. As a Senior ML Engineer, you’ll play a key role in driving its evolution.

We are passionate about what we do and support each other’s growth! You will learn and grow with the team and will have the opportunity to work on a diverse set of challenges as you shape your career.

What You’ll Do: 

Provide architectural guidance and best practices to support internally built ML/AI applications (including feature enhancements and new microservices) and their integration with 3rd-party solutions across the teams’ project portfolio.
Be a strong individual contributor who can demonstrate the feasibility of novel ML approaches and estimate business value at scale.
Develop and execute ML Ops strategies to streamline the deployment, monitoring, and maintenance of machine learning models on Google Cloud Platform (GCP).
Optimize ML processes to enhance scalability, efficiency, and cost-effectiveness of machine learning solutions in production.
Collaborate with cross-functional teams (data scientists, engineers, project management, and business stakeholders) to deliver enhancements to existing functionalities and create innovative new features.
Identify reoccurring use cases and drive a strategy to create assets and infrastructure that can be leveraged across the organization.
Develop a highly engaged team by being an inclusive coach, mentor, and role model for all team members to help grow and promote our diverse talent pool.

Does This Sound Like You? 

5+ years of industry experience in the development of large-scale production systems for machine learning, with a strong preference for experience defining technical strategy and leading junior engineers.
Advanced proficiency with Data Science languages like Python, SQL, and their relevant libraries and frameworks.
Strong experience building end-to-end applications in the cloud (e.g. GCP) and making appropriate architectural choices. Practical experience with ML Ops and DevOps best practices.
Experience packaging and deploying applications as APIs using containerization technologies such as Docker and Kubernetes.
Strong interpersonal skills including ability to work in a multi-functional environment and a keen ability to learn new tools, concepts, and subject matter.
Experience in software engineering best practices (e.g. object-oriented programming, automated testing, writing ‘clean code’).
Experience working with Git Workflows, Jira, and Confluence; especially in the context of Agile product development.
A Master’s or Ph.D. degree in a quantitative field (e.g Computer Science, Engineering, Mathematics, Physics, etc.) is preferred.

Our commitment to Sustainability and Social Impact is an essential part of the way we do business, and we focus our attention on areas where we can have the greatest impact. Our approach to sustainability and social impact is based on three pillars – Environment, Sourcing and Community – and we are constantly looking for ways to demonstrate leadership in these important areas. Our CORE Values – Care, Ownership, Respect and Excellence – guide all our decision-making and come to life through our Blue Culture. We offer our colleagues progressive careers, comprehensive training, flexibility, and other competitive benefits – these are some of the many reasons why we are one of Canada’s Top Employers, Canada’s Best Diversity Employers, Canada’s Greenest Employers & Canada’s Top Employers for Young People.

If you are unsure whether your experience matches every requirement above, we encourage you to apply anyway. We are looking for varied perspectives which include diverse experiences that we can add to our team.

We have a long-standing focus on diversity, equity and inclusion because we know it will make our company a better place to work and shop. We are committed to creating accessible environments for our colleagues, candidates and customers. Requests for accommodation due to a disability (which may be visible or invisible, temporary or permanent) can be made at any stage of application and employment. We encourage candidates to make their accommodation needs known so that we can provide equitable opportunities.

Please Note:

Candidates who are 18 years or older are required to complete a criminal background check. Details will be provided through the application process.

#EN

#SS #DISTRC #ON",[]
Senior DevOps/MLOps,Global Relay,"Vancouver, BC",Hybrid,"About the job
Who we are:

For over 20 years, Global Relay has set the standard in enterprise information archiving with industry-leading cloud archiving, surveillance, eDiscovery, and analytics solutions. We securely capture and preserve the communications data of the world’s most highly regulated firms, giving them greater visibility and control over their information and ensuring compliance with stringent regulations.

Though we offer competitive compensation and benefits and all the other perks one would expect from an established company, we are not your typical technology company. Global Relay is a career-building company. A place for big ideas. New challenges. Groundbreaking innovation. It’s a place where you can genuinely make an impact – and be recognized for it.

We believe great businesses thrive on diversity, inclusion, and the contributions of all employees. To that end, we recruit candidates from different backgrounds and foster a work environment that encourages employees to collaborate and learn from each other, completely free of barriers.

Your role:

As a Senior DevOps/MLOps on our Artificial Intelligence team you will be responsible for the reliability and smooth operation of various environments and build automation to improve reliability and efficiency of code and machine learning model delivery from build to production. Challenge yourself by learning new technologies, and apply your skills across our different projects and application domains. You'll get to work in the exciting field of MLOps and will have the opportunity to work with tools unique to machine learning and artificial intelligence.

At Global Relay we use leading edge technologies to deploy and manage the infrastructure that delivers highly scalable and available services. The role involves cross-team collaboration and communication; you will be working closely with key stakeholders to ensure that product requirements are met. This is an opportunity to influence the design and implementation of systems at scales that many do not get a chance to work at.

Your responsibilities: 


Automation: Developing tools & frameworks to enhance our CI (Continuous Integration) & CD (Continuous Delivery) automation using industry standard CI/CD practices.
Deployments: Leveraging the above mentioned CI/CD automation to deploy our services to Kubernetes. 
Operations: Monitor and ensure smooth operation of our services in various environments.
Service Reliability: Occasionally provide support and initial troubleshooting when required by reviewing dashboards and logs to ensure system issues are timely addressed.


About you: 


5+ years experience in a DevOps/MLOps or in a similar role.
Bachelor's degree in computer science or related field, or equivalent work experience.
Understanding of computer science fundamentals like threading, OOP and more.
Understanding of software systems concepts such as networking, firewalls, protocols, databases and more.
Understanding of software delivery practices such as Git branching models, configuration management, secret rotation, feature toggling, no-downtime deployments, and more.
Experience mentoring Junior and Intermediate DevOps/MLOps.
Strong organizational and communication skills.
Experience with:
CI/CD tools such as Jenkins.
Containerization technology such as; Docker, Kubernetes.
Python or other similar scripting languages.
Databases such as; CockroachDB, PostgreSQL. 
Distributed event streaming platforms such as; Kafka.
Instrumentation & Monitoring tools such as: Splunk, Loki, Zabbix, or Prometheus.
Package managers and artifact repositories such as: Artifactory, npm.
Mentoring Junior DevOps/MLOps.


Nice-to-haves:


Artificial intelligence or machine learning tools such as; MLFlow, JupyterHub, DVC, TensorFlow
Supporting containerized GPU workloads in Kubernetes
NoSQL data stores, including vector databases
Supporting Large Language Models


Compensation:

Global Relay advertises the pay range for this role in compliance with British Columbia’s pay transparency laws. Individual pay rates are determined by evaluating factors such as expertise, skills, education, and professional background.

The range below reflects the expected annual base salary, which is only one element of our comprehensive total rewards package designed to reflect our company pay philosophy, culture and values. We aim to foster an inspiring work environment and support employees' work-life rhythms. We provide a comprehensive extended health benefits program, including virtual healthcare and a wellness allowance. Employees also receive annual allotted vacation days, which increase based on tenure. Other benefits include: Paid sick days, maternity/parental enhancement program, corporate bonuses, and an RRSP contribution matching program.

For Vancouver-based employees, we provide a subsidized meal program, courtesy of our talented in-house culinary team!

British Columbia - Base Salary Range:

$90,000—$130,000 CAD

What you can expect:

At Global Relay, there’s no ceiling to what you can achieve. It’s the land of opportunity for the energetic, the intelligent, the driven. You’ll receive the mentoring, coaching, and support you need to reach your career goals. You’ll be part of a culture that breeds creativity and rewards perseverance and hard work. And you’ll be working alongside smart, talented individuals from diverse backgrounds, with complementary knowledge and skills.

Global Relay is an equal-opportunity employer committed to diversity, equity, and inclusion.

We seek to ensure reasonable adjustments, accommodations, and personal time are tailored to meet the unique needs of every individual.

We understand flexible work arrangements are important, and we encourage that in our work culture. Whether it’s flexibility around work hours, workstyle, or lifestyle, we want to ensure our employees have a healthy work/life balance. We support and value a hybrid work model that blends collaboration with the team in the office and focus time from the comfort of your home.

To learn more about our business, culture, and community involvement, visit www.globalrelay.com.",[]
Senior Machine Learning Developer,Elastic,Canada,Remote,"About the job
Elastic, the Search AI Company, enables everyone to find the answers they need in real time, using all their data, at scale — unleashing the potential of businesses and people. The Elastic Search AI Platform, used by more than 50% of the Fortune 500, brings together the precision of search and the intelligence of AI to enable everyone to accelerate the results that matter. By taking advantage of all structured and unstructured data — securing and protecting private information more effectively — Elastic’s complete, cloud-based solutions for search, security, and observability help organizations deliver on the promise of AI.

What Is The Role:

Elastic Security focuses on AI driven Security solutions across our SIEM and Endpoint products. The Security ML team researches, designs, and builds AI and ML solutions and drives innovation in this domain. We are looking for a Senior MLOps Engineer to join our ML team and continue to innovate, build and ship new models that will help secure our users against the latest emerging threats. You will collaborate with the broader Elastic Security team, which consists of a diverse group of skilled researchers, ML engineers, data scientists, and developers who possess extensive domain expertise in their respective areas. Our geographically dispersed team values positivity and inclusion in the workplace, collaborative learning, and candid communication.

If you are passionate about ML and Data Science and would like to apply your expertise to secure world's data from attacks, we would love to have you join our growing team!

What you’ll be doing:

Support ongoing efforts to improve data quality and ML model training automation, as well as observability and reproducibility of ML models
Collaborate within the Data Science team, and with members of other teams, especially Data Engineering
Promote long-term vision for monitoring performance of deployed models to identify concept drift and determine retraining cadence
Determine how to improve models over time by leveraging implicit and explicit feedback

What you bring:

Be comfortable working in a fully-remote environment
Be able to communicate clearly to diverse groups of stakeholders coming from different disciplines, timezones, and programming language preferences
Proficient Python programming skills
Experience with writing and running tests (unit tests, integration tests, regression tests)
Experience with AWS or GCP
Experience with Airflow, Buildkite or other CICD tooling
Experience with performing data analysis as required to support data quality decisions
Ability to both give and receive helpful code reviews

Bonus points for:

Experience in Security
Experience with Kubernetes
Working knowledge of deep learning, clustering, and/or graph algorithms
Experience designing, training, and evaluating models using popular ML frameworks

Compensation for this role is in the form of base salary. This role does not have a variable compensation component. The typical starting salary range for new hires in this role is listed below.

These ranges represent the lowest to highest salary we reasonably and in good faith believe we would pay for this role at the time of this posting. We may ultimately pay more or less than the posted range, and the ranges may be modified in the future.

An employee's position within the salary range will be based on several factors including, but not limited to, relevant education, qualifications, certifications, experience, skills, geographic location, performance, and business or organizational needs.

Elastic believes that employees should have the opportunity to share in the value that we create together for our shareholders. Therefore, in addition to cash compensation, this role is currently eligible to participate in Elastic's stock program. Our total rewards package also includes a company-matched Registered Retirement Savings Plan (RRSP) with dollar-for-dollar matching up to 6% of eligible earnings, along with a range of other benefits offered with a holistic emphasis on employee well-being.

The typical starting salary range for this role is:

$128,300—$203,000 CAD

Additional Information - We Take Care Of Our People

As a distributed company, diversity drives our identity. Whether you’re looking to launch a new career or grow an existing one, Elastic is the type of company where you can balance great work with great life. Your age is only a number. It doesn’t matter if you’re just out of college or your children are; we need you for what you can do.

We strive to have parity of benefits across regions and while regulations differ from place to place, we believe taking care of our people is the right thing to do.

Competitive pay based on the work you do here and not your previous salary
Health coverage for you and your family in many locations
Ability to craft your calendar with flexible locations and schedules for many roles
Generous number of vacation days each year
Increase your impact - We match up to $2000 (or local currency equivalent) for financial donations and service
Up to 40 hours each year to use toward volunteer projects you love
Embracing parenthood with minimum of 16 weeks of parental leave

Different people approach problems differently. We need that. Elastic is an equal opportunity employer and is committed to creating an inclusive culture that celebrates different perspectives, experiences, and backgrounds. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, pregnancy, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, disability status, or any other basis protected by federal, state or local law, ordinance or regulation.

We welcome individuals with disabilities and strive to create an accessible and inclusive experience for all individuals. To request an accommodation during the application or the recruiting process, please email candidate_accessibility@elastic.co. We will reply to your request within 24 business hours of submission.

Applicants have rights under Federal Employment Laws, view posters linked below: Family and Medical Leave Act (FMLA) Poster; Pay Transparency Nondiscrimination Provision Poster; Employee Polygraph Protection Act (EPPA) Poster and Know Your Rights (Poster)

Elasticsearch develops and distributes encryption software and technology that is subject to U.S. export controls and licensing requirements for individuals who are located in or are nationals of the following sanctioned countries and regions: Belarus, Cuba, Iran, North Korea, Russia, Syria, the Crimea Region of Ukraine, the Donetsk People’s Republic (“DNR”), and the Luhansk People’s Republic (“LNR”). If you are located in or are a national of one of the listed countries or regions, an export license may be required as a condition of your employment in this role. Please note that national origin and/or nationality do not affect eligibility for employment with Elastic.

Please see here for our Privacy Statement.

Different people approach problems differently. We need that. Elastic is an equal opportunity/affirmative action employer committed to diversity, equity, and inclusion. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, pregnancy, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, disability status, or any other basis protected by federal, state or local law, ordinance or regulation.

We welcome individuals with disabilities and strive to create an accessible and inclusive experience for all individuals. To request an accommodation during the application or the recruiting process, please email candidate_accessibility@elastic.co We will reply to your request within 24 business hours of submission.

Applicants have rights under Federal Employment Laws, view posters linked below:

Family and Medical Leave Act (FMLA) Poster; Equal Employment Opportunity (EEO) Poster; and Employee Polygraph Protection Act (EPPA) Poster.

Please see here for our Privacy Statement.",[]
Direct client position- MLOps Engineer-Remote-Canada,Accion Labs,Canada,Remote,"About the job
Role: Sr. MLOps Engineer
Location: Remote-Canada
Type of position: Contract 12 months
Required Skills and Experience:
Proven experience in MLOps engineering, with a strong understanding of ML lifecycle management
Expertise in Databricks and cloud-native ML environments (e.g., Azure ML, AWS SageMaker, GCP Vertex AI)
Proficiency in tools such as MLflow, Kubeflow, Airflow, or similar orchestration frameworks
Experience with monitoring and observability stacks (e.g., Prometheus, Grafana, ELK, or Datadog)
Strong programming skills in Python and familiarity with containerization technologies like Docker and Kubernetes
Excellent problem-solving and communication skills
Experience working in the Healthcare domain.",[]
MLOps Engineering Manager,Workday,"Greater Toronto Area, Canada",Hybrid,"About the job
Your work days are brighter here.

At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.

At Workday, we value our candidates’ privacy and data security. Workday will never ask candidates to apply to jobs through websites that are not Workday Careers.

Please be aware of sites that may ask for you to input your data in connection with a job posting that appears to be from Workday but is not.

In addition, Workday will never ask candidates to pay a recruiting fee, or pay for consulting or coaching services, in order to apply for a job at Workday.

About The Team

This is an opportunity to be part of a growth team focused on MLOps. We build ML capabilities into our products, and you would be building part of the next generation of Workday technology. We believe predictive products can be as ground-breaking to the next interation of technology as mobile was to the last.

About The Role

We are seeking a highly skilled and experienced Machine Learning Manager to lead our dynamic team of machine learning engineers. The ideal candidate will be a hands-on technical leader with a consistent track record of building and deploying machine learning platforms and integrating them with other services. You will be responsible for driving the development and implementation of our machine learning strategy, ensuring the delivery of high-quality, scalable, and robust solutions.

Responsibilities:

Lead and develop a team of software development engineers, fostering a collaborative, innovative environment.
Drive the design, development, and deployment of end-to-end machine learning systems, from data ingestion and preprocessing to model training, evaluation, and deployment.
Oversee the building/development and maintenance of our ML platform, ensuring its scalability, reliability, and performance.
Lead the integration of machine learning solutions with other company services and systems.
Collaborate with multi-functional teams, including product management, data engineering, and software development, to define project requirements and deliver solutions that meet business needs.
Stay up-to-date with the latest advancements in machine learning, cloud computing, and related technologies, and drive the adoption of standard methodologies.
Ensure the quality, security, and compliance of all machine learning solutions.
Mentor and develop team members, providing technical guidance and fostering their professional growth.
Manage project timelines, resources, and budgets effectively.
Contribute to the overall AI/ML strategy of the organization.

About You

Basic Qualifications:

Bachelor's degree in Computer Science, Machine Learning; Master's degree preferred.
Minimum of 5 years of experience in a management role, leading machine learning or software engineering teams.
Minimum of 10 years of hands-on experience in software engineering, with a strong focus on machine learning.
Deep understanding of machine learning principles, algorithms, and techniques.
Extensive experience with cloud platforms (e.g., AWS, GCP), including machine learning services (e.g., SageMaker, Vertex AI, Databricks).
Proven experience with data engineering concepts and tools, including data warehousing, ETL processes, and big data technologies (e.g., Spark).
Proficiency in Python and experience with machine learning libraries and frameworks (e.g.,PyTorch, TensorFlow, scikit-learn).
Proven understanding of software development standard processes, including version control (Git), CI/CD, and testing.
Strong experience with containerization and orchestration technologies (e.g., Docker, Kubernetes).
Experience with data platforms and databases (SQL and NoSQL).
Experience with MLOps practices and tools, ideally Kubeflow ecosystem.

Other Qualifications:

Excellent communication, collaboration, and leadership skills.
Strong problem-solving and analytical abilities.
Ability to thrive in a fast-paced, dynamic environment.
Proven ability to deliver high-quality machine learning solutions in a production setting.
Contributions to open-source machine learning projects.
Experience with specific machine learning domains (e.g., natural language processing, recommendation systems)

Workday Pay Transparency Statement 

The annualized base salary ranges for the primary location and any additional locations are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please click here.

Primary Location: CAN.ON.Toronto

Primary CAN Base Pay Range: $132,000 - $198,000 CAD

Additional CAN Location(s) Base Pay Range: $132,000 - $198,000 CAD

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.

Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.

Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.

Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!

,",[]
Senior MLOps Engineer,Clio,"Toronto, ON",Hybrid,"About the job
Clio is more than just a tech company–we are a global leader that is transforming the legal experience for all by bettering the lives of legal professionals while increasing access to justice.

Summary:

We are currently seeking a Senior MLOps Engineer to join our Engineering team. This role is available to candidates across Canada. If you are local to one of our hubs (Burnaby, Calgary, or Toronto) you will be expected to be in office minimum two days per week for our Anchor Days.

What your team does:

Our MLOps team builds and operates the scalable infrastructure and robust platforms that power GenAI solutions across the company. We blend deep AI and ML expertise with strong software engineering and cloud infrastructure skills to enable the entire lifecycle of machine learning and generative AI - spanning experimentation, deployment, monitoring, and continuous improvement. By applying best practices in CI/CD, observability, cost optimization, and model governance, and leveraging state-of-the-art tools and frameworks, we ensure our AI systems are reliable, performant, and aligned with business goals. We partner closely with data scientists, engineers, and product teams to accelerate the delivery of impactful AI capabilities.

What a day in the life might look like:

Build and deploy LLM-based solutions that help Clio’s clients save time and improve operational efficiency.
Collaborate cross-functionally with engineering, product management, operations, and data science to identify and develop new ML-driven features.
Work agilely alongside MLOps, MLE, and full stack developers on diverse projects spanning multiple engineering teams across three countries.
Evaluate and integrate new ML tools and frameworks to accelerate experimentation and optimize operations.
Troubleshoot and resolve production issues such as data drift and model latency using observability tools and logs.
Participate in design reviews and contribute to architectural decisions shaping Clio’s AI platforms.
Engage in code reviews within your team and across the company, providing and receiving constructive feedback to maintain high standards.
Continuously learn, challenge yourself, and grow as a machine learning expert while mentoring and collaborating with teammates.

What you may have:

Strong Python or Ruby development skills, with experience building production-grade applications, services, or ML tooling.
Expertise in cloud infrastructure (AWS, GCP, or Azure), including Kubernetes, and infrastructure-as-code (Terraform, Helm, or similar).
Experience with CI/CD and automating model training, testing, and deployment pipelines.
Solid understanding of machine learning and GenAI concepts, workflows, and lifecycle management.
Demonstrated leadership skills, with the ability to mentor and guide team members effectively. 
Demonstrated ability to fully own the design and delivery of robust, scalable solutions from concept through implementation.
You excel at breaking down complex, challenging problems into manageable parts and iterating toward effective solutions.
You are naturally curious and love to dig deep into problems, constantly asking, “Why?”.
You communicate clearly and concisely, regardless of the medium (text, voice, or in-person).
You value collaboration and proactively seek to build context to power your decisions.
You have a team-first mentality and will naturally support co-workers when you sense they are facing difficulty.

Serious bonus points if you have:

Familiarity with GenAI observability tools (logging, metrics, tracing) to monitor and debug AI systems.
Awareness of ML governance, responsible AI, and best practices for secure, compliant AI operations.
Proficient in developing and utilizing guardrails to ensure safe, reliable, and compliant GenAI operations.

What you will find here:

Compensation is one of the main components of Clio’s Total Rewards Program. We have developed a series of programs and processes to ensure we are creating fair and competitive pay practices that form the foundation of our human and high-performing culture.

Some highlights of our Total Rewards program include: 

Competitive, equitable salary with top-tier health benefits, dental, and vision insurance 
Hybrid work environment, with expectation for local Clions (Vancouver, Calgary, Toronto, and Dublin) to be in office minimum 2 days per week on our Anchor Days. 
Flexible time off policy, with an encouraged 20 days off per year.
$2000 annual counseling benefit
RRSP matching and RESP contribution 
Clioversary recognition program with special acknowledgement at 3, 5, 7, and 10 years 

The full salary range* for this role is $152,600 to $179,500 to $206,400 CAD.Please note salary bands may differ based on location and local currency. Additionally, benefit offerings may differ depending on the employee's location.

We aim to hire all candidates between the minimum and the midpoint of the full salary range. We reserve the midpoint to the maximum of the salary band for internal employees who demonstrate sustained high performance and impact at Clio. The final offer amount for this role will be dependent on individual experience and skillset of the candidate. Please note there are a separate set of salary bands for other regions based on local currency.

Diversity, Inclusion, Belonging and Equity (DIBE) & Accessibility 

Our team shows up as their authentic selves, and are united by our mission. We are dedicated to diversity, equity and inclusion. We pride ourselves in building and fostering an environment where our teams feel included, valued, and enabled to do the best work of their careers, wherever they choose to log in from. We believe that different perspectives, skills, backgrounds, and experiences result in higher-performing teams and better innovation. We are committed to equal employment and we encourage candidates from all backgrounds to apply.

Clio provides accessibility accommodations during the recruitment process. Should you require any accommodation, please let us know and we will work with you to meet your needs.

Learn more about our culture at clio.com/careers

Disclaimer: We only communicate with candidates through official @clio.com email addresses.",[]
Senior MLOps Engineer,Clio,Canada,Remote,"About the job
Clio is more than just a tech company–we are a global leader that is transforming the legal experience for all by bettering the lives of legal professionals while increasing access to justice.

Summary:

We are currently seeking a Senior MLOps Engineer to join our Engineering team. This role is available to candidates across Canada. If you are local to one of our hubs (Burnaby, Calgary, or Toronto) you will be expected to be in office minimum two days per week for our Anchor Days.

What your team does:

Our MLOps team builds and operates the scalable infrastructure and robust platforms that power GenAI solutions across the company. We blend deep AI and ML expertise with strong software engineering and cloud infrastructure skills to enable the entire lifecycle of machine learning and generative AI - spanning experimentation, deployment, monitoring, and continuous improvement. By applying best practices in CI/CD, observability, cost optimization, and model governance, and leveraging state-of-the-art tools and frameworks, we ensure our AI systems are reliable, performant, and aligned with business goals. We partner closely with data scientists, engineers, and product teams to accelerate the delivery of impactful AI capabilities.

What a day in the life might look like:

Build and deploy LLM-based solutions that help Clio’s clients save time and improve operational efficiency.
Collaborate cross-functionally with engineering, product management, operations, and data science to identify and develop new ML-driven features.
Work agilely alongside MLOps, MLE, and full stack developers on diverse projects spanning multiple engineering teams across three countries.
Evaluate and integrate new ML tools and frameworks to accelerate experimentation and optimize operations.
Troubleshoot and resolve production issues such as data drift and model latency using observability tools and logs.
Participate in design reviews and contribute to architectural decisions shaping Clio’s AI platforms.
Engage in code reviews within your team and across the company, providing and receiving constructive feedback to maintain high standards.
Continuously learn, challenge yourself, and grow as a machine learning expert while mentoring and collaborating with teammates.

What you may have:

Strong Python or Ruby development skills, with experience building production-grade applications, services, or ML tooling.
Expertise in cloud infrastructure (AWS, GCP, or Azure), including Kubernetes, and infrastructure-as-code (Terraform, Helm, or similar).
Experience with CI/CD and automating model training, testing, and deployment pipelines.
Solid understanding of machine learning and GenAI concepts, workflows, and lifecycle management.
Demonstrated leadership skills, with the ability to mentor and guide team members effectively. 
Demonstrated ability to fully own the design and delivery of robust, scalable solutions from concept through implementation.
You excel at breaking down complex, challenging problems into manageable parts and iterating toward effective solutions.
You are naturally curious and love to dig deep into problems, constantly asking, “Why?”.
You communicate clearly and concisely, regardless of the medium (text, voice, or in-person).
You value collaboration and proactively seek to build context to power your decisions.
You have a team-first mentality and will naturally support co-workers when you sense they are facing difficulty.

Serious bonus points if you have:

Familiarity with GenAI observability tools (logging, metrics, tracing) to monitor and debug AI systems.
Awareness of ML governance, responsible AI, and best practices for secure, compliant AI operations.
Proficient in developing and utilizing guardrails to ensure safe, reliable, and compliant GenAI operations.

What you will find here:

Compensation is one of the main components of Clio’s Total Rewards Program. We have developed a series of programs and processes to ensure we are creating fair and competitive pay practices that form the foundation of our human and high-performing culture.

Some highlights of our Total Rewards program include: 

Competitive, equitable salary with top-tier health benefits, dental, and vision insurance 
Hybrid work environment, with expectation for local Clions (Vancouver, Calgary, Toronto, and Dublin) to be in office minimum 2 days per week on our Anchor Days. 
Flexible time off policy, with an encouraged 20 days off per year.
$2000 annual counseling benefit
RRSP matching and RESP contribution 
Clioversary recognition program with special acknowledgement at 3, 5, 7, and 10 years 

The full salary range* for this role is $152,600 to $179,500 to $206,400 CAD.Please note salary bands may differ based on location and local currency. Additionally, benefit offerings may differ depending on the employee's location.

We aim to hire all candidates between the minimum and the midpoint of the full salary range. We reserve the midpoint to the maximum of the salary band for internal employees who demonstrate sustained high performance and impact at Clio. The final offer amount for this role will be dependent on individual experience and skillset of the candidate. Please note there are a separate set of salary bands for other regions based on local currency.

Diversity, Inclusion, Belonging and Equity (DIBE) & Accessibility 

Our team shows up as their authentic selves, and are united by our mission. We are dedicated to diversity, equity and inclusion. We pride ourselves in building and fostering an environment where our teams feel included, valued, and enabled to do the best work of their careers, wherever they choose to log in from. We believe that different perspectives, skills, backgrounds, and experiences result in higher-performing teams and better innovation. We are committed to equal employment and we encourage candidates from all backgrounds to apply.

Clio provides accessibility accommodations during the recruitment process. Should you require any accommodation, please let us know and we will work with you to meet your needs.

Learn more about our culture at clio.com/careers

Disclaimer: We only communicate with candidates through official @clio.com email addresses.",[]
Analyste développeur - Intelligence artificielle MLOps,Beneva,"Montreal, Quebec, Canada",Hybrid,"About the job
Titre interne officiel:

Analyste développeur - Intelligence artificielle MLOps

Statut:

Temporaire (Durée déterminée)

Sommaire:

Relevant de la directrice – Hyperautomatisation et intelligence artificielle, le développeur MLOps œuvre dans les pratiques du développement de « Machine Learning », dès la capture du besoin d’affaires, en passant par la préparation de données et de modèles en intelligence artificielle jusqu’à son déploiement en production. Il participe activement à la compréhension des requis affaires et des processus à optimiser. Il agit à titre d’expert de pointe dans le domaine technologique de l’intelligence artificielle pour la conception, le développement, l’évaluation et la maintenance de solutions d’intelligence artificielle pour des activités d’affaires diversifiées telles que les affaires numériques, le marketing et ventes, l’actuariat, et les équipes opérationnelles. Sa contribution touche l’ensemble des champs d’activités Beneva tels que l’assurance de dommages, l’assurance collective, l’assurance voyage, l’assurance individuelle et les produits d’investissement. Le développeur MLOps assume ainsi un rôle transversal de bout en bout pour l'ensemble des secteurs d’activités de Beneva dans la mise en place de solutions d’intelligence artificielle.

Responsabilités générales

Participe à la capture du besoin d’affaires et amène son expertise dans l’optimisation des processus par une vision des capacités offertes dans le domaine de pointe de l’intelligence artificielle
Contribuer à la conception / au développement / à l’évaluation / à la maintenance de solutions d’intelligence artificielle
Prendre les décisions et assurer la mise en œuvre de la cible d’architecture technologique MLOps nécessaire à l’opérationnalisation des solutions d’intelligence artificielle
Agir comme référence pour les technologies Anaconda Entreprise, AWS Sagemaker, MLFlow et Python/R/SQL nécessaire pour concevoir et opérationnaliser les solutions basées sur l’intelligence artificielle
Prendre en charge les travaux de préparation de données (structurées et non-structurées) complexes avec le framework d’ingénierie de données DWA
Explorer et mettre en œuvre l’utilisation des services API disponibles sur un Cloud ou des librairies open-source pour développer les solutions d’intelligence artificielle
Collaborer aux différents projets de veille, expérimentation et amélioration des technologies, modèles d’intelligence artificielle, langages, logiciels et outils de développement utilisés par l’équipe
Exercer un rôle-conseil en tant que référent sur les technologies MLOps ; être garant de l’application des règles d’architecture préalablement définies et la bonne utilisation des technologies
Assurer la formation et le coaching des nouveaux équipiers : « pair programming », formation sur l’architecture MLOps, encadrement et suivi de l’évolution de leurs travaux techniques
Être responsable de dossiers spéciaux : CI/CD, déploiement, environnements, preuve de concept, autres
Veiller au bon fonctionnement, à l’évolution, à la cohérence et à la performance de l’écosystème MLOps incluant les modèles d’intelligence artificielle
Participe à la coordination des activités en assurant, entre autres, le lien avec les autres parties prenantes de l’écosystème au besoin : autres équipes de réalisation TI, équipes opérationnelles, sécurité, conformité, réseau, infrastructure, etc. 

Qualifications

1 à 8 années d’expérience en tant que développeur Intelligence Artificielle ou données (selon le niveau du candidat recherché)
Maitriser l’anglais et le français tant à l’oral et qu’à l’écrit
Baccalauréat en informatique, mathématique ou l’équivalent dans les domaines de l’intelligence artificielle
Maîtrise un atout

Qualifications Spécifiques

Avoir de l’expérience dans la réalisation de projets en intelligence artificielle
Avoir des connaissances approfondies des concepts d’intelligence artificielle : concepts de régression linéaire, de série chronologique, de réseau de neurones, d’arbres de classification/régression, d’inférence bayésienne, de machine à vecteurs de support et autres techniques de machine learning
Comprendre les enjeux liés à la préparation de données pour l’intelligence artificielle
Avoir une bonne maîtrise des bonnes pratiques en ingénierie logicielle pour structurer du code source
Avoir des connaissances importantes en ingénierie de données
Détenir une bonne connaissance des langages Python et/ou R
Avoir une bonne maîtrise de AWS Sagemaker ou Anaconda (version Entreprise)
Avoir de l’expérience avec l’opérationnalisation de modèles d’intelligence artificielle avec MLFlow
Démontrer les connaissances approfondies avec des outils et des pratiques de DevOps (GitHub, jenkins) et de la contenarisation (Kubernetes)
Avoir une expérience pratique dans le développement et la maintenant d’API REST
Détenir une expérience avec des services « cognitives » ou analytiques disponible sur le Cloud

Beneva souscrit au programme d’accès à l’égalité en emploi et encourage les membres des groupes visés à savoir les femmes, les personnes handicapées, les autochtones et les minorités visibles, à soumettre leur candidature. 

Raison d'être : Les gens sont au cœur de nos actions. Nous les accompagnons dans leurs projets de vie en leur apportant la tranquillité d'esprit et nous contribuons au bien-être de la collectivité. 

Suivez-nous sur Instagram ! 

@beneva.ca",[]
Analyste développeur - Intelligence artificielle MLOps,Beneva,"Longueuil, QC",Hybrid,"About the job
Titre interne officiel:

Analyste développeur - Intelligence artificielle MLOps

Statut:

Temporaire (Durée déterminée)

Sommaire:

Relevant de la directrice – Hyperautomatisation et intelligence artificielle, le développeur MLOps œuvre dans les pratiques du développement de « Machine Learning », dès la capture du besoin d’affaires, en passant par la préparation de données et de modèles en intelligence artificielle jusqu’à son déploiement en production. Il participe activement à la compréhension des requis affaires et des processus à optimiser. Il agit à titre d’expert de pointe dans le domaine technologique de l’intelligence artificielle pour la conception, le développement, l’évaluation et la maintenance de solutions d’intelligence artificielle pour des activités d’affaires diversifiées telles que les affaires numériques, le marketing et ventes, l’actuariat, et les équipes opérationnelles. Sa contribution touche l’ensemble des champs d’activités Beneva tels que l’assurance de dommages, l’assurance collective, l’assurance voyage, l’assurance individuelle et les produits d’investissement. Le développeur MLOps assume ainsi un rôle transversal de bout en bout pour l'ensemble des secteurs d’activités de Beneva dans la mise en place de solutions d’intelligence artificielle.

Responsabilités générales

Participe à la capture du besoin d’affaires et amène son expertise dans l’optimisation des processus par une vision des capacités offertes dans le domaine de pointe de l’intelligence artificielle
Contribuer à la conception / au développement / à l’évaluation / à la maintenance de solutions d’intelligence artificielle
Prendre les décisions et assurer la mise en œuvre de la cible d’architecture technologique MLOps nécessaire à l’opérationnalisation des solutions d’intelligence artificielle
Agir comme référence pour les technologies Anaconda Entreprise, AWS Sagemaker, MLFlow et Python/R/SQL nécessaire pour concevoir et opérationnaliser les solutions basées sur l’intelligence artificielle
Prendre en charge les travaux de préparation de données (structurées et non-structurées) complexes avec le framework d’ingénierie de données DWA
Explorer et mettre en œuvre l’utilisation des services API disponibles sur un Cloud ou des librairies open-source pour développer les solutions d’intelligence artificielle
Collaborer aux différents projets de veille, expérimentation et amélioration des technologies, modèles d’intelligence artificielle, langages, logiciels et outils de développement utilisés par l’équipe
Exercer un rôle-conseil en tant que référent sur les technologies MLOps ; être garant de l’application des règles d’architecture préalablement définies et la bonne utilisation des technologies
Assurer la formation et le coaching des nouveaux équipiers : « pair programming », formation sur l’architecture MLOps, encadrement et suivi de l’évolution de leurs travaux techniques
Être responsable de dossiers spéciaux : CI/CD, déploiement, environnements, preuve de concept, autres
Veiller au bon fonctionnement, à l’évolution, à la cohérence et à la performance de l’écosystème MLOps incluant les modèles d’intelligence artificielle
Participe à la coordination des activités en assurant, entre autres, le lien avec les autres parties prenantes de l’écosystème au besoin : autres équipes de réalisation TI, équipes opérationnelles, sécurité, conformité, réseau, infrastructure, etc. 

Qualifications

1 à 8 années d’expérience en tant que développeur Intelligence Artificielle ou données (selon le niveau du candidat recherché)
Maitriser l’anglais et le français tant à l’oral et qu’à l’écrit
Baccalauréat en informatique, mathématique ou l’équivalent dans les domaines de l’intelligence artificielle
Maîtrise un atout

Qualifications Spécifiques

Avoir de l’expérience dans la réalisation de projets en intelligence artificielle
Avoir des connaissances approfondies des concepts d’intelligence artificielle : concepts de régression linéaire, de série chronologique, de réseau de neurones, d’arbres de classification/régression, d’inférence bayésienne, de machine à vecteurs de support et autres techniques de machine learning
Comprendre les enjeux liés à la préparation de données pour l’intelligence artificielle
Avoir une bonne maîtrise des bonnes pratiques en ingénierie logicielle pour structurer du code source
Avoir des connaissances importantes en ingénierie de données
Détenir une bonne connaissance des langages Python et/ou R
Avoir une bonne maîtrise de AWS Sagemaker ou Anaconda (version Entreprise)
Avoir de l’expérience avec l’opérationnalisation de modèles d’intelligence artificielle avec MLFlow
Démontrer les connaissances approfondies avec des outils et des pratiques de DevOps (GitHub, jenkins) et de la contenarisation (Kubernetes)
Avoir une expérience pratique dans le développement et la maintenant d’API REST
Détenir une expérience avec des services « cognitives » ou analytiques disponible sur le Cloud

Beneva souscrit au programme d’accès à l’égalité en emploi et encourage les membres des groupes visés à savoir les femmes, les personnes handicapées, les autochtones et les minorités visibles, à soumettre leur candidature. 

Raison d'être : Les gens sont au cœur de nos actions. Nous les accompagnons dans leurs projets de vie en leur apportant la tranquillité d'esprit et nous contribuons au bien-être de la collectivité. 

Suivez-nous sur Instagram ! 

@beneva.ca",[]
Senior Machine Learning Developer,Elastic,Canada,Remote,"About the job
Elastic, the Search AI Company, enables everyone to find the answers they need in real time, using all their data, at scale — unleashing the potential of businesses and people. The Elastic Search AI Platform, used by more than 50% of the Fortune 500, brings together the precision of search and the intelligence of AI to enable everyone to accelerate the results that matter. By taking advantage of all structured and unstructured data — securing and protecting private information more effectively — Elastic’s complete, cloud-based solutions for search, security, and observability help organizations deliver on the promise of AI.

What Is The Role:

Elastic Security focuses on AI driven Security solutions across our SIEM and Endpoint products. The Security ML team researches, designs, and builds AI and ML solutions and drives innovation in this domain. We are looking for a Senior MLOps Engineer to join our ML team and continue to innovate, build and ship new models that will help secure our users against the latest emerging threats. You will collaborate with the broader Elastic Security team, which consists of a diverse group of skilled researchers, ML engineers, data scientists, and developers who possess extensive domain expertise in their respective areas. Our geographically dispersed team values positivity and inclusion in the workplace, collaborative learning, and candid communication.

If you are passionate about ML and Data Science and would like to apply your expertise to secure world's data from attacks, we would love to have you join our growing team!

What you’ll be doing:

Support ongoing efforts to improve data quality and ML model training automation, as well as observability and reproducibility of ML models
Collaborate within the Data Science team, and with members of other teams, especially Data Engineering
Promote long-term vision for monitoring performance of deployed models to identify concept drift and determine retraining cadence
Determine how to improve models over time by leveraging implicit and explicit feedback

What you bring:

Be comfortable working in a fully-remote environment
Be able to communicate clearly to diverse groups of stakeholders coming from different disciplines, timezones, and programming language preferences
Proficient Python programming skills
Experience with writing and running tests (unit tests, integration tests, regression tests)
Experience with AWS or GCP
Experience with Airflow, Buildkite or other CICD tooling
Experience with performing data analysis as required to support data quality decisions
Ability to both give and receive helpful code reviews

Bonus points for:

Experience in Security
Experience with Kubernetes
Working knowledge of deep learning, clustering, and/or graph algorithms
Experience designing, training, and evaluating models using popular ML frameworks

Compensation for this role is in the form of base salary. This role does not have a variable compensation component. The typical starting salary range for new hires in this role is listed below.

These ranges represent the lowest to highest salary we reasonably and in good faith believe we would pay for this role at the time of this posting. We may ultimately pay more or less than the posted range, and the ranges may be modified in the future.

An employee's position within the salary range will be based on several factors including, but not limited to, relevant education, qualifications, certifications, experience, skills, geographic location, performance, and business or organizational needs.

Elastic believes that employees should have the opportunity to share in the value that we create together for our shareholders. Therefore, in addition to cash compensation, this role is currently eligible to participate in Elastic's stock program. Our total rewards package also includes a company-matched Registered Retirement Savings Plan (RRSP) with dollar-for-dollar matching up to 6% of eligible earnings, along with a range of other benefits offered with a holistic emphasis on employee well-being.

The typical starting salary range for this role is:

$128,300—$203,000 CAD

Additional Information - We Take Care Of Our People

As a distributed company, diversity drives our identity. Whether you’re looking to launch a new career or grow an existing one, Elastic is the type of company where you can balance great work with great life. Your age is only a number. It doesn’t matter if you’re just out of college or your children are; we need you for what you can do.

We strive to have parity of benefits across regions and while regulations differ from place to place, we believe taking care of our people is the right thing to do.

Competitive pay based on the work you do here and not your previous salary
Health coverage for you and your family in many locations
Ability to craft your calendar with flexible locations and schedules for many roles
Generous number of vacation days each year
Increase your impact - We match up to $2000 (or local currency equivalent) for financial donations and service
Up to 40 hours each year to use toward volunteer projects you love
Embracing parenthood with minimum of 16 weeks of parental leave

Different people approach problems differently. We need that. Elastic is an equal opportunity employer and is committed to creating an inclusive culture that celebrates different perspectives, experiences, and backgrounds. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, pregnancy, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, disability status, or any other basis protected by federal, state or local law, ordinance or regulation.

We welcome individuals with disabilities and strive to create an accessible and inclusive experience for all individuals. To request an accommodation during the application or the recruiting process, please email candidate_accessibility@elastic.co. We will reply to your request within 24 business hours of submission.

Applicants have rights under Federal Employment Laws, view posters linked below: Family and Medical Leave Act (FMLA) Poster; Pay Transparency Nondiscrimination Provision Poster; Employee Polygraph Protection Act (EPPA) Poster and Know Your Rights (Poster)

Elasticsearch develops and distributes encryption software and technology that is subject to U.S. export controls and licensing requirements for individuals who are located in or are nationals of the following sanctioned countries and regions: Belarus, Cuba, Iran, North Korea, Russia, Syria, the Crimea Region of Ukraine, the Donetsk People’s Republic (“DNR”), and the Luhansk People’s Republic (“LNR”). If you are located in or are a national of one of the listed countries or regions, an export license may be required as a condition of your employment in this role. Please note that national origin and/or nationality do not affect eligibility for employment with Elastic.

Please see here for our Privacy Statement.

Different people approach problems differently. We need that. Elastic is an equal opportunity/affirmative action employer committed to diversity, equity, and inclusion. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, pregnancy, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, disability status, or any other basis protected by federal, state or local law, ordinance or regulation.

We welcome individuals with disabilities and strive to create an accessible and inclusive experience for all individuals. To request an accommodation during the application or the recruiting process, please email candidate_accessibility@elastic.co We will reply to your request within 24 business hours of submission.

Applicants have rights under Federal Employment Laws, view posters linked below:

Family and Medical Leave Act (FMLA) Poster; Equal Employment Opportunity (EEO) Poster; and Employee Polygraph Protection Act (EPPA) Poster.

Please see here for our Privacy Statement.",[]
DevOps/MLOps Engineer,Thrive Career Wellness Platform ,"Toronto, ON",Remote,"About the job
📍 Remote within Canada | 🕐 Full-Time

💰 Base Salary: $120K–$150K CAD

About Thrive

Thrive Career Wellness Platform is a mission-driven SaaS company helping people take control of their career journeys. We support individuals through meaningful career transitions and empower organizations with tools to deliver impactful outplacement and career wellness services. Our platform is used by public and private sector organizations across Canada and beyond.

About The Role

We’re looking for a skilled DevOps/MLOps Engineer to manage and optimize our AWS cloud infrastructure while supporting the operationalization of machine learning workflows. You’ll play a key role in building scalable systems that drive performance, security, and efficiency—both for our platform and the data-driven features that power it.

What You’ll Be Doing

Cloud Infrastructure Management: Design, implement, and maintain secure, scalable AWS solutions.
CI/CD & Automation: Build and maintain pipelines for infrastructure provisioning and application deployment.
Monitoring & Optimization: Ensure performance and cost-effectiveness through monitoring tools and reporting.
Security: Apply cloud security best practices including IAM, encryption, and secure networking.
ML Ops Enablement: Work closely with AI teams to deploy machine learning models into production.
Containerization: Leverage Docker and Kubernetes for container orchestration.
Cross-Team Collaboration: Partner with developers, data engineers, and stakeholders to support scalable delivery.
Documentation: Keep internal documentation updated and accessible for scaling and onboarding.

What You’ll Bring

3+ years in DevOps or a similar role, ideally with ML Ops experience.
Strong AWS knowledge (EC2, S3, EKS, SageMaker, etc.).
Proficiency in IaC tools (Terraform or CloudFormation).
Experience with CI/CD tools like GitHub Actions or GitLab CI/CD.
Familiarity with Docker, Kubernetes, and scripting languages (Python, Bash).
Knowledge of ML Ops tools (SageMaker, MLflow, Kubeflow).
Experience with monitoring tools (CloudWatch, Prometheus, Grafana).
Clear, collaborative communication style.

Nice-to-Haves

Experience with Databricks or managing data engineering workflows.
Knowledge of serverless architecture and event-driven design.
Familiarity with cloud cost optimization tools.
Security compliance knowledge (e.g., SOC 2, ISO 27001).
Experience working with Ruby on Rails environments.

Why Thrive

At Thrive, we value diversity, autonomy, and collaboration. We’re proud to be an Equal Opportunity Employer and are committed to providing accommodations throughout the hiring process. Applicants must be legally entitled to work in Canada.

Ready to Make an Impact?

Apply now and join a team that’s reshaping the future of career wellness.",[]
"Staff Machine Learning Operations Engineer, AI Sim",SandboxAQ,Canada,Remote,"About the job
About SandboxAQ

SandboxAQ is a high-growth company delivering AI solutions that address some of the world's greatest challenges. The company’s Large Quantitative Models (LQMs) power advances in life sciences, financial services, navigation, cybersecurity, and other sectors.

We are a global team that is tech-focused and includes experts in AI, chemistry, cybersecurity, physics, mathematics, medicine, engineering, and other specialties. The company emerged from Alphabet Inc. as an independent, growth capital-backed company in 2022, funded by leading investors and supported by a braintrust of industry leaders.

At SandboxAQ, we’ve cultivated an environment that encourages creativity, collaboration, and impact. By investing deeply in our people, we’re building a thriving, global workforce poised to tackle the world's epic challenges. Join us to advance your career in pursuit of an inspiring mission, in a community of like-minded people who value entrepreneurialism, ownership, and transformative impact.

About The Role

SandboxAQ is seeking a Staff MLOps engineer to mature our MLOps practices by building out infrastructure and application code, as well as embedding with R&D teams to champion adoption of your tools and gather feedback to improve them. In this role, you’ll be working closely with data engineers, software developers, research scientists, and ML scientists to deliver solutions at the frontier of AI in chemistry and the life sciences. This is a hands-on-keyboard role, however it includes the opportunity to build and lead a team of MLOps engineers for interested candidates.

You’ll bring broad experience with infrastructure for automated training, evaluation, and maintenance of trained models; systems for efficient inference on trained models; and practices for versioning dataset and models. Ideal candidates will bring a blend of experience with highly-automated, stable MLOps pipelines for highly-available systems, and scrappy ad-hoc pipelines for R&D projects. Most importantly, you’ll bring a track record of working in a fast-moving software development team, exploring new technologies, and solving problems across an entire software stack.

What You’ll Do

Mature our MLOps practice by defining processes and building fundamental tooling.
Embed closely with R&D teams to assist in delivering project goals and drive adoption of practices and tooling.
Drive the design and implementation of complex, security-sensitive data processing and storage systems with complex tenancy and data isolation requirements.
Collaborate closely with the product team and internal stakeholders in all phases of software development to validate the solutions you propose and implement.
In collaboration with the rest of the engineering team, build and manage infrastructure for SandboxAQ’s simulation and data platform.
Review code and participate in design and architectural discussions.

About You

7+ years of experience with MLOps fundamentals:
Automated training, evaluation, and retraining loops
Dataset and model versioning tools, Weights & Biases preferred
Systems for serving inference
Build end-to-end ML pipeline using industry-standard tools.
Deep experience with at least one major cloud provider. GCP preferred.
Experience with managing complex data governance requirements.
Familiarity with MLOps architectures and best practices for LLMs and Agentic systems.
3+ years of experience with infrastructure as code management of public cloud providers. Familiar with terraform. GCP preferred.
Familiarity with building and maintaining CI/CD pipelines for ML systems.
3+ years of experience with Python, with strong knowledge of software design principles.
Familiarity with building data pipelines or data processing systems at scale, including orchestration tools like Airflow.
Excellent communication and collaboration skills, with the ability to effectively influence a cross-functional team.

Nice to have

Domain experience in advanced materials, drug discovery, cheminformatics, or other areas of chemistry or biology, especially experience with AI systems applied to these domains.
Experience with AI applications in knowledge graphs.
Experience profiling and optimizing GPU usage in MLOps applications.

The US base salary range for this full-time position is expected to be $225k - $295k per year. Our salary ranges are determined by role and level. Within the range, individual pay is determined by factors including job-related skills, experience, and relevant education or training. This role may be eligible for annual discretionary bonuses and equity.

SandboxAQ welcomes all.

We are committed to creating an inclusive culture where we have zero tolerance for discrimination. We invest in our employees' personal and professional growth. Once you work with us, you can’t go back to normalcy because great breakthroughs come from great teams and we are the best in AI and quantum technology.

We offer competitive salaries, stock options depending on employment type, generous learning opportunities, medical/dental/vision, family planning/fertility, PTO (summer and winter breaks), financial wellness resources, 401(k) plans, and more.

Equal Employment Opportunity: All qualified applicants will receive consideration regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status.

Accommodations: We provide reasonable accommodations for individuals with disabilities in job application procedures for open roles. If you need such an accommodation, please let a member of our Recruiting team know.",[]
"Principle Machine Learning Ops Developer, AI/ML Platform",Autodesk,Canada,Remote,"About the job
Job Requisition ID #

25WD89028

Principal Machine Learning Operations Developer 

Job Description

Position Overview

We are looking for an experienced Principal Software Engineer to join our platform team focusing on AI/ML Platform (AMP). This team builds and maintains central components to fast track the development new ML/AI models such as model development studio, feature store, model serving, model observability.   Ideal candidate would have background in MLOps, Data engineering, DevOps with the experience of building high scale deployment architectures, observability. As an important contributor to our engineering team, you will help shape the future of our AI/ML capabilities, delivering solutions that inspire value for our organization. You will report to a manager.

Responsibilities

System design: You will design, implement and manage software systems for the AI/ML Platform, orchestrating the full ML development lifecycle for the partner teams. 
Mentoring: Spreading your knowledge, sharing best practices, doing design reviews to step up the expertise at the team level. 
Multi-cloud architecture: Define components which leverages strengths from multiple cloud platforms (e.g., AWS, Azure) to optimize performance, cost, and scalability 
AI/ML observability: You will build systems for monitoring performance of AI/ML models and finding insights on the underlying data such as drift detection, data fairness/bias, anomalies 
ML Solution Deployment: You will develop tools for building and deploying ML artifacts in production environments, facilitating a smooth transition from development to deployment 
Big Data Management: Automate and orchestrate tasks related to managing big data transformation and processing, building large-scale data stores for ML artifacts 
Scalable Services: Design and implement low-latency, scalable prediction, and inference services to support the diverse needs of our users 
Cross-Functional Collaboration: Collaborate across diverse teams, including machine learning researchers, developers, product managers, software architects, and operations, fostering a collaborative and cohesive work environment 
End-to-end ownership: You will take the end-to-end ownership of the components and work with other engineers in the team including design, architecture, implementation, rollout, onboarding support to partner teams, production on-call support, testing/verification, investigations etc. 

Minimum Qualifications

Educational Background: Bachelors degree in Computer Science or equivalent practical experience 
Experience: Over 8 years of experience in software development and engineering, delivering production systems and services 
Prior experience of working with MLOps team at the intersection of the expertise across ML model deployments, DevOps, data engineering. 
Hands-on skills: Ability to fluently translate the design into high quality code in golang, python, Java. 
Knowledge of DevOps practices, containerization, orchestration tools such as CI/CD, Terraform, Docker, Kubernetes, Gitops 
Demonstrated knowledge of distributed data processing frameworks, orchestrators, and data lake architectures using technologies such as Spark, Airflow, iceberg/ parquet formats. 
Prior collaborations with Data science teams to deploy their models, setting up ML observability for inference level monitoring. 
Exposure for building RAG based applications by collaborating with other product teams, Data scientists/AI engineers. 
Demonstrated creative problem-solving skills with the ability to break down problems into manageable components 
Knowledge of Amazon AWS and/or Azure cloud for solutioning large scale application deployments. 
Excellent communication and collaboration skills, fostering teamwork and effective information exchange 

Preferred Qualifications

Experience of integrating with third party vendors 
Experience in latency optimization with the ability to diagnose, tune, and enhance the efficiency of serving systems 
Familiarity with tools and frameworks for monitoring and managing the performance of AI/ML models in production (e.g., MLflow, Kubeflow, TensorBoard) 
Familiarity with distributed model training/inference pipelines using (KubeRay or equivalent) 
Exposure to leveraging GPU computing for AI/ML workloads, including experience with CUDA, OpenCL, or other GPU programming tools, to significantly enhance model training and inference performance 
Exposure to ML libraries such as PyTorch, TensorFlow, XGBoost, Pandas, and ScikitLearn 

Learn More

About Autodesk

Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.

We take great pride in our culture here at Autodesk – our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers.

When you’re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us!

Salary transparency

Salary is one part of Autodesk’s competitive compensation package. For Canada-BC based roles, we expect a starting base salary between $141,600 and $194,700. Offers are based on the candidate’s experience and geographic location, and may exceed this range. In addition to base salaries, we also have a significant emphasis on annual cash bonuses, commissions for sales roles, stock grants, and a comprehensive benefits package.

Diversity & Belonging

We take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging

Are you an existing contractor or consultant with Autodesk? 

Please search for open jobs and apply internally (not on this external site).",[]
Machine Learning Engineer,Xsolla,"Montreal, QC",Hybrid,"About the job
About Us

At Xsolla, we believe that great games begin as ideas, driven by the curiosity, dedication, and grit of creators around the world. Our mission is to empower these visionaries by providing the support and resources they need to bring their games to life. We are committed to leveling the playing field, ensuring that every creator has the opportunity to share their passion with the world.

Headquartered in Los Angeles, with offices in Berlin, Seoul, and beyond, we partner with industry leaders like Valve, Twitch, and Ubisoft to clear the paths for innovation in gaming. Our global reach spans over 200 geographies, offering more than 700 payment methods in 130+ currencies.

Longevity Opportunity Vision Enjoy the game!

About You

We are looking for a Machine Learning Engineer who is technically expert, highly collaborative, and innovation-driven to join our AI and Data Science team. The best candidate will be someone who thrives in a fast-paced, highly collaborative, and exceptionally dynamic setting and is excited to build, deploy, and optimize machine learning models that deliver real-world impact at scale.

Strong ML engineering skills, cloud deployment experience, and MLOps proficiency are essential, along with experience in managing model workflows from development to production. The ability to mentor junior engineers, collaborate with cross-functional teams, and lead complex projects to successful delivery will be key to your success in this role.

If you’re passionate about developing scalable, cutting-edge machine learning systems and love building high-performance models that drive innovation, we would love to hear from you!

Responsibilities

Leads and supports multiple Machine Learning projects, ensuring alignment with business objectives and data needs.
Oversees the Kanban process for managing ML model development, deployment, and maintenance.
Engages in technical discussions both within the company and with external data partners, fostering collaboration and knowledge sharing.
Drives the design and architecture of machine learning solutions by deeply understanding data usage and identifying opportunities to integrate new data sources.
Implements emerging technologies and methodologies in machine learning, ensuring state-of-the-art solutions and continuous innovation.
Mentors and guides junior ML engineers, promoting best practices, scalability, and efficiency in model development.
Collaborates closely with data engineers and scientists to enhance ML workflows, ensuring models are reliable and production-ready.


Qualifications & Skills

Strong proficiency in ML frameworks/libraries such as TensorFlow, PyTorch, Scikit-learn, and XGBoost.
Experience with cloud platforms (AWS, GCP, Azure), and deploying ML models using SageMaker, Vertex AI, or Azure ML.
Familiarity with MLOps practices, including model versioning, CI/CD pipelines (e.g., MLflow, Kubeflow, Airflow), and production monitoring.
Expertise in data preprocessing and feature engineering using tools such as Pandas, NumPy, and Apache Spark.
Strong programming skills in Python (preferred) or Scala.
Experience with containerization tools like Docker and Kubernetes.
Understanding of distributed computing and parallel processing frameworks (e.g., Ray, Dask) for scalable ML workloads.
Experience deploying ML models to production with a focus on inference latency, scalability, and robustness.
Experience in data pipelines and analytics for video-game development (Preferred).
Experience in the advertising industry (Preferred).
Experience in online businesses where transactions happen without human intervention (Preferred).


$100,000 - $140,000 a year

Equal Employment Opportunity Statement:

Xsolla is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based on race, color, religion, sex, national origin, age, disability, sexual orientation, gender identity, or any other characteristic protected by law.

We consider qualified applicants with criminal histories in accordance with the Fair Chance Act.

Criminal History Consideration:

For the Machine Learning Engineer, we will conduct a background check that may include the following:

Criminal history check

Employment verification

Education verification

Relevance to Job Responsibilities:

The background check is relevant to this position because of the following role responsibilities:

Accessing confidential company data

Ensuring compliance with regulatory requirements

Handling sensitive financial information/managing budgets/accessing funds

Rights Under the Fair Chance Act:

Applicants are encouraged to inquire about their rights under the Fair Chance Act. If you have questions regarding our hiring practices, please contact careers@xsolla.com .

Benefits:

We are passionate about fostering a supportive environment for our team, so we prioritize the physical, mental, and emotional well-being of our employees and their families through a comprehensive Benefits Program. This includes 100% company-paid medical, dental, and vision plans, unlimited Flexible Time Off, and a personalized career roadmap for each employee. By investing in professional development through training and educational opportunities, we ensure that our team thrives both personally and professionally. Together, we’re not just building a business; we’re cultivating a community that values creativity, collaboration, and the transformative power of play.

By submitting the following job application form, you consent to Xsolla processing your data for career-related inquiries and potential employment opportunities. We process your data in accordance with this  Xsolla Privacy Notice for Job Applicants . Please direct any inquiries regarding your data privacy to careers@xsolla.com.",[]
Senior ML Engineer,Quandri,"Vancouver, BC",Hybrid,"About the job
We’re Quandri, our mission is to unlock the world’s insurance data so brokerages and agencies can best serve their clients. Our Renewal Intelligence Platform is designed to help brokerages save time, increase profitability, and drive better outcomes for their staff, clients, and business. 

We saw 3x ARR growth last year and have plans to continue to grow both revenue and our team this year. Named one of LinkedIn’s Top Canadian Startups in 2024, we have already made a big impact on the insurance industry. However, what matters most is making our customer’s lives better one renewal at a time. We want you to be a critical part of that journey! We’re a hybrid company, with ⅔ of our team in Vancouver and the rest distributed. For those in Vancouver, we have an office in Gastown that we expect people to be at three days a week. We understand both the advantages of some flexibility around personal lives, and the positive interpersonal effects of in-person collaboration.

Running a profitable personal lines book of business is harder than ever for insurance brokerages. Market conditions, rising costs, talent shortages, and staffing constraints are just some of the challenges that hinder profit margins, scalability, and exceptional client service. Trusted by 5 of Canada’s top 10 brokerages, Quandri is transforming the renewal process with AI-driven automation, enabling proactive workflows and delivering data-driven insights.

Today’s renewal process is often reactive, with brokers focusing on clients who request help rather than adopting a proactive, data-driven approach. Quandri is revolutionizing renewals by offering a platform that uses AI and automation to streamline operations. This allows brokerages to retain more business, enhance client and staff experiences, reduce E&O risk, and boost sales through upselling and cross-selling.

Are you looking to make an impact in your next role? How about transforming an entire industry? At Quandri, we’re unlocking new frontiers in insurance. To do that, we model our culture as a crew of interstellar astronauts. As Quandronauts, we’re committed to building a company that is diverse and multi-faceted. We’ve raised venture capital from top US and Canadian investors to help us achieve our mission, and are now scaling to achieve this.

About the Role:

We're seeking a Machine Learning Engineer to bridge the gap between our data products, data science insights and production systems. You'll be responsible for taking ML models from concept to production, building robust MLOps infrastructure, and ensuring our machine learning systems operate reliably at scale. This role focuses on the engineering aspects of ML design, deployment, automation, monitoring, and infrastructure.

What you will do:

Design and implement end-to-end ML pipelines from data ingestion to model serving
Build automated model training, validation, and deployment workflows using CI/CD best practices
Develop and maintain MLOps infrastructure for model versioning, experiment tracking, and deployment
Create robust monitoring and alerting systems for model performance, data drift, and system health
Optimize model inference performance and cost for production workloads
Collaborate with our Data Engineers to design and implement feature stores and feature pipelines
Develop automated data quality checks and validation frameworks for ML pipelines
Build scalable feature engineering workflows that support both batch and real-time inference
Implement data versioning and lineage tracking for reproducible ML workflows
Partner with Software Data Scientists to productionize research models and experiments
Implement frameworks for model evaluation and gradual rollouts
Design automated retraining pipelines and model refresh strategies
Establish best practices for model governance, documentation, and compliance
Work closely with Software Engineers to integrate ML capabilities into existing applications
Contribute to architectural decisions for scalable, maintainable ML systems
Participate in code reviews, documentation, and knowledge sharing across teams
Mentor junior engineers on ML engineering best practices

The right person for this role will have:

3+ years of experience in machine learning engineering, MLOps, or related fields
Strong proficiency in Python for ML development and automation
Solid SQL skills for data manipulation and analysis
Hands-on experience with AWS or other cloud platforms (Azure, or GCP) and their ML services
Experience with containerization (Docker) and orchestration (Kubernetes) for ML workloads
Proficiency with ML frameworks (scikit-learn, TensorFlow, PyTorch) and MLOps tools
Knowledge of CI/CD pipelines and infrastructure-as-code principles
Databricks experience is a plus
Experience with feature engineering at scale and feature store implementations
Understanding of model monitoring, observability, and production ML challenges
Knowledge of data quality frameworks and automated testing for ML systems
Familiarity with distributed computing frameworks (Databricks or Sagemaker) for large-scale ML
Experience with experiment tracking and model versioning tools (MLflow, Weights & Biases, etc.)

Bonus points if you have:

Master's or PhD in Computer Science, Engineering, Statistics, or related quantitative field Experience with real-time ML inference and streaming data pipelines
Knowledge of AutoML platforms and automated hyperparameter tuning
Familiarity with model compression, quantization, and edge deployment Experience with multi-cloud or hybrid cloud ML architectures
Contributions to open-source ML tools or platforms

Our guiding principles:

Customers at the core. We put the customer at the center of all we do. At a basic level, we believe business success comes down to talking to customers and building something they want. We don’t listen to customers and just take what they say blindly, but we think critically about it and build what they need. Customers are the core of everything we do, and our business exists to serve them. We prioritize their needs over all else within the company.
Move with urgency. There are times when we need to move slowly and deliberately, but we default to acting fast and with urgency. We slow down when necessary, but this should be a deliberate choice. Businesses become more lethargic as they grow, this principle is designed to fight this fact.
Be curious. We understand the world by being curious and asking why. We aren’t satisfied with surface level understanding, and seek a deeper understanding of why things are the way they are. Don’t take someone’s word for it or the answer “because that’s how we do it.” Understand why and dig deep.
Excellence in execution. We know that what separates good from great is a high level of execution. We commit ourselves to excellence in everything that we do, from delivering an amazing product to writing a great email.
Act like an owner.  We’re all owners of the business and act like it. We follow through on commitments, own our results and think long-term.
Fight for simplicity. The law of increasing functional information states that systems evolve to become more complex over time. At Quandri, we believe there is sophistication in simplicity; as such, we intentionally fight for streamlined solutions and are committed to the uncomplicated.

Compensation and benefits:

Compensation range of $145k to $200K annually
Employee stock options based on experience level
Comprehensive health benefits, including Lifestyle Spending Account
4 weeks of paid vacation per year
Work anywhere in the world for 60 days of the year

Application process:
Please submit your resume highlighting relevant experience and include a cover letter explaining your interest in the specific role
Provide links to relevant projects, GitHub repositories, or publications
Be prepared to discuss technical projects and problem-solving approaches in interviews

Quandri is dedicated to fostering a diverse and inclusive workplace. As an equal opportunity employer, Quandri adheres to Canadian labour laws and does not engage in discrimination based on race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or any other status protected under Canadian law.

Don’t let imposter syndrome stop you from applying. Great people sometimes don’t have the “right” experience. If you think that you’ll be amazing at this role then we encourage you to apply.",[]
Tech Lead Platform Engineer - AI & ML Ops,Enable,"Toronto, ON",Remote,"About the job
Managing pricing and rebates shouldn’t be a hassle. Enable’s intelligent platform is built for the speed of today’s market, eliminating disconnects between pricing strategy and rebate execution. We help companies to increase profitability and simplify the complex with accurate, AI-powered insights, real-time performance monitoring, agreement optimization, and simplified rebate management.

After securing $291M in Series A-D funding and acquiring Flintfox in 2025, Enable is positioned for continued, significant growth. Since the launch of our flagship product in 2016, we have been rapidly scaling our client base, product offerings, and built a team of top-tier professionals committed to reshaping the industry.

Want a glimpse into life at Enable? Visit our  Life at Enable  page to learn how you can be part of our journey.

Job Summary

We are seeking a Tech Lead Platform Engineer – AI & MLOps to drive the evolution of Enable’s cloud-native platform, ensuring scalability, reliability, and efficiency across all aspects of our SaaS infrastructure. This role will focus on architecting and optimizing our platform for high-performance distributed systems while also enabling machine learning (MLOps) capabilities for AI-driven applications.

As a key technical leader, you will collaborate across teams to develop best-in-class platform solutions that support product engineering, data engineering, and AI/ML teams. You will establish best practices, automate workflows, and ensure that Enable’s infrastructure is secure, resilient, and future-proof.

Key Responsibilities - SaaS Platform Engineering

Design, build, and optimize a cloud-native, multi-tenant SaaS platform that scales with Enable’s rapid growth.
Develop and maintain core infrastructure components, including compute, networking, observability, and CI/CD pipelines.
Implement best practices for cloud cost optimization, security, and system reliability.
Enhance API gateways, identity management, and service orchestration for seamless integration across services.


Key Responsibilities - MLOps & AI Infrastructure

Architect and manage scalable AI/ML pipelines for model training, deployment, and monitoring.
Develop and maintain MLOps workflows using tools like Kubeflow and MLflow.
Optimize ML model inference for real-time and batch processing in a production SaaS environment.
Collaborate with data scientists and ML engineers to streamline model lifecycle management.


Key Responsibilities - Automation, Observability & Performance

Implement and refine Infrastructure-as-Code (IaC) practices using Terraform or Pulumi.
Build self-healing, automated monitoring solutions for system health, application performance, and security.
Improve CI/CD processes to support high-velocity engineering teams with minimal operational overhead.
Establish robust logging, tracing, and metrics collection for visibility into SaaS application performance.


Key Responsibilities - Cross-Functional Collaboration & Leadership

Work closely with engineering teams to ensure platform capabilities support product innovation and reliability.
Partner with security teams to ensure compliance with SaaS security and compliance standards and best practices.
Implement monitoring, logging, and alerting solutions to track model and system performance, ensuring compliance with best practices.
Define and document platform engineering best practices to elevate team-wide capabilities.
Mentor junior and mid-level engineers, fostering a culture of technical excellence and continuous learning.


Qualifications

8+ years of experience in platform, DevOps, or cloud engineering, with at least 3+ years in SaaS environments.
Bachelor’s degree in Computer Science, Engineering, or a related field.
Expertise in architecting, deploying, and managing cloud-native applications on AWS, GCP, or Azure.
Strong experience with Kubernetes, serverless computing, and container orchestration.
Proficiency in modern Infrastructure-as-Code (Terraform, Pulumi) and CI/CD tools (GitHub Actions, ArgoCD).
Experience in distributed systems, service mesh technologies (Istio, Linkerd), and event-driven architectures.
Hands-on experience with databases (SQL, NoSQL, vector DBs), ensuring high availability and performance.
Deep understanding of SaaS security principles, identity management, and compliance frameworks (SOC 2, ISO 27001).
Strong programming and automation skills in Python, SQL, and Bash.
Strong experience with microservices architecture and API development.
Familiarity with MLOps frameworks and ML model operationalization.


Preferred Qualifications

Experience building and maintaining large-scale data processing pipelines.
Expertise in observability tools such as Prometheus, Grafana, OpenTelemetry, or ELK stack.
Familiarity with real-time data processing and messaging platforms (Kafka, Pub/Sub, Kinesis).
Background in high-availability, globally distributed architectures.
Work experience in cutting-edge AI and MLOps challenges at the intersection of ML, engineering, and cloud infrastructure.
Certifications in cloud computing (e.g., AWS Certified DevOps Engineer, Azure DevOps Engineer).
Contributions to open-source DevOps, platform, or MLOps tooling.


Job Title

Once hired this person will have the job title Tech Lead II, Platform Engineer - AI & ML Ops


Total Rewards

At Enable, we’re committed to your professional development and growth. Starting pay is determined by factors like location, skills, experience, market conditions, and internal parity.

Benefits

Salary/TCC is just one component of Enable’s total rewards package. Enable is committed to investing in the holistic health and wellbeing of all Enablees and their families. Our benefits and perks include, but are not limited to:

 Paid Time Off:  Take the time you need to relax and recharge

 Wellness Benefit:  Quarterly incentive dedicated to improving your health and well-being

 Comprehensive Insurance:  Health and life coverage for you and your family

 Retirement Plan:  Build your future with our retirement savings plan

 Lucrative Bonus Plan:  Enjoy a rewarding bonus structure subject to company or individual performance

 Equity Program:  Benefit from our equity program with additional options tied to tenure and performance

 Career Growth:  Explore new opportunities with our internal mobility program

 Additional Perks: 

Free Food: Complimentary meals, snacks, and drinks on-site in our global offices 

Training: Access a range of workshops and courses designed to boost your professional growth and take your career to new heights 

Pets: Bring your pets to our welcoming, pet-friendly offices

According to LinkedIn's Gender Insights Report, women apply for 20% fewer jobs than men, despite similar job search behaviors. At Enable, we’re committed to closing this gap by encouraging women and underrepresented groups to apply, even if they don’t meet all qualifications.

Enable is an equal opportunity employer, fostering an inclusive, accessible workplace that values diversity. We provide fair, discrimination-free employment, ensuring a harassment-free environment with equitable treatment.

We welcome applications from all backgrounds. If you need reasonable adjustments during recruitment or in the role, please let us know.",[]
ML Engineering - ML Ops,Workday,"Victoria, BC",Hybrid,"About the job
Your work days are brighter here.

At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.

At Workday, we value our candidates’ privacy and data security. Workday will never ask candidates to apply to jobs through websites that are not Workday Careers.

Please be aware of sites that may ask for you to input your data in connection with a job posting that appears to be from Workday but is not.

In addition, Workday will never ask candidates to pay a recruiting fee, or pay for consulting or coaching services, in order to apply for a job at Workday.

About The Team

Workday was founded on a vision to revolutionize enterprise software, built on a culture that puts people first. Our success is driven by a collaborative, employee-centric environment, where Workmates thrive and contribute to a greater purpose. We prioritize our people, communities, and the planet while maintaining profitability. Here, you’re encouraged to be yourself, embrace your energy and passion, and help shape the future. Join us in creating a brighter Workday for all!

Come join the Workday Search/Assistant team! We are part of the Employee Experience organization that enables employers to better engage and support their people while making work more personal and productive.

Workday is looking for a hardworking Machine Learning Operations engineer to contribute to the strategic mission of reaching workers where they are at. You will join an energetic, open minded and supportive group of engineers to redefine how workers engage with Enterprise applications. If you have a willingness to explore the unknown, be a technological pioneer and have passion around improving customer experiences then we want to hear from you!

About The Role

As a machine learning engineer passionate about ML Ops, you will

Implement MLOps tools, frameworks, and platforms to support ML development, deployment, and governance
Create and maintain a repeatable and reusable ML workflow for model training, evaluation, deployment, and maintenance
Improve tracking and monitoring of models, experiments, artifacts, and data
Engage with data engineers and data scientists in feature engineering efforts
Diagnose and resolve ML workflow and production issues quickly

We will challenge you to apply your best creative thinking, analysis, problem-solving, and technical abilities to make an impact on thousands of enterprises and millions of people.

About You

Highly self-motivated, always looking to take on work and get great pleasure from delivering production scale machine learning solutions to customers
A collaborative teammate who uses positive leadership to coordinate and deliver results across teams
A fast learner, detail oriented, decisive, and enjoys a fast-paced work environment
Flexible, reliable, outgoing and has a positive work attitude.

Basic Qualifications

3+ years understanding of Python in both production and ETL settings
2+ years of building Data or MLOps pipelines using Python, Airflow, Databricks, or other similar cloud native services
2+ years experience on AWS, Vertex AI, and Kubernetes 
2+ years experience in operationalization of Data Science projects using at least one of the popular frameworks or platforms (e.g. Airflow, Kubeflow, AWS Sagemaker, Google AI Platform) - Kubeflow in particular is a plus
1+ years experience building both data / ETL pipelines as well as model training infrastructure, and working with GPUs
1+ years Experience managing and supporting Docker, Kubernetes, Spark, CI/CD, Git-Ops
1+ years Experience with data versioning, ML model management, lifecycle, and reproducibility

Other Qualifications

Experience with ML frameworks such as PyTorch, Keras, Transformers, SKLearn
Experience with fine-tuning NLP models and with HuggingFace
Experience with AWS services especially EKS 
1+ years with MLOps tools like TFX, MLFlow, Kubeflow, Apache Spark, etc.
B.S. in a relevant field - (E.g. Computer Science, Mathematics, Engineering). M.S. or Ph.D are nice, but not required

Workday Pay Transparency Statement 

The annualized base salary ranges for the primary location and any additional locations are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please click here.

Primary Location: CAN.BC.Vancouver

Primary CAN Base Pay Range: $122,400 - $183,600 CAD

Additional CAN Location(s) Base Pay Range: $122,400 - $183,600 CAD

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.

Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.

Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.

Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!

,",[]
ML Engineering - ML Ops,Workday,"Vancouver, BC",Hybrid,"About the job
Your work days are brighter here.

At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.

At Workday, we value our candidates’ privacy and data security. Workday will never ask candidates to apply to jobs through websites that are not Workday Careers.

Please be aware of sites that may ask for you to input your data in connection with a job posting that appears to be from Workday but is not.

In addition, Workday will never ask candidates to pay a recruiting fee, or pay for consulting or coaching services, in order to apply for a job at Workday.

About The Team

Workday was founded on a vision to revolutionize enterprise software, built on a culture that puts people first. Our success is driven by a collaborative, employee-centric environment, where Workmates thrive and contribute to a greater purpose. We prioritize our people, communities, and the planet while maintaining profitability. Here, you’re encouraged to be yourself, embrace your energy and passion, and help shape the future. Join us in creating a brighter Workday for all!

Come join the Workday Search/Assistant team! We are part of the Employee Experience organization that enables employers to better engage and support their people while making work more personal and productive.

Workday is looking for a hardworking Machine Learning Operations engineer to contribute to the strategic mission of reaching workers where they are at. You will join an energetic, open minded and supportive group of engineers to redefine how workers engage with Enterprise applications. If you have a willingness to explore the unknown, be a technological pioneer and have passion around improving customer experiences then we want to hear from you!

About The Role

As a machine learning engineer passionate about ML Ops, you will

Implement MLOps tools, frameworks, and platforms to support ML development, deployment, and governance
Create and maintain a repeatable and reusable ML workflow for model training, evaluation, deployment, and maintenance
Improve tracking and monitoring of models, experiments, artifacts, and data
Engage with data engineers and data scientists in feature engineering efforts
Diagnose and resolve ML workflow and production issues quickly

We will challenge you to apply your best creative thinking, analysis, problem-solving, and technical abilities to make an impact on thousands of enterprises and millions of people.

About You

Highly self-motivated, always looking to take on work and get great pleasure from delivering production scale machine learning solutions to customers
A collaborative teammate who uses positive leadership to coordinate and deliver results across teams
A fast learner, detail oriented, decisive, and enjoys a fast-paced work environment
Flexible, reliable, outgoing and has a positive work attitude.

Basic Qualifications

3+ years understanding of Python in both production and ETL settings
2+ years of building Data or MLOps pipelines using Python, Airflow, Databricks, or other similar cloud native services
2+ years experience on AWS, Vertex AI, and Kubernetes 
2+ years experience in operationalization of Data Science projects using at least one of the popular frameworks or platforms (e.g. Airflow, Kubeflow, AWS Sagemaker, Google AI Platform) - Kubeflow in particular is a plus
1+ years experience building both data / ETL pipelines as well as model training infrastructure, and working with GPUs
1+ years Experience managing and supporting Docker, Kubernetes, Spark, CI/CD, Git-Ops
1+ years Experience with data versioning, ML model management, lifecycle, and reproducibility

Other Qualifications

Experience with ML frameworks such as PyTorch, Keras, Transformers, SKLearn
Experience with fine-tuning NLP models and with HuggingFace
Experience with AWS services especially EKS 
1+ years with MLOps tools like TFX, MLFlow, Kubeflow, Apache Spark, etc.
B.S. in a relevant field - (E.g. Computer Science, Mathematics, Engineering). M.S. or Ph.D are nice, but not required

Workday Pay Transparency Statement 

The annualized base salary ranges for the primary location and any additional locations are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please click here.

Primary Location: CAN.BC.Vancouver

Primary CAN Base Pay Range: $122,400 - $183,600 CAD

Additional CAN Location(s) Base Pay Range: $122,400 - $183,600 CAD

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.

Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.

Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.

Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!

,",[]
Senior ML Engineer,Loblaw Companies Limited,,,"About the job
L’utilisation du masculin à pour but d’alléger le texte

Venez faire votre différence dans les communautés à travers le Canada, où l'authenticité, la confiance et l'établissement de liens sont valorisés - alors que nous façonnons l'avenir du commerce de détail au Canada, ensemble. Notre position unique en tant que l'un des plus grands employeurs du pays, celle associée à notre engagement à avoir un impact positif sur la vie de tous les Canadiens, viens offrir à nos collègues une gamme d'opportunités et d'expériences pour aider les Canadiens à Vivre Bien, Vivre Pleinement.

Chez Les Compagnies Loblaw Limitée, nous réussissons grâce à la collaboration, à l'engagement et nous plaçons la barre haute pour nous-mêmes et ceux qui nous entourent. Que vous débutiez votre carrière, que vous réintégriez le marché du travail ou que vous recherchiez un nouvel emploi, votre place est avec nous.

Senior ML Engineer, Brampton, ON

Loblaw Technology and Analytics is looking for an experienced, dedicated Senior ML Engineer to join our fast-growing team of Data Scientists, Engineers, Front-End Developers and Designers to build and enhance Loblaw's price optimization platform.

In addition to knowledge of cutting-edge machine learning models and techniques, you will bring experience in cloud-based development, engineering best practices and end-to-end product development. This includes the design and implementation of AI/ML algorithms, data pipelines, and ML infrastructure. You will assist teams of Data Scientists, ML Engineers, and Data Engineers in collaboration with an accomplished team of Product Managers and Designers to implement ML/AI solutions at scale. Our price optimization platform is critical to Loblaw’s long-term strategy, directly impacting revenue and customer satisfaction. As a Senior ML Engineer, you’ll play a key role in driving its evolution.

We are passionate about what we do and support each other’s growth! You will learn and grow with the team and will have the opportunity to work on a diverse set of challenges as you shape your career.

What You’ll Do: 

Provide architectural guidance and best practices to support internally built ML/AI applications (including feature enhancements and new microservices) and their integration with 3rd-party solutions across the teams’ project portfolio.
Be a strong individual contributor who can demonstrate the feasibility of novel ML approaches and estimate business value at scale.
Develop and execute ML Ops strategies to streamline the deployment, monitoring, and maintenance of machine learning models on Google Cloud Platform (GCP).
Optimize ML processes to enhance scalability, efficiency, and cost-effectiveness of machine learning solutions in production.
Collaborate with cross-functional teams (data scientists, engineers, project management, and business stakeholders) to deliver enhancements to existing functionalities and create innovative new features.
Identify reoccurring use cases and drive a strategy to create assets and infrastructure that can be leveraged across the organization.
Develop a highly engaged team by being an inclusive coach, mentor, and role model for all team members to help grow and promote our diverse talent pool.

Does This Sound Like You? 

5+ years of industry experience in the development of large-scale production systems for machine learning, with a strong preference for experience defining technical strategy and leading junior engineers.
Advanced proficiency with Data Science languages like Python, SQL, and their relevant libraries and frameworks.
Strong experience building end-to-end applications in the cloud (e.g. GCP) and making appropriate architectural choices. Practical experience with ML Ops and DevOps best practices.
Experience packaging and deploying applications as APIs using containerization technologies such as Docker and Kubernetes.
Strong interpersonal skills including ability to work in a multi-functional environment and a keen ability to learn new tools, concepts, and subject matter.
Experience in software engineering best practices (e.g. object-oriented programming, automated testing, writing ‘clean code’).
Experience working with Git Workflows, Jira, and Confluence; especially in the context of Agile product development.
A Master’s or Ph.D. degree in a quantitative field (e.g Computer Science, Engineering, Mathematics, Physics, etc.) is preferred.

Notre engagement envers la durabilité et l'impact social est un élément essentiel de notre façon de faire des affaires. Nous concentrons notre attention sur les domaines où nous pouvons avoir le plus grand impact. Notre approche de la durabilité et de l'impact social repose sur trois piliers - l'environnement, l'approvisionnement et la communauté. Nous recherchons constamment des moyens de faire preuve de leadership dans ces domaines importants. Nos valeurs ÊTRE – Engagement, Tient à coeur, Respect et Excellence – guident toutes nos prises de décision et prennent vie à travers notre culture bleue. Nous offrons à nos collègues des carrières progressives, une formation complète, de la flexibilité ainsi que les nombreux avantages compétitifs - voici quelques-unes des nombreuses raisons pour lesquelles nous sommes classés au palmarès des meilleurs employeurs du Canada, au palmarès des meilleurs employeurs pour la diversité au Canada, au palmarès des employeurs les plus verts au Canada et au palmarès des meilleurs employeurs pour les jeunes au Canada.

Si vous ne savez pas si votre expérience correspond à toutes les exigences ci-dessus, nous vous encourageons à postuler quand même. Nous recherchons des perspectives de candidatures variées, qui incluent des expériences diverses que nous pouvons ajouter à notre équipe.

Nous nous concentrons depuis longtemps sur la diversité, l'équité et l'inclusion, car nous savons que cela fera de notre entreprise un meilleur lieu de travail et de magasinage. Nous nous engageons à créer des environnements accessibles pour nos collègues, candidats et clients. Les demandes d'aménagement en raison d'un handicap (qui peut être visible ou pas, temporaire ou permanent) peuvent être faites à n'importe quel stade de la demande et de l'emploi. Nous encourageons les candidats à faire connaître leurs besoins en matière d'accommodation afin que nous puissions offrir des opportunités équitables.

Veuillez noter:

Les candidats âgés de 18 ans ou plus doivent effectuer une vérification des antécédents criminels. Les détails seront fournis lors du processus d’embauche.

#FR

#SS #DISTRC #ON",[]
Machine Learning Engineer,Bree,"Toronto, ON",Hybrid,"About the job
About Bree

Bree is a consumer finance platform that brings better, faster, and cheaper financial services to over half the Canadian population who live paycheck to paycheck. We operate in a huge, but overlooked market in a country with the least amount of financial technology innovation among the developed world. Our first act is becoming the cheapest and best provider of short-term credit to the 20 million people in Canada who live paycheck to paycheck.

More than 400,000 Canadians have already signed up with Bree and we believe we are just scratching the surface. We are in an exciting place where we have product market fit, explosive growth, and a clear path to becoming one of the most important FinTechs in Canada.

We are at 8-figures of annualized revenue, growing double-digit monthly, profitable, and have had 0 voluntary employee churn. We were part of Y Combinator in 2021 and raised a $2M seed round shortly after.

About The Role

We’re looking for a Machine Learning Engineer to build and scale high-impact, world-class ML systems. You’re passionate about deploying AI solutions, optimizing performance, and driving measurable results. Your work will power critical decisions and shape the future of our technology.

What You'll Do

Design, develop, and deploy end-to-end machine learning pipelines, ensuring efficiency in training, validation, and inference.
Implement MLOps best practices, including CI/CD for ML models, model versioning, monitoring, and retraining strategies.
Optimize ML models using feature engineering, hyperparameter tuning, and scalable inference techniques.
Work with structured and unstructured data, leveraging Pandas, NumPy, and SQL for efficient data manipulation.
Apply machine learning design patterns to build modular, reusable, and production-ready models.
Collaborate with data engineers to develop high-performance data pipelines for training and inference.
Deploy and manage models on cloud platforms (AWS, GCP, Azure) with containerization and orchestration tools like Docker and Kubernetes.
Maintain model performance by implementing continuous monitoring, bias detection, and explainability techniques.

What You'll Need

Proficiency in Python and familiarity with ML libraries like Scikit-learn, LightGBM, and PyTorch.
Strong understanding of machine learning algorithms, including supervised and unsupervised learning techniques.
Experience with MLOps tools such as MLflow, Kubeflow, or SageMaker for tracking experiments and automating workflows.
Hands-on experience with data manipulation libraries (Pandas, NumPy) and databases (SQL, NoSQL).
Knowledge of cloud-based ML deployment and infrastructure management.
Ability to implement real-time and batch inference pipelines efficiently.
Strong analytical and problem-solving skills to translate business needs into scalable ML solutions.
Eagerness to work in a fast-paced environment and continuously refine ML processes for efficiency and accuracy.

Benefits

Top of the market compensation for top performers
Comprehensive dental / vision
$1,500 annual learning stipend
$1,000 annual wellness stipend
$250 monthly lunch stipend
2 annual company retreats
Parental leave
Unlimited PTO

How to Apply

https://jobs.ashbyhq.com/bree/d5fe10d5-d3fa-4a89-a93f-3685570a7106",[]
Senior MLOPs Engineer - GCP - (Canada Remote),Rackspace Technology,Canada,Remote,"About the job
About the Role: 100% REMOTE!!!

We are looking for a seasoned Machine Learning Operations (MLOPs) Engineer to build, and optimize ML inference platform. The role demands an individual with significant expertise in Machine Learning engineering and infrastructure, with an emphasis on building Machine Learning inference systems. Proven experience in building and scaling ML inference platforms in a production environment is crucial. This remote position calls for exceptional communication skills and a knack for independently tackling complex challenges with innovative solutions.

Work Location: 100% Remote

Key Responsibilities

Architect and optimize ML Platforms to support cutting-edge machine learning and deep learning models
Collaborate closely with cross-functional teams to translate business objectives into scalable engineering solutions
Lead the end-to-end development and operation of high-performance, cost-effective inference systems for a diverse range of models, including state-of-the-art large language models (LLMs)
Provide technical leadership and mentorship to cultivate a high-performing engineering team
Develop CI/CD workflows for ML models and data pipelines using tools like Cloud Build, GitHub Actions, or Jenkins
Automate model training, validation, and deployment across development, staging, and production environments
Monitor and maintain ML models in production using Vertex AI Model Monitoring, logging (Cloud Logging), and performance metrics
Ensure reproducibility and traceability of experiments using ML metadata tracking tools like Vertex AI Experiments or MLflow
Manage model versioning and rollbacks using Vertex AI Model Registry or custom model management solutions
Collaborate with data scientists and software engineers to translate model requirements into robust and scalable ML systems
Optimize model inference infrastructure for latency, throughput, and cost efficiency using GCP services such as Cloud Run, Kubernetes Engine (GKE), or custom serving frameworks
Implement data and model governance policies, including auditability, security, and access control using IAM and Cloud DLP
Stay current with evolving GCP MLOps practices, tools, and frameworks to continuously improve system reliability and automation


Qualifications

Technical degree: Bachelor's degree in Computer Science with a minimum of 6+ years of relevant industry experience, or 
A Master's degree in Computer Science with at least 4+ years of relevant industry experience. Proven experience in implementing MLOps solutions on Google Cloud Platform (GCP) using services such as Vertex AI, Cloud Storage, BigQuery, Cloud Functions, and Dataflow
Proven experience in building and scaling agentic AI systems in production environments
Hands-on experience with leading deep learning frameworks such as TensorFlow, Pytorch, HuggingFace, Langchain, etc. 
Solid foundation in machine learning algorithms, natural language processing, and statistical modeling. 
Strong grasp of fundamental computer science concepts including algorithms, distributed systems, data structures, and database management. 
Ability to tackle complex challenges and devise effective solutions. Use critical thinking to approach problems from various angles and propose innovative solutions
Worked effectively in a remote setting, maintaining strong written and verbal communication skills. Collaborate with team members and stakeholders, ensuring clear understanding of technical requirements and project goals


Travel

Travel as per business requirements


Sponsorship

Candidate must be legally able to work for any employer in the US
This role is not sponsorship eligible


About Rackspace Technology

We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.

More on Rackspace Technology

Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",[]
Data Scientist - ML Engineer,SGS & Co,Canada,Remote,"About the job
ML Engineer - Data Science Team 
The ML Engineer will be a core member of the Data Science team at Propelis, collaborating with a diverse group of data scientists, data engineers, and developers. The team works across machine learning (ML), MLOps, machine vision, NLP, IoT, and prompt engineering. The ML Engineer will focus on deploying scalable AI/ML solutions in production and driving automation.
Profile
The ML Engineer is responsible for building robust, production-ready models and maintaining scalable machine learning pipelines. This role requires strong technical depth in MLOps, model optimization, and monitoring while also working closely with business stakeholders to support decision-making with AI-powered insights.
Key Responsibilities
Design, develop, and maintain machine learning models to solve business challenges and drive automation.
Implement and optimize ML algorithms for efficiency, scalability, and actionable insights.
Conduct experiments, A/B testing, and model evaluations to improve model performance.
Develop, containerize, and deploy AI/ML systems in production environments using best practices.
Automate and streamline end-to-end ML pipelines, ensuring reliable transitions from development to production.
Monitor and troubleshoot model performance, accuracy, and drift in live environments.
Execute and automate validation tests to ensure robustness and reliability.
Optimize training and inference workflows to enhance speed and scalability.
Manage model versioning, deployment strategies, and rollback mechanisms.
Collaborate with product, analytics, and engineering teams to align ML solutions with business goals.
Contribute to team codebases, documentation, and internal knowledge sharing.
Skills & Experience
Strong background in machine learning, statistics, and MLOps practices.
Experience with machine learning algorithms such as classification, XGBoost, decision trees, and deep learning.
Proficient in Python and familiar with libraries such as pandas, scikit-learn, NumPy, and PyTorch.
Knowledge of data pipelining and streaming tools.
Familiarity with SQL, NoSQL, or Cassandra is a plus.
Experience deploying ML models on cloud platforms (Azure, AWS, or GCP).
Strong communication, problem-solving skills, and ability to work in cross-functional teams.
Interest or experience in NLP, prompt engineering, or generative AI (e.g., GPT) is a plus.
Education Requirements
Bachelor’s degree in Data Science, Computer Science, Applied Mathematics, or related field.
Master’s degree preferred.
 We are committed to ensuring equal opportunity in all aspects of employment, including recruitment. We encourage applications from all qualified individuals, particularly those who may contribute to the further diversification of our organization. If you require any form of accommodation during the recruitment process, please do not hesitate to inform us. Together, we strive to foster an environment where everyone can thrive and be their authentic selves.
 
Desired Skills and Experience
Experience
Experience deploying ML models on cloud platforms (Azure, AWS, or GCP).
Familiarity with SQL, NoSQL, or Cassandra is a plus.
Knowledge of data pipelining and streaming tools.
Proficient in Python and familiar with libraries such as pandas, scikit-learn, NumPy, and PyTorch.
Experience with machine learning algorithms such as classification, XGBoost, decision trees, and deep learning.
Strong background in machine learning, statistics, and MLOps practices
Interest or experience in NLP, prompt engineering, or generative AI (e.g., GPT) is a plus.
Education
Bachelors or better in Computer Science or related field.
Masters or better.",[]
Lead DevOps Engineer (ML Platform)- EN,RBC,"Montreal, QC",Hybrid,"About the job
Job Summary

Job Description

What's the opportunity?

We’re looking for an experienced Lead DevOps Engineer (ML Platform) who will bring focus and subject-matter expertise around designing and implementing machine learning infrastructure and automation tools (MLOps and DevOps). This is a unique opportunity to grow in the world of machine learning infrastructure and work with a team of passionate individuals committed to the mission of bringing ML to enterprise.

At RBC Borealis, you’ll be joining a team that works directly with leading researchers in machine learning, has access to rich and massive datasets, and offers the computational resources to support ongoing development in areas such as reinforcement learning, unsupervised learning and computer vision. You can find out more about our research areas at rbcborealis.com.

Your responsibilities include:

Designing, building, and optimizing machine learning deployment tools and automation systems that operate the business’s data and ML applications;
Designing and implementing best practices and standards for data and machine learning pipelines across the organization;
Collaborating with engineers, and machine learning researchers to automate code analysis, build, integration and deployment of ML applications;
Supporting applications and projects with infrastructure design decision, and monitoring solution;
Building highly scalable, resilient cloud and on-premise systems for hosting machine learning systems using state-of-the-art technologies.

You're our ideal candidate if you have:

5+ years of working experience with building and maintaining DevOps pipeline such as Jenkins, GitHub actions;
Strong and relevant experience designing and implementing distributed systems and Machine Learning systems;
Previous experience with MLOps orchestration tools such as AirFlow, KubeFlow, Dagster, Flyte, or MetaFlow;
In-depth knowledge of various stages of the machine learning application deployment process;
Experience with building tools and applications to automate various infrastructure and DevOps tasks;
Proficiency with programming languages such as Python, Bash, or JavaScript;
Solid understanding of the UNIX operating system;
Implementing monitoring solutions to identify system bottlenecks and production issues;
Knowledge of professional software engineering best practices for the full software development life cycle, including testing methods, coding standards, code reviews and source control management;
Hands-on experience building and deploying hybrid environments on-prem and major cloud environments, such as AWS and Azure;
Familiarity with machine learning frameworks such as PyTorch, TensorFlow and/or similar.

What's in it for you?

Become part of a team that thinks progressively and works collaboratively. We care about seeing each other reach full potential;
A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock options where applicable;
Leaders who support your development through coaching and managing opportunities;
Ability to make a difference and lasting impact from a local-to-global scale.

About RBC Borealis

RBC Borealis is the driving force behind Royal Bank of Canada’s AI and data innovation. As part of Canada’s largest financial institution, we bring together a team of architects, engineers, scientists, and product experts on a mission to revolutionize finance through world-class research, solutions, and a resilient data platform. With locations across Toronto, Waterloo, Montreal, Calgary, and Vancouver, we’re at the forefront of AI research and platform development. With a focus on cutting-edge research in areas like time series forecasting, causal machine learning, and responsible AI, we are seamlessly integrating AI research and data engineering, to solve critical challenges in the financial industry. We are building intelligent, and scalable, data-driven solutions that will help communities thrive and drive innovation for our customers across the bank.

Inclusion and Equal Opportunity Employment

RBC is an equal opportunity employer committed to diversity and inclusion. We are pleased to consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veterans status, Aboriginal/Native American status or any other legally-protected factors. Disability-related accommodations during the application process are available upon request.

Job Skills

Big Data Analytics, Critical Thinking, Decision Making, Industry Knowledge, Machine Learning, Results-Oriented, Software Engineering, Software Product Design

Additional Job Details

Address:

777 BAY ST, TH 27:TORONTO

City:

TORONTO

Country:

Canada

Work hours/week:

37.5

Employment Type:

Full time

Platform:

TECHNOLOGY AND OPERATIONS

Job Type:

Regular

Pay Type:

Salaried

Posted Date:

2025-02-25

Application Deadline:

Note: Applications will be accepted until 11:59 PM on the day prior to the application deadline date above

Inclusion and Equal Opportunity Employment

At RBC, we believe an inclusive workplace that has diverse perspectives is core to our continued growth as one of the largest and most successful banks in the world. Maintaining a workplace where our employees feel supported to perform at their best, effectively collaborate, drive innovation, and grow professionally helps to bring our Purpose to life and create value for our clients and communities. RBC strives to deliver this through policies and programs intended to foster a workplace based on respect, belonging and opportunity for all.

Join our Talent Community

Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com</a/span>",[]
Sr. Machine Learning Engineer,Fortra,Canada,Remote,"About the job
Whether you’re an experienced professional or just getting started, your contributions matter at Fortra. If you’re passionate about tackling meaningful challenges alongside talented team members committed to helping each other succeed, all while having lots of fun, we want to hear from you. We offer competitive benefits and salaries, personal and professional development opportunities, flexibility, and much more!

At Fortra, we’re breaking the attack chain. Ready to join us?

This position is responsible for developing, enhancing, and maintaining our Machine Learning pipelines and data science solutions including data pipelines, infrastructure, and deployment of machine learning models. The scope of the role includes both existing software products and new products in development. The ideal candidate has a strong commitment to excellence, brings a wealth of expertise in ML Engineering, is a creative problem solver, and a team player.

What You'll Do

Lead highly complex ML engineering projects with extensive latitude for independent judgment. 
Design, develop, document, test, and debug software engineering solutions for both customer-facing applications and internal use. 
Deploy, scale, and maintain machine learning models in production environments. 
Develop scalable ML architecture and pipelines. 
Collaborate with data scientists to optimize, test, and evaluate ML models. 
Identify and evaluate new platforms and technologies to enhance our existing systems. 
Follow and help define and enforce our development best practices and standards. 
Provide mentorship and assistance to less experienced team members. 
Collaborate with architects and engineering managers to maintain development roadmaps and prioritize new features. 
Engage with data science and engineering teams to understand requirements and constraints for multiple products. 
Share your technical knowledge and MLOps framework expertise with team members. 
Maintain up-to-date knowledge of related MLOps and data science topics and technologies. 
Serve as the technical expert on the deployment and benchmarking of ML models including LLMs, and generative models. 
Acquire domain expertise in at least one cybersecurity application area. 
Write technical documentation based on architectural design and stated engineering requirements. 

Qualifications

At least 7 years of experience in engineering and/or data science roles is required with at least 1 year of senior role experience included. Multi-year experience as an ML engineer is desirable. 
Strong academic background (M.S or PhD program in a technical field) is an adequate substitute for a few years of industry experience. 
Thorough knowledge of software engineering and data science techniques and methodologies, and experience leading projects applying these methodologies. 
Extensive experience developing system architecture and solving engineering problems in at least one major programming language such as Python, Java, or C++. 
Comprehensive MLOps background and expertise in data processing, model training, and deployment of models as microservices. 
Substantial experience integrating applications with cloud technologies such as AWS. 
Proven track record of deploying and benchmarking ML models in production environments. 
Expertise in MLOps frameworks such as MLflow and Kubeflow is nice to have. 
Solid experience with Python-based frameworks such as PyTorch, TensorFlow, and scikit-learn is a plus. 
Demonstrated ability to collaborate with engineering leads, software architects, and other stakeholders to advance engineering and data science projects. 
Led multiple projects to completion in a small team. 
Proven experience assisting or providing mentorship to junior engineers. 
Excellent communication and presentation skills. Ability to convey complicated technical topics to non-technical people both verbally and in writing. 
Demonstrated excellent problem solving ability and critical thinking skill with a variety of engineering challenges. 
Comfortable and enthusiastic about sharing technical knowledge with team members. 
Interest in cybersecurity applications. 

Visit our website to learn more about why employees choose to work for Fortra. Remember to connect with us on LinkedIn.

As an EEO/Affirmative Action Employer, all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, veteran or disability status.",[]
Principal Machine Learning Operations Developer,Autodesk,"Toronto, ON",Hybrid,"About the job
Job Requisition ID #

25WD89881

Job Title: Principal Machine Learning Operations Developer for AI Research

Position Overview

The work we do at Autodesk touches nearly every person on the planet. By creating software tools for making buildings, machines, and even the latest movies, we influence and empower some of the most creative people in the world to solve problems that matter.

As a MLOps Developers at Autodesk Research, you will be working side-by-side with world-class AI researchers to build and scale foundation models trained on design data. You will focus on overcoming the challenges associated with large-scale model training and processing of vast amounts of diverse design data. Your expertise in distributed systems, ML infrastructure, and data engineering will be crucial in developing the next generation of ML-powered product features that will help our customers imagine, design, and make a better world.

You'll be joining a rapidly growing team working on a project that aims to revolutionize the design of nearly every aspect of the built environment. Your contributions will directly influence how designers, architects, and engineers interact with AI tools in the future.

This role is fully remote-friendly. Our team operates primarily remotely with team members distributed across the globe, with offices in London, Boston, Toronto and other locations worldwide. At Autodesk, we embrace remote work while fostering connection through regular team offsites for collaborative planning and relationship building. This balanced approach ensures you can work where you're most productive while maintaining meaningful connections with colleagues.

Responsibilities

Support AI researchers by building scalable ML training pipelines and infrastructure for foundation model development
Design efficient data processing workflows for large-scale design datasets and industry-specific file formats
Optimize distributed training systems and develop solutions for model parallelism, checkpointing, and efficient resource management
Analyze performance bottlenecks and provide solutions to scaling problems
Implement and maintain robust, testable code that is well documented and easy to understand
Collaborate on projects at the intersection of research and product with a diverse, global team of researchers and engineers
Present results to collaborators and leadership

Minimum Qualifications

BSc or MSc in Computer Science or related field, or equivalent industry experience
Experience with distributed systems for machine learning and deep learning at scale
Strong knowledge of ML infrastructure and model parallelism techniques, including frameworks like PyTorch, Lightning, Megatron, DeepSpeed, and FSDPProficiency in Python and strong software engineering practices
Experience with cloud services and architectures (AWS, Azure, etc.)
Familiarity with version control, CI/CD, and deployment pipelines
Excellent written documentation skills to document code, architectures, and experiments

Preferred Qualifications

Experience with AEC data formats (e.g., BIM models, IFC files, CAD files, Drawing Sets)
Knowledge of the AEC industry and its specific data processing challenges
Experience scaling ML training and data pipelines for large datasets
Experience with distributed data processing and ML infrastructure (e.g., Apache Spark, Ray, Docker, Kubernetes)
Experience with performance optimization, monitoring, and efficiency in large-scale ML systems
Experience with Autodesk or similar products (Revit, Sketchup, Forma)

The Ideal Candidate

A self-starter who can solve problems with minimal supervision while collaborating effectively with a global, remote-first team
Adaptable and creative, comfortable building new infrastructure or working within existing codebases
Thrives in ambiguous, rapidly evolving areas where learning and flexibility are essential
Excellent communicator who can convey complex technical concepts clearly to diverse audiences

______________________________________________________________________________________________________________

Ingénieur principal MLOps en IA""

Présentation du poste

Le travail que nous faisons chez Autodesk touche presque chaque personne sur la planète. En créant des outils logiciels pour construire des bâtiments, des machines et même les derniers films, nous influençons et donnons les moyens à certaines des personnes les plus créatives du monde de résoudre des problèmes importants.

En tant que développeur MLOps chez Autodesk Research,

vous travaillerez aux côtés de chercheurs en IA de renommée mondiale pour construire et mettre à l'échelle des modèles de base formés sur des données de conception. Vous vous concentrerez sur la résolution des défis associés à la formation de modèles à grande échelle et au traitement de vastes quantités de données de conception diverses. Votre expertise en matière de systèmes distribués, d'infrastructure d'apprentissage automatique et d'ingénierie des données sera cruciale pour développer la prochaine génération de fonctionnalités de produits basées sur l'apprentissage automatique qui aideront nos clients à imaginer, concevoir et créer un monde meilleur.

Vous rejoindrez une équipe en pleine croissance travaillant sur un projet qui vise à révolutionner la conception de presque tous les aspects de l'environnement bâti. Vos contributions influenceront directement la manière dont les designers, les architectes et les ingénieurs interagiront avec les outils d'IA à l'avenir.

Ce poste est entièrement adapté au télétravail. Notre équipe travaille principalement à distance, avec des membres répartis dans le monde entier, et des bureaux à Londres, Boston, Toronto et ailleurs. Chez Autodesk, nous encourageons le travail à distance tout en favorisant les liens entre les équipes grâce à des réunions régulières en dehors du bureau pour planifier la collaboration et renforcer les relations. Cette approche équilibrée vous permet de travailler là où vous êtes le plus productif tout en maintenant des liens significatifs avec vos collègues.

Responsabilités

Soutenir les chercheurs en IA en créant des pipelines et une infrastructure de formation ML évolutifs pour le développement de modèles de base
Concevoir des flux de traitement de données efficaces pour les ensembles de données de conception à grande échelle et les formats de fichiers spécifiques à l'industrie
Optimiser les systèmes de formation distribués et développer des solutions pour le parallélisme des modèles, le point de contrôle et la gestion efficace des ressources
Analyser les goulots d'étranglement en matière de performance et fournir des solutions aux problèmes d'évolutivité
Mettre en œuvre et maintenir un code robuste, testable, bien documenté et facile à comprendre
Collaborer à des projets à l'intersection de la recherche et du produit avec une équipe diversifiée et internationale de chercheurs et d'ingénieurs
Présenter les résultats aux collaborateurs et à la direction

Qualifications Minimales

Licence ou master en informatique ou dans un domaine connexe, ou expérience équivalente dans l'industrie
Expérience des systèmes distribués pour l'apprentissage automatique et l'apprentissage profond à grande échelle
Solide connaissance de l'infrastructure d'apprentissage automatique et des techniques de parallélisme des modèles, y compris des frameworks tels que PyTorch, Lightning, Megatron, DeepSpeed et FSDP Maîtrise de Python et des bonnes pratiques en matière de génie logiciel
Expérience des services et architectures cloud (AWS, Azure, etc.)
Connaissance du contrôle de version, de l'intégration continue/développement continu et des pipelines de déploiement
Excellentes compétences en matière de documentation écrite pour documenter le code, les architectures et les expériences

Qualifications Préférées

Expérience des formats de données AEC (par exemple, modèles BIM, fichiers IFC, fichiers CAO, jeux de dessins)
Connaissance du secteur AEC et de ses défis spécifiques en matière de traitement des données
Expérience de la mise à l'échelle de la formation en ML et des pipelines de données pour les grands ensembles de données
Expérience du traitement de données distribuées et de l'infrastructure ML (par exemple, Apache Spark, Ray, Docker, Kubernetes)
Expérience de l'optimisation des performances, de la surveillance et de l'efficacité des systèmes ML à grande échelle
Expérience avec Autodesk ou des produits similaires (Revit, Sketchup, Forma)

Le candidat idéal

Un esprit d'initiative qui peut résoudre des problèmes avec un minimum de supervision tout en collaborant efficacement avec une équipe mondiale, en priorité à distance
Adaptable et créatif, à l'aise pour construire de nouvelles infrastructures ou travailler dans des bases de code existantes
Épanoui dans des domaines ambigus et en évolution rapide où l'apprentissage et la flexibilité sont essentiels
Excellent communicateur capable de transmettre clairement des concepts techniques complexes à des publics divers

Learn More

About Autodesk

Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.

We take great pride in our culture here at Autodesk – it’s at the core of everything we do. Our culture guides the way we work and treat each other, informs how we connect with customers and partners, and defines how we show up in the world.

When you’re an Autodesker, you can do meaningful work that helps build a better world designed and made for all. Ready to shape the world and your future? Join us!

Salary transparency

Salary is one part of Autodesk’s competitive compensation package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, our compensation package may include annual cash bonuses, commissions for sales roles, stock grants, and a comprehensive benefits package.

Diversity & Belonging

We take pride in cultivating a culture of belonging where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging

Are you an existing contractor or consultant with Autodesk? 

Please search for open jobs and apply internally (not on this external site).",[]
Lead DevOps Engineer (ML Platform),RBC,"Vancouver, BC",Hybrid,"About the job
Job Summary

Job Description

What's the opportunity?

We’re looking for an experienced Lead DevOps Engineer (ML Platform) who will bring focus and subject-matter expertise around designing and implementing machine learning infrastructure and automation tools (MLOps and DevOps). This is a unique opportunity to grow in the world of machine learning infrastructure and work with a team of passionate individuals committed to the mission of bringing ML to enterprise.

At RBC Borealis, you’ll be joining a team that works directly with leading researchers in machine learning, has access to rich and massive datasets, and offers the computational resources to support ongoing development in areas such as reinforcement learning, unsupervised learning and computer vision. You can find out more about our research areas at rbcborealis.com.

Your responsibilities include:

Designing, building, and optimizing machine learning deployment tools and automation systems that operate the business’s data and ML applications;
Designing and implementing best practices and standards for data and machine learning pipelines across the organization;
Collaborating with engineers, and machine learning researchers to automate code analysis, build, integration and deployment of ML applications;
Supporting applications and projects with infrastructure design decision, and monitoring solution;
Building highly scalable, resilient cloud and on-premise systems for hosting machine learning systems using state-of-the-art technologies.

You're our ideal candidate if you have:

5+ years of working experience with building and maintaining DevOps pipeline such as Jenkins, GitHub actions;
Strong and relevant experience designing and implementing distributed systems and Machine Learning systems;
Previous experience with MLOps orchestration tools such as AirFlow, KubeFlow, Dagster, Flyte, or MetaFlow;
In-depth knowledge of various stages of the machine learning application deployment process;
Experience with building tools and applications to automate various infrastructure and DevOps tasks;
Proficiency with programming languages such as Python, Bash, or JavaScript;
Solid understanding of the UNIX operating system;
Implementing monitoring solutions to identify system bottlenecks and production issues;
Knowledge of professional software engineering best practices for the full software development life cycle, including testing methods, coding standards, code reviews and source control management;
Hands-on experience building and deploying hybrid environments on-prem and major cloud environments, such as AWS and Azure;
Familiarity with machine learning frameworks such as PyTorch, TensorFlow and/or similar.

What's in it for you?

Become part of a team that thinks progressively and works collaboratively. We care about seeing each other reach full potential;
A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock options where applicable;
Leaders who support your development through coaching and managing opportunities;
Ability to make a difference and lasting impact from a local-to-global scale.

About RBC Borealis

RBC Borealis is the driving force behind Royal Bank of Canada’s AI and data innovation. As part of Canada’s largest financial institution, we bring together a team of architects, engineers, scientists, and product experts on a mission to revolutionize finance through world-class research, solutions, and a resilient data platform. With locations across Toronto, Waterloo, Montreal, Calgary, and Vancouver, we’re at the forefront of AI research and platform development. With a focus on cutting-edge research in areas like time series forecasting, causal machine learning, and responsible AI, we are seamlessly integrating AI research and data engineering, to solve critical challenges in the financial industry. We are building intelligent, and scalable, data-driven solutions that will help communities thrive and drive innovation for our customers across the bank.

Inclusion and Equal Opportunity Employment

RBC is an equal opportunity employer committed to diversity and inclusion. We are pleased to consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veterans status, Aboriginal/Native American status or any other legally-protected factors. Disability-related accommodations during the application process are available upon request.

Job Skills

Big Data Analytics, Critical Thinking, Decision Making, Industry Knowledge, Machine Learning, Results-Oriented, Software Engineering, Software Product Design

Additional Job Details

Address:

777 BAY ST, TH 27:TORONTO

City:

TORONTO

Country:

Canada

Work hours/week:

37.5

Employment Type:

Full time

Platform:

TECHNOLOGY AND OPERATIONS

Job Type:

Regular

Pay Type:

Salaried

Posted Date:

2025-02-25

Application Deadline:

Note: Applications will be accepted until 11:59 PM on the day prior to the application deadline date above

Inclusion and Equal Opportunity Employment

At RBC, we believe an inclusive workplace that has diverse perspectives is core to our continued growth as one of the largest and most successful banks in the world. Maintaining a workplace where our employees feel supported to perform at their best, effectively collaborate, drive innovation, and grow professionally helps to bring our Purpose to life and create value for our clients and communities. RBC strives to deliver this through policies and programs intended to foster a workplace based on respect, belonging and opportunity for all.

Join our Talent Community

Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com</a/span>",[]
Engineering Manager - MLOps & Analytics,Canonical,"Gatineau, QC",Remote,"About the job
The role of an Engineering Manager at Canonical

As an Engineering Manager at Canonical, you must be technically strong, but your main responsibility is to run an effective team and develop the colleagues you manage. You will develop and review code as a leader, while at the same time staying aware of that the best way to improve the product is to ensure that the whole team is focused, productive and unblocked.

You are expected to help them grow as engineers, do meaningful work, do it outstandingly well, find professional and personal satisfaction, and work well with colleagues and the community. You will also be expected to be a positive influence on culture, facilitate technical delivery, and regularly reflect with your team on strategy and execution.

You will collaborate closely with other Engineering Managers, product managers, and architects, producing an engineering roadmap with ambitious and achievable goals.

We expect Engineering Managers to be fluent in the programming language, architecture, and components that their team uses, in this case popular open-source machine learning tools like Kubeflow, MLFlow, and Feast.

Code reviews and architectural leadership are part of the job. The commitment to healthy engineering practices, documentation, quality and performance optimisation is as important, as is the requirement for fair and clear management, and the obligation to ensure a high-performing team.

Location: This is a Globally remote role.

What your day will look like

Manage a distributed team of engineers and its MLOps/Analytics portfolio
Organize and lead the team's processes in order to help it achieve its objectives
Conduct one-on-one meetings with team members
Identify and measure team health indicators
Interact with a vibrant community
Review code produced by other engineers
Attend conferences to represent Canonical and its MLOps solutions
Mentor and grow your direct reports, helping them achieve their professional goals
Work from home with global travel for 2 to 4 weeks per year for internal and external events 

What we are looking for in you

A proven track record of professional experience of software delivery
Professional python development experience, preferably with a track record in open source
A proven understanding of the machine learning space, its challenges and opportunities to improve
Experience designing and implementing MLOps solutions
An exceptional academic track record from both high school and preferably university
Willingness to travel up to 4 times a year for internal events

Additional skills that you might also bring

The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them.

Hands-on experience with machine learning libraries, or tools.
Proven track record of building highly automated machine learning solutions for the cloud.
Experience with building machine learning models
Experience with container technologies (Docker, LXD, Kubernetes, etc.)
Experience with public clouds (AWS, Azure, Google Cloud)
Experience in the Linux and open-source software world
Working knowledge of cloud computing
Passionate about software quality and testing
Experience working on a distributed team on an open source project -- even if that is community open source contributions.
Demonstrated track record of Open Source contributions

What we offer you

We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally.

Distributed work environment with twice-yearly team sprints in person - we've been working remotely since 2004!
Personal learning and development budget of USD 2,000 per year
Annual compensation review
Recognition rewards
Annual holiday leave
Maternity and paternity leave
Employee Assistance Programme
Opportunity to travel to new locations to meet colleagues from your team and others
Priority Pass for travel and travel upgrades for long haul company events

About Canonical

Canonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do.

Canonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business.

Canonical is an equal opportunity employer

We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",[]
Senior Machine Learning Engineer,ShyftLabs,"Toronto, ON",Hybrid,"About the job
Position Overview:

ShyftLabs is seeking an experienced Senior Machine Learning Engineer to design and implement ML infrastructure and assess Agentic BI readiness for Fortune 500 enterprise companies. You will build robust MLOps platforms, design scalable ML pipelines, and provide strategic guidance for implementing autonomous business intelligence and AI-driven analytics systems.

ShyftLabs is a growing data product company founded in early 2020 and works primarily with Fortune 500 companies. We deliver digital solutions built to help accelerate the growth of businesses in various industries, by focusing on creating value through innovation.

Job Responsibilities:

Design and implement MLOps infrastructure using MLflow, Databricks Unity Catalogue, and AWS managed services
Build feature store implementations and ML model versioning strategies using Databricks and MLflow
Assess AI readiness and design roadmaps for Agentic BI implementations supporting autonomous insights generation
Design production ML systems supporting predictive analytics, classification, and optimization models
Implement ML model deployment pipelines with automated training, validation, and deployment workflows
Build model monitoring and performance management systems for production ML applications
Evaluate generative AI infrastructure requirements including semantic layers and automated analytics workflows
Design ML pipeline automation strategies integrating feature engineering, model training, and deployment processes
Implement real-time ML inference patterns supporting business-critical applications
Enterprise MLOps Expertise: Proven experience implementing ML infrastructure at Fortune 500 scale
Agentic BI Assessment: Understanding of autonomous AI systems and ability to assess organizational readiness for AI-driven business intelligence
Production ML Focus: Deep understanding of ML model deployment, monitoring, and lifecycle management in production environments
Strategic Communication: Strong consulting skills to present ML strategies and AI readiness roadmaps to executive leadership


Basic Qualifications:

Bachelor's or Master's degree in Computer Science, Machine Learning, Engineering, or related quantitative field
5+ years of experience in ML engineering with Fortune 500 enterprise-scale implementations
Expert-level experience with MLflow for model lifecycle management and experimentation tracking
Deep hands-on experience with Databricks ML platform including Unity Catalogue for ML governance
Proven experience with AWS ML services including SageMaker, model deployment, and managed ML infrastructure
Strong background in machine learning algorithms including supervised/unsupervised learning, ensemble methods, and deep learning
Experience with generative AI and LLM integration for business intelligence applications and semantic data modeling requirements
Knowledge of feature store architectures, ML data management patterns, and model versioning/automation workflows


Preferred Qualifications

Experience with Agentic BI frameworks and autonomous analytics systems
Knowledge of conversational AI and natural language interfaces for business intelligence
Understanding of AI governance frameworks and enterprise AI readiness assessment
Experience with real-time recommendation systems and live inference pipelines
Familiarity with financial modeling or pricing optimization ML applications
Understanding of A/B testing frameworks for ML model evaluation
Knowledge of ML governance and regulatory compliance requirements


We are proud to offer a competitive salary alongside a strong healthcare insurance and benefits package. The role is preferably hybrid, with 2 days per week spent in the office, and flexibility for client engagement needs. We pride ourselves on the growth of our employees, offering extensive learning and development resources.

ShyftLabs is an equal-opportunity employer committed to creating a safe, diverse and inclusive environment. We encourage qualified applicants of all backgrounds including ethnicity, religion, disability status, gender identity, sexual orientation, family status, age, nationality, and education levels to apply. If you are contacted for an interview and require accommodation during the interviewing process, please let us know.",[]
Machine Learning Engineer,Loblaw Companies Limited,,,"About the job
L’utilisation du masculin à pour but d’alléger le texte

Venez faire votre différence dans les communautés à travers le Canada, où l'authenticité, la confiance et l'établissement de liens sont valorisés - alors que nous façonnons l'avenir du commerce de détail au Canada, ensemble. Notre position unique en tant que l'un des plus grands employeurs du pays, celle associée à notre engagement à avoir un impact positif sur la vie de tous les Canadiens, viens offrir à nos collègues une gamme d'opportunités et d'expériences pour aider les Canadiens à Vivre Bien, Vivre Pleinement.

Chez Les Compagnies Loblaw Limitée, nous réussissons grâce à la collaboration, à l'engagement et nous plaçons la barre haute pour nous-mêmes et ceux qui nous entourent. Que vous débutiez votre carrière, que vous réintégriez le marché du travail ou que vous recherchiez un nouvel emploi, votre place est avec nous.

Does working with some of Canada’s most talented minds in innovation supporting retail, digital consumer solutions and analytical platforms excite you? Loblaw Technology powers some of Canada’s most game-changing retail solutions, giving our customers the ability to live their lives well.

Come work with a team that values diverse ideas, fosters a culture of inclusion and develops our talent from within. Loblaw Technology gives you the chance to excel, and helps you to strive for success in a big way. Keep reading to learn more!

Key Responsibilities

 Design, develop, and implement robust Machine Learning (ML) solutions and scalable data pipelines, contributing to the full ML lifecycle from data preparation to deployment and monitoring.
 Collaborate on the architecture and implementation of MLOps pipelines to automate and streamline model deployment, versioning, monitoring, and governance.
 Contribute to the design, implementation, and optimization of scalable, secure, and reliable ML infrastructure, leveraging Google Cloud Platform (GCP).
 Work closely with cross-functional teams including product, engineering, analytics, and business stakeholders to deliver high-quality data and ML solutions supporting analytics, reporting, and GenAI initiatives.
 Ensure data integrity, governance, security, and compliance in all data engineering and ML efforts.
 Provide hands-on technical expertise and contribute to architectural discussions in cloud-native data platforms, distributed systems, and real-time data processing.
 Monitor the performance and quality assurance of ML systems, identifying opportunities for continuous optimization.
 Participate in project delivery and technical planning to ensure successful execution of data and ML projects.

Required Qualifications

 Bachelor’s or master’s degree in computer science, Data Science, Engineering, or a related field.
 5+ years of hands-on experience in Data Science, ML engineering, or a related technical domain.
 Proven experience in designing and implementing data platforms and ML systems on cloud platforms, preferably GCP.
 Strong technical knowledge of data/ML architecture, ML models, ETL/ELT processes, and distributed computing frameworks.
 Proficiency in machine learning frameworks (e.g., TensorFlow, PyTorch, Scikit-learn) and experience with MLOps tools (e.g., MLflow, Kubeflow, Vertex AI Pipelines).
 Excellent communication, problem-solving, and collaboration skills, with the ability to work effectively within a team.

What Loblaw Offers You

We offer flexibility and balance, and an environment that sets you up for success no matter where your workspace is located.

Here, you will find a great team to help you achieve your goals as you help us achieve ours! Work in our fast-paced, exciting Technology environment, helping our stores, colleagues and customers every day.

Loblaw colleagues also enjoy:

Work Perks Program
Basketball & Volleyball courts, Ice Rink, Dry Cleaning services (1PCC Office)
Benefits
Paid Vacation

If you’re up to the challenge, then we would love to hear from you. Apply today, and get the process started. 

Loblaw recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. At Loblaw, we celebrate diversity and strive to build a culture of inclusion where differences are embraced, valued and supported. We are committed to being an equal opportunity employer and encourage people from all backgrounds and identities to apply to our jobs. Accommodation in the recruitment, assessment, and hiring process is available upon request for applicants with disabilities. 

We thank all candidates for their interest but please note, those candidates who meet the minimum requirements for the position will be contacted. 

www.Loblaw.ca/careers

Notre engagement envers la durabilité et l'impact social est un élément essentiel de notre façon de faire des affaires. Nous concentrons notre attention sur les domaines où nous pouvons avoir le plus grand impact. Notre approche de la durabilité et de l'impact social repose sur trois piliers - l'environnement, l'approvisionnement et la communauté. Nous recherchons constamment des moyens de faire preuve de leadership dans ces domaines importants. Nos valeurs ÊTRE – Engagement, Tient à coeur, Respect et Excellence – guident toutes nos prises de décision et prennent vie à travers notre culture bleue. Nous offrons à nos collègues des carrières progressives, une formation complète, de la flexibilité ainsi que les nombreux avantages compétitifs - voici quelques-unes des nombreuses raisons pour lesquelles nous sommes classés au palmarès des meilleurs employeurs du Canada, au palmarès des meilleurs employeurs pour la diversité au Canada, au palmarès des employeurs les plus verts au Canada et au palmarès des meilleurs employeurs pour les jeunes au Canada.

Si vous ne savez pas si votre expérience correspond à toutes les exigences ci-dessus, nous vous encourageons à postuler quand même. Nous recherchons des perspectives de candidatures variées, qui incluent des expériences diverses que nous pouvons ajouter à notre équipe.

Nous nous concentrons depuis longtemps sur la diversité, l'équité et l'inclusion, car nous savons que cela fera de notre entreprise un meilleur lieu de travail et de magasinage. Nous nous engageons à créer des environnements accessibles pour nos collègues, candidats et clients. Les demandes d'aménagement en raison d'un handicap (qui peut être visible ou pas, temporaire ou permanent) peuvent être faites à n'importe quel stade de la demande et de l'emploi. Nous encourageons les candidats à faire connaître leurs besoins en matière d'accommodation afin que nous puissions offrir des opportunités équitables.

Veuillez noter:

Les candidats âgés de 18 ans ou plus doivent effectuer une vérification des antécédents criminels. Les détails seront fournis lors du processus d’embauche.

#FR

#SS #DISTRC #ON",[]
Senior Machine Learning Engineer - Platform,Gusto,"Toronto, ON",Remote,"About the job
About Gusto

Gusto is a modern, online people platform that helps small businesses take care of their teams. On top of full-service payroll, Gusto offers health insurance, 401(k)s, expert HR, and team management tools. Today, Gusto offices in Denver, San Francisco, and New York serve more than 400,000 businesses nationwide.

Our mission is to create a world where work empowers a better life, and it starts right here at Gusto. That’s why we’re committed to building a collaborative and inclusive workplace, both physically and virtually. Learn more about our Total Rewards philosophy.

About The Role

As a Senior Machine Learning Engineer, you will work closely with applied science practitioners and engineers to rapidly build, deploy, and iterate high-quality ML infrastructure solutions at scale, ensuring both reliability and effectiveness. Your deep expertise in the machine learning

Model development cycle, along with a strong understanding of data pipelines and data infrastructure will be crucial in developing a dependable and scalable ML infrastructure for all of Gusto to rely on.

The ideal candidate is passionate about developing software, developing and documenting optimal processes, working with data, and understanding the needs of end users. A strong grasp of ML and data infrastructure is essential, as you will work with stakeholders to build efficient solutions to help our partners scale x times better.

Here’s What You’ll Do Day-to-day

Drive core components of our ML Platform technical roadmap to design and build MLOps solutions with automated pipelines and standardized processes to build, deploy, run, monitor, debug, and retrain ML Models.
Develop, maintain, and enhance frameworks for machine learning model development and deployment.
Collaborate with the ML model builders and application owners to determine business requirements and SLAs for API-enabled services.
Develop, maintain, and enhance infrastructure supporting machine learning services.
Support the development of new patterns for the deployment of machine learning models with CI/CD pipelines and automated testing.

Here’s What We're Looking For

At least 10 years of software engineering experience (Python, Ruby or Java).
Demonstrated experience architecting and developing infrastructure and platform services for machine learning lifecycle, such as feature stores, model development, deployment, and observability tools and solutions.
Experience with at least one of the major cloud platforms (AWS preferred but not required).
Experience with MLOps tooling such as KubeFlow, AWS Sagemaker, MlFlow, or similar.

Our cash compensation amount for this role is targeted at $157,000-$194,000/year in Denver, Chicago, Miami, Austin and Atlanta, $188,000-$222,000/year in Los Angeles, and $190,000- $235,000/year for San Francisco, Seattle and New York. Final offer amounts are determined by multiple factors, including candidate experience and expertise, and may vary from the amounts listed above.

Gusto has physical office spaces in Denver, San Francisco, and New York City. Employees who are based in those locations will be expected to work from the office on designated days approximately 2-3 days per week (or more depending on role). The same office expectations apply to all Symmetry roles, Gusto's subsidiary, whose physical office is in Scottsdale.

Note: The San Francisco office expectations encompass both the San Francisco and San Jose metro areas.

When approved to work from a location other than a Gusto office, a secure, reliable, and consistent internet connection is required.

Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto.

Gusto is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Gusto considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Gusto is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. We want to see our candidates perform to the best of their ability. If you require a medical or religious accommodation at any time throughout your candidate journey, please fill out this form and a member of our team will get in touch with you.

Gusto takes security and protection of your personal information very seriously. Please review our Fraudulent Activity Disclaimer.

Personal information collected and processed as part of your Gusto application will be subject to Gusto's Applicant Privacy Notice.",[]
ML Engineering - ML Ops,Workday,"Greater Toronto Area, Canada",Hybrid,"About the job
Your work days are brighter here.

At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.

At Workday, we value our candidates’ privacy and data security. Workday will never ask candidates to apply to jobs through websites that are not Workday Careers.

Please be aware of sites that may ask for you to input your data in connection with a job posting that appears to be from Workday but is not.

In addition, Workday will never ask candidates to pay a recruiting fee, or pay for consulting or coaching services, in order to apply for a job at Workday.

About The Team

Workday was founded on a vision to revolutionize enterprise software, built on a culture that puts people first. Our success is driven by a collaborative, employee-centric environment, where Workmates thrive and contribute to a greater purpose. We prioritize our people, communities, and the planet while maintaining profitability. Here, you’re encouraged to be yourself, embrace your energy and passion, and help shape the future. Join us in creating a brighter Workday for all!

Come join the Workday Search/Assistant team! We are part of the Employee Experience organization that enables employers to better engage and support their people while making work more personal and productive.

Workday is looking for a hardworking Machine Learning Operations engineer to contribute to the strategic mission of reaching workers where they are at. You will join an energetic, open minded and supportive group of engineers to redefine how workers engage with Enterprise applications. If you have a willingness to explore the unknown, be a technological pioneer and have passion around improving customer experiences then we want to hear from you!

About The Role

As a machine learning engineer passionate about ML Ops, you will

Implement MLOps tools, frameworks, and platforms to support ML development, deployment, and governance
Create and maintain a repeatable and reusable ML workflow for model training, evaluation, deployment, and maintenance
Improve tracking and monitoring of models, experiments, artifacts, and data
Engage with data engineers and data scientists in feature engineering efforts
Diagnose and resolve ML workflow and production issues quickly

We will challenge you to apply your best creative thinking, analysis, problem-solving, and technical abilities to make an impact on thousands of enterprises and millions of people.

About You

Highly self-motivated, always looking to take on work and get great pleasure from delivering production scale machine learning solutions to customers
A collaborative teammate who uses positive leadership to coordinate and deliver results across teams
A fast learner, detail oriented, decisive, and enjoys a fast-paced work environment
Flexible, reliable, outgoing and has a positive work attitude.

Basic Qualifications

3+ years understanding of Python in both production and ETL settings
2+ years of building Data or MLOps pipelines using Python, Airflow, Databricks, or other similar cloud native services
2+ years experience on AWS, Vertex AI, and Kubernetes 
2+ years experience in operationalization of Data Science projects using at least one of the popular frameworks or platforms (e.g. Airflow, Kubeflow, AWS Sagemaker, Google AI Platform) - Kubeflow in particular is a plus
1+ years experience building both data / ETL pipelines as well as model training infrastructure, and working with GPUs
1+ years Experience managing and supporting Docker, Kubernetes, Spark, CI/CD, Git-Ops
1+ years Experience with data versioning, ML model management, lifecycle, and reproducibility

Other Qualifications

Experience with ML frameworks such as PyTorch, Keras, Transformers, SKLearn
Experience with fine-tuning NLP models and with HuggingFace
Experience with AWS services especially EKS 
1+ years with MLOps tools like TFX, MLFlow, Kubeflow, Apache Spark, etc.
B.S. in a relevant field - (E.g. Computer Science, Mathematics, Engineering). M.S. or Ph.D are nice, but not required

Workday Pay Transparency Statement 

The annualized base salary ranges for the primary location and any additional locations are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please click here.

Primary Location: CAN.BC.Vancouver

Primary CAN Base Pay Range: $122,400 - $183,600 CAD

Additional CAN Location(s) Base Pay Range: $122,400 - $183,600 CAD

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.

Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.

Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.

Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!

,",[]
Lead DevOps Engineer (ML Platform),RBC,"Toronto, ON",Hybrid,"About the job
Job Summary

Job Description

What's the opportunity?

We’re looking for an experienced Lead DevOps Engineer (ML Platform) who will bring focus and subject-matter expertise around designing and implementing machine learning infrastructure and automation tools (MLOps and DevOps). This is a unique opportunity to grow in the world of machine learning infrastructure and work with a team of passionate individuals committed to the mission of bringing ML to enterprise.

At RBC Borealis, you’ll be joining a team that works directly with leading researchers in machine learning, has access to rich and massive datasets, and offers the computational resources to support ongoing development in areas such as reinforcement learning, unsupervised learning and computer vision. You can find out more about our research areas at rbcborealis.com.

Your responsibilities include:

Designing, building, and optimizing machine learning deployment tools and automation systems that operate the business’s data and ML applications;
Designing and implementing best practices and standards for data and machine learning pipelines across the organization;
Collaborating with engineers, and machine learning researchers to automate code analysis, build, integration and deployment of ML applications;
Supporting applications and projects with infrastructure design decision, and monitoring solution;
Building highly scalable, resilient cloud and on-premise systems for hosting machine learning systems using state-of-the-art technologies.

You're our ideal candidate if you have:

5+ years of working experience with building and maintaining DevOps pipeline such as Jenkins, GitHub actions;
Strong and relevant experience designing and implementing distributed systems and Machine Learning systems;
Previous experience with MLOps orchestration tools such as AirFlow, KubeFlow, Dagster, Flyte, or MetaFlow;
In-depth knowledge of various stages of the machine learning application deployment process;
Experience with building tools and applications to automate various infrastructure and DevOps tasks;
Proficiency with programming languages such as Python, Bash, or JavaScript;
Solid understanding of the UNIX operating system;
Implementing monitoring solutions to identify system bottlenecks and production issues;
Knowledge of professional software engineering best practices for the full software development life cycle, including testing methods, coding standards, code reviews and source control management;
Hands-on experience building and deploying hybrid environments on-prem and major cloud environments, such as AWS and Azure;
Familiarity with machine learning frameworks such as PyTorch, TensorFlow and/or similar.

What's in it for you?

Become part of a team that thinks progressively and works collaboratively. We care about seeing each other reach full potential;
A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock options where applicable;
Leaders who support your development through coaching and managing opportunities;
Ability to make a difference and lasting impact from a local-to-global scale.

About RBC Borealis

RBC Borealis is the driving force behind Royal Bank of Canada’s AI and data innovation. As part of Canada’s largest financial institution, we bring together a team of architects, engineers, scientists, and product experts on a mission to revolutionize finance through world-class research, solutions, and a resilient data platform. With locations across Toronto, Waterloo, Montreal, Calgary, and Vancouver, we’re at the forefront of AI research and platform development. With a focus on cutting-edge research in areas like time series forecasting, causal machine learning, and responsible AI, we are seamlessly integrating AI research and data engineering, to solve critical challenges in the financial industry. We are building intelligent, and scalable, data-driven solutions that will help communities thrive and drive innovation for our customers across the bank.

Inclusion and Equal Opportunity Employment

RBC is an equal opportunity employer committed to diversity and inclusion. We are pleased to consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veterans status, Aboriginal/Native American status or any other legally-protected factors. Disability-related accommodations during the application process are available upon request.

Job Skills

Big Data Analytics, Critical Thinking, Decision Making, Industry Knowledge, Machine Learning, Results-Oriented, Software Engineering, Software Product Design

Additional Job Details

Address:

777 BAY ST, TH 27:TORONTO

City:

TORONTO

Country:

Canada

Work hours/week:

37.5

Employment Type:

Full time

Platform:

TECHNOLOGY AND OPERATIONS

Job Type:

Regular

Pay Type:

Salaried

Posted Date:

2025-02-25

Application Deadline:

Note: Applications will be accepted until 11:59 PM on the day prior to the application deadline date above

Inclusion and Equal Opportunity Employment

At RBC, we believe an inclusive workplace that has diverse perspectives is core to our continued growth as one of the largest and most successful banks in the world. Maintaining a workplace where our employees feel supported to perform at their best, effectively collaborate, drive innovation, and grow professionally helps to bring our Purpose to life and create value for our clients and communities. RBC strives to deliver this through policies and programs intended to foster a workplace based on respect, belonging and opportunity for all.

Join our Talent Community

Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com</a/span>",[]
Associate Machine Learning Engineer,Manulife,"Toronto, ON",Hybrid,"About the job
The Associate Machine Learning Engineer will join the Group AI team, focusing on packaging models, automating workflows, and operationalizing analytics solutions to deliver business value across JH/Manulife! The ideal candidate should be an advanced programmer with a strong grasp of Data Science, Data Engineering, application development, software engineering, and DevOps.

Position Responsibilities

Collaborate closely with Data Scientists and Data Engineers to design and implement scalable, efficient machine learning pipelines that meet business needs.
Evaluate machine learning models to ensure optimal performance and scalability, making necessary adjustments to improve outcomes.
Deploy machine learning models into production environments, ensuring seamless integration, and continuously monitor their performance to maintain reliability and accuracy.
Manage and oversee data science infrastructure to streamline the model development and deployment process, ensuring efficient workflows.
Propose and implement appropriate tools, including languages, libraries, and frameworks, to enhance project execution and outcomes.
Work in collaboration with infrastructure architects to develop scalable and efficient solutions that align with organizational goals and technological capabilities.
Collaborate with multi-functional teams to integrate machine learning models into existing systems and processes, ensuring a smooth transition and effective implementation.
Stay ahead of the latest advancements in Machine Learning (ML), Artificial Intelligence (AI), and Generative AI (GenAI) to incorporate innovative techniques and technologies into projects.
Mentor peers and provide guidance on ML/LLMOps standard practices, fostering a culture of continuous learning and improvement within the team.

Required Qualifications

A bachelor's degree in computer science, engineering, or a related field is required, with a graduate degree being preferred.
Extensive hands-on experience with large-scale software engineering systems, emphasizing the development and deployment of machine learning models.

Preferred Qualifications

Proven experience in operationalizing code through DevOps pipelines, including tools like Git, Jenkins, and code scanning technologies.
Strong programming skills in Python, with experience in machine learning libraries like TensorFlow, PyTorch, or scikit-learn.
Strong familiarity with MLOps practices, including model monitoring, versioning, and lifecycle management to ensure robust and scalable deployment of machine learning solutions.
Advanced knowledge of SQL and experience working with relational databases, alongside proficiency in RDBMS and NoSQL databases.
Experience in infrastructure management, including cloud computing, Linux OS, networks, Docker, and Kubernetes.
Expertise in cloud-native architecture, preferably using the Azure stack, with skills in Azure ML, Databricks (Spark), and Azure Data Factory as valuable assets.
Proficient in building ETL pipelines for feature engineering on large-scale datasets using Spark.
Experience with Large Language Models (LLMs) including proprietary or open source models..
Ability to balance urgency with the delivery of high-quality, pragmatic solutions.
Expertise in delivering analytics and machine learning products, with a deep understanding of agile product delivery in enterprise environments.

When You Join Our Team

We’ll empower you to learn and grow the career you want. 
We’ll recognize and support you in a flexible environment where well-being and inclusion are more than just words. 
As part of our global team, we’ll support you in shaping the future you want to see. 

About Manulife And John Hancock

Manulife Financial Corporation is a leading international financial services provider, helping people make their decisions easier and lives better. To learn more about us, visit https://www.manulife.com/en/about/our-story.html.

Manulife is an Equal Opportunity Employer

At Manulife/John Hancock, we embrace our diversity. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour, ethnic origin, citizenship, religion or religious beliefs, creed, sex (including pregnancy and pregnancy-related conditions), sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law.

It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will work with applicants who request a reasonable accommodation during the application process. All information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and Manulife/John Hancock policies. To request a reasonable accommodation in the application process, contact recruitment@manulife.com.

Referenced Salary Location

Toronto, Ontario

Working Arrangement

Hybrid

Salary range is expected to be between

$60,900.00 CAD - $113,100.00 CAD

If you are applying for this role outside of the primary location, please contact recruitment@manulife.com for the salary range for your location. The actual salary will vary depending on local market conditions, geography and relevant job-related factors such as knowledge, skills, qualifications, experience, and education/training. Employees also have the opportunity to participate in incentive programs and earn incentive compensation tied to business and individual performance.

Manulife offers eligible employees a wide array of customizable benefits, including health, dental, mental health, vision, short- and long-term disability, life and AD&D insurance coverage, adoption/surrogacy and wellness benefits, and employee/family assistance plans. We also offer eligible employees various retirement savings plans (including pension and a global share ownership plan with employer matching contributions) and financial education and counseling resources. Our generous paid time off program in Canada includes holidays, vacation, personal, and sick days, and we offer the full range of statutory leaves of absence. If you are applying for this role in the U.S., please contact recruitment@manulife.com for more information about U.S.-specific paid time off provisions.",[]
Director of Machine Learning,Loblaw Companies Limited,,,"About the job
Come make your difference in communities across Canada, where authenticity, trust and making connections is valued – as we shape the future of Canadian retail, together. Our unique position as one of the country's largest employers, coupled with our commitment to positively impact the lives of all Canadians, provides our colleagues a range of opportunities and experiences to help Canadians Live Life Well®.

At Loblaw Companies Limited, we succeed through collaboration and commitment and set a high bar for ourselves and those around us. Whether you are just starting your career, re-entering the workforce, or looking for a new job, this is where you belong.

Does working with some of Canada’s most talented minds in innovation supporting retail, digital consumer solutions and analytical platforms excite you? Loblaw Technology powers some of Canada’s most game-changing retail solutions, giving our customers the ability to live their lives well.

Come work with a team that values diverse ideas, fosters a culture of inclusion and develops our talent from within. Loblaw Technology gives you the chance to excel, and helps you to strive for success in a big way. Keep reading to learn more!

Key Responsibilities

Lead, mentor, and scale high-performing teams of data and ML engineers, fostering a culture of technical excellence, innovation, and collaboration
Define and execute the organization’s machine learning strategy, ensuring alignment with business goals and driving impactful AI/ML initiatives.
Oversee the end-to-end ML lifecycle, including data preparation, feature engineering, model development, training, evaluation, deployment, monitoring, and retraining.
Architect and implement robust MLOps pipelines to automate and streamline model deployment, versioning, monitoring, and governance.
Oversee the design, implementation, and optimization of scalable, secure, and reliable data pipelines and ML infrastructure, leveraging Google Cloud Platform (GCP).
Collaborate cross-functionally with product, engineering, analytics, and business stakeholders to deliver robust data and ML solutions supporting analytics, reporting, Customer 360, and GenAI initiatives
Ensure data integrity, governance, security, and compliance across all data engineering and ML initiatives
Provide hands-on technical and architectural leadership in cloud-native data platforms, distributed systems, and real-time data processing
Oversee performance monitoring, quality assurance, and continuous optimization of data and ML systems
Stay current with emerging technologies and industry trends in data engineering, ML, and GenAI, driving continuous improvement and innovation.
Manage project delivery, resource allocation, and stakeholder communication to ensure successful execution of complex, high-impact data and ML projects.
Required Qualifications
Bachelor’s or Master’s degree in Computer Science, Data Science, Engineering, or a related field
10+ years of experience in data engineering, ML engineering, Data Science, or related domains, with 5+ years in a leadership role managing large, multi-disciplinary teams
Proven expertise in designing and operating large-scale data platforms and ML systems on cloud.
Deep technical knowledge of data/ML architecture, ML models, ETL/ELT, and distributed computing frameworks.
Expertise in machine learning frameworks (TensorFlow, PyTorch, Scikit-learn), MLOps tools (MLflow, Kubeflow, Vertex AI Pipelines), and cloud-native ML services.
Excellent communication, stakeholder management, and cross-functional collaboration skills

What Loblaw Offers You

We offer flexibility and balance, and an environment that sets you up for success no matter where your workspace is located.

Here, you will find a great team to help you achieve your goals as you help us achieve ours! Work in our fast-paced, exciting Technology environment, helping our stores, colleagues and customers every day.

Loblaw colleagues also enjoy:

Work Perks Program
On-site GoodLife Fitness, Basketball & Volleyball courts, Ice Rink, Dry Cleaning services (1PCC Office)
Tuition Reimbursement & Online Learning
Pension & Benefits
Paid Vacation

If you’re up to the challenge, then we would love to hear from you. Apply today, and get the process started. 

Loblaw recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. At Loblaw, we celebrate diversity and strive to build a culture of inclusion where differences are embraced, valued and supported. We are committed to being an equal opportunity employer and encourage people from all backgrounds and identities to apply to our jobs. Accommodation in the recruitment, assessment, and hiring process is available upon request for applicants with disabilities. 

We thank all candidates for their interest but please note, those candidates who meet the minimum requirements for the position will be contacted. 

www.Loblaw.ca/careers

Our commitment to Sustainability and Social Impact is an essential part of the way we do business, and we focus our attention on areas where we can have the greatest impact. Our approach to sustainability and social impact is based on three pillars – Environment, Sourcing and Community – and we are constantly looking for ways to demonstrate leadership in these important areas. Our CORE Values – Care, Ownership, Respect and Excellence – guide all our decision-making and come to life through our Blue Culture. We offer our colleagues progressive careers, comprehensive training, flexibility, and other competitive benefits – these are some of the many reasons why we are one of Canada’s Top Employers, Canada’s Best Diversity Employers, Canada’s Greenest Employers & Canada’s Top Employers for Young People.

If you are unsure whether your experience matches every requirement above, we encourage you to apply anyway. We are looking for varied perspectives which include diverse experiences that we can add to our team.

We have a long-standing focus on diversity, equity and inclusion because we know it will make our company a better place to work and shop. We are committed to creating accessible environments for our colleagues, candidates and customers. Requests for accommodation due to a disability (which may be visible or invisible, temporary or permanent) can be made at any stage of application and employment. We encourage candidates to make their accommodation needs known so that we can provide equitable opportunities.

Please Note:

Candidates who are 18 years or older are required to complete a criminal background check. Details will be provided through the application process.

#EN

#SS #LTnA #ON",[]
Senior Machine Learning (ML) Engineer,Sanofi,"Toronto, ON",Hybrid,"About the job
Reference No. R2794016

Position Title: Senior Machine Learning (ML) Engineer

Department: MLOps Engineering

Location:  Downtown Toronto, Ontario, Hybrid (3 days onsite)

About Sanofi

We are an innovative global healthcare company, driven by one purpose: we chase the miracles of science to improve people’s lives. Our team, across some 100 countries, is dedicated to transforming the practice of medicine by working to turn the impossible into the possible. We provide potentially life-changing treatment options and life-saving vaccine protection to millions of people globally, while putting sustainability and social responsibility at the center of our ambitions.

Sanofi has recently embarked on a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions, to accelerate R&D, manufacturing and commercial performance and bring better drugs and vaccines to patients faster, to improve health and save lives.

Our vision for AI 

Join us on our journey in enabling Sanofi’s Digital Transformation through becoming an AI first organization. This means:

AI Factory: An extensive portfolio of AI products driving every stage of the company's value chain, from R&D and trials to manufacturing, supply chain, and commercial operations.

State-of-the-art Tech Stack: Globally deployed products using a state-of-the-art technology stack.

World-Class Mentorship and Training: Collaborate with renowned leaders and academics in AI/ML to enhance your skills and expertise.

We are an innovative global healthcare company with one purpose: to chase the miracles of science to improve people’s lives. We’re also a company where you can flourish and grow your career, with countless opportunities to explore, make connections with people, and stretch the limits of what you thought was possible. Ready to get started?

Main Job Responsibilities

Design, build, deploy and maintain AI/ML applications (contribution in multiple products) with a strong consideration for scalability, reliability, and security
Work in agile PODs to develop AI/ML products (Owning lifecycle of AI/ML components of the system)
Implement automated model training and deployment pipelines adapting and validating via close collaboration with data scientists and data engineers
Support end-to-end lifecycle management (e.g., new releases, change management, monitoring, and troubleshooting) of deployed AI/ML applications
Build scalable, robust, and reusable code, as well as processes supporting seamless AI/ML Ops (e.g., app monitoring, troubleshooting, life cycle management, and customer support) experience
Work closely with the product management team in designing solutions and challenging product features
Work as subject matter expert in MLOps (e.g., develop and maintain enterprise standards, user guides, release notes, FAQs)
Mentor junior team members and contribute to the AI engineering center of practice community.
Develop Architecture Decision Record (ADR) via cross-functional collaboration
Build processes and reusable components supporting seamless ML Operations (e.g., app monitoring, troubleshooting, life cycle management and customer support)
Walk stakeholders and solution partners through solutions and reviewing product change and development needs
Maintain effective relationships with app userbase to develop education and communication content as per life cycle events
Research and gain expertise on emerging tools and technologies. An enthusiasm to ask questions and try and learn new things is essential

About You

You are a dynamic experienced Machine Learning Engineer interested in challenging the status quo to ensure seamless AI/ML Engineering Operations that scale up Sanofi's AI solutions for the patients of tomorrow. You are an influencer and a future leader who has deployed AI/ML solutions with technically robust lifecycle management and infrastructural support. You are deeply interested in improvement opportunities and always thrive to demonstrate ability to deliver using AI/ML Engineering skills while working across the full stack and moving fluidly between programming languages and technologies

We are a highly collaborative team of tech enthusiasts with experience from the world class tech companies around the world, on a mission to help Sanofi transform into a first-in-class AI-focused data-driven company
Your work will have a tangible positive impact on patients’ lives around the world
Help bring the miracles of science to life alongside a supportive, future-focused team
Discover endless opportunities to grow your talent and drive your career, whether it is through a promotion or lateral move, at home or internationally
Enjoy a thoughtful, well-crafted rewards package that recognizes your contribution and amplifies your impact
Take good care of yourself and your family, with a wide range of health and wellbeing benefits including high-quality healthcare, prevention, and wellness programs and at least 14 weeks’ gender-neutral parental leave.
Play an instrumental part in creating best practice within our manufacturing facility

This position is for a current vacant role that we are actively hiring for.

Sanofi is an equal opportunity employer committed to diversity and inclusion. Our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. We welcome and encourage applications from all qualified applicants. Accommodations for persons with disabilities required during the recruitment process are available upon request.

#GD-SP

#DBBCA

All compensation will be determined commensurate with demonstrated experience. Employees may be eligible to participate in Company employee benefit programs, and additional benefits information can be found here.

Les employés peuvent être admissibles à participer aux programmes d'avantages sociaux de l'entreprise. Des informations supplémentaires sur les avantages sociaux peuvent être trouvées ici.

Pursue Progress. Discover Extraordinary.

Join Sanofi and step into a new era of science - where your growth can be just as transformative as the work we do. We invest in you to reach further, think faster, and do what’s never-been-done-before. You’ll help push boundaries, challenge convention, and build smarter solutions that reach the communities we serve. Ready to chase the miracles of science and improve people’s lives? Let’s Pursue Progress and Discover Extraordinary – together.

At Sanofi, we provide equal opportunities to all regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, protected veteran status or other characteristics protected by law.",[]
Senior ML OPS _ Content Creation Technology Group,Jobs for Humanity,,,"About the job
This job is sourced from a job board. Learn More
The Content Creation Technology Group (CCTG) is looking for a Senior ML Ops to work in a team that develops machine learning tools to support teams in creating, testing, and deploying ML solutions to games. You will support and collaborate with Data Scientists, Software Developers and other stakeholders in delivering these ML solutions. The Senior ML Ops role will bring best practices and design principles to assist the team in delivering our ambitious features roadmap.

Main Responsibilities

Designing and developing machine learning systems and schemes based on the business requirements and objectives.
Optimizing existing tools for improved performance, scalability, and efficiency.
Contribute to the industrialization of machine learning projects, focusing on building pipelines and workflows.
Adapting and improving models’ usage, facilitating tools usage, and adapting these to users needs.
Create tools to support and integrate the ML models inside a multi-process pipeline.
Enhancing the existing machine learning libraries and frameworks.
Collaborating with game production teams, data science team, research team and other stakeholders.

Other Responsibilities

Conducting research to stay up to date with the latest advancements.
Documentation, presentations, and knowledge sharing to communicate complex AI concepts to both technical and non-technical collaborators.
Creating proof of concepts to satisfy investigations into product directions.

Education

Bachelor’s degree in computer science or computer engineering or equivalent. A specialization in Machine Learning is an asset.

Relevant Experience

A minimum of 5 years of experience in software engineering.
A minimum of 2 years of experience in machine learning.

Skills

A good knowledge of a production machine learning pipeline; from ML training and deployment to model performance-tracking/behavioral-drift.
Proficient in Python and have experience with libraries and frameworks such as PyTorch and/or TensorFlow.
A familiarity with MLOps platforms such as Databricks and/or ClearML.
A good knowledge of container technology such as Docker and/or Kubernetes.
A good knowledge of machine learning and deep learning fundamentals.
A good knowledge of Database products is an asset.
A good knowledge of cloud-based platforms is an asset.

Jobs for Humanity is collaborating with Ubisoft to build an inclusive and just employment ecosystem. We support individuals coming from all walks of life.

Company Name: Ubisoft",[]
Senior ML Engineer,Xero,"Vancouver, BC",Remote,"About the job



Our Purpose 
 At Xero, we’re here to help you supercharge your business. We do this by automating routine tasks, surfacing actionable insights and connecting businesses with the right data, advisors and apps. When that happens, we’re not only making life better for small business, we’ll be building a stronger economy that can change the world. 


 The AI team at Xero brings together ML Engineers and Applied Scientists to build systems that power Xero's next generation of beautiful, insightful products. 


About The Team


 The AI Products group exists to collaboratively build products that use AI and ML to reduce toil and deliver the right insight at the right time. Working within the Data & Science team, you will join a diverse, globally distributed team of scientists, engineers, product managers, and analysts who help Xero turn data into beautiful, insightful products. 


 ML engineers design and build the infrastructure and services that power AI products that serve millions of customers every day. They also work closely with Applied Scientists through the research and development process to create harnesses and interfaces to safely take models from research to production environments. As a Sr.ML Engineer, you will lead delivery programs and co-lead research programs that push the boundaries of what's possible with today's technology. 
 

About The Role
Leading the design of our AI research and production infrastructure and services, ensuring that our services scale while preserving flexibility for research teams
Owning our strategy for managing the growth rate of technical debt and costs across our stack
Making sure we're solving the right problems with the right methods
Sharing knowledge with colleagues and lifting the bar for the AI Products team
Working with teams across Xero to improve the quality and usability of data 
Building Xero's profile in market through public facing content and events
 

About You
You have 6+ years of experience delivering cloud-based products at scale
You are drawn to solving hard problems and understanding how things work
You are comfortable learning new frameworks (GenAI and agentic based flows, etc) and applying them to real problems
You are willing to dive into the unknown, and allow new information to change your decisions
Constant learning and growth are an important part of who you are
You are always willing to learn from others and ask for help
 

What you’ll Bring With You
Strong coding and system design skills in Python or another language used in large scale AI applications
Excellent written and verbal communication skills for communicating technical concepts to technical and business stakeholder
Familiarity with modern cloud architecture, preferably in AWS.
Familiarity with GenAI frameworks (Pydantic AI, Langchain, etc) is a strong plus.
 

Why Xero?
Diversity of people brings diversity of thought, and we like that. Our human-first culture of respect, fairness, and inclusion is what helps Xeros thrive and work and beyond, and that includes our candidates. Research has shown that women and underrepresented groups are less likely to apply to jobs unless they meet every single competency or experience, but you could be just the right person for this role. If you are excited about working at Xero, but your past experience doesn't align perfectly, we encourage you to apply anyway.


Offering very generous paid leave to use however you’d like (plus statutory holidays!), dedicated paid leave to care for your physical and mental wellbeing as well as an Employee Assistance Program to access mental health care for you and your family, health insurance and dental reimbursement with vision allowances, a healthcare spending account, fertility and family forming financial support, wellbeing and sports programmes, employee resource groups, 26 weeks of parental leave for primary caregivers, an Employee Share Plan, beautiful offices with shared meals, flexible working, career development, and many other benefits that reflect our human value, you’ll do the best work of your life at Xero.",[]
Engineering Manager - MLOps & Analytics,Canonical,"Victoria, BC",Remote,"About the job
The role of an Engineering Manager at Canonical

As an Engineering Manager at Canonical, you must be technically strong, but your main responsibility is to run an effective team and develop the colleagues you manage. You will develop and review code as a leader, while at the same time staying aware of that the best way to improve the product is to ensure that the whole team is focused, productive and unblocked.

You are expected to help them grow as engineers, do meaningful work, do it outstandingly well, find professional and personal satisfaction, and work well with colleagues and the community. You will also be expected to be a positive influence on culture, facilitate technical delivery, and regularly reflect with your team on strategy and execution.

You will collaborate closely with other Engineering Managers, product managers, and architects, producing an engineering roadmap with ambitious and achievable goals.

We expect Engineering Managers to be fluent in the programming language, architecture, and components that their team uses, in this case popular open-source machine learning tools like Kubeflow, MLFlow, and Feast.

Code reviews and architectural leadership are part of the job. The commitment to healthy engineering practices, documentation, quality and performance optimisation is as important, as is the requirement for fair and clear management, and the obligation to ensure a high-performing team.

Location: This is a Globally remote role.

What your day will look like

Manage a distributed team of engineers and its MLOps/Analytics portfolio
Organize and lead the team's processes in order to help it achieve its objectives
Conduct one-on-one meetings with team members
Identify and measure team health indicators
Interact with a vibrant community
Review code produced by other engineers
Attend conferences to represent Canonical and its MLOps solutions
Mentor and grow your direct reports, helping them achieve their professional goals
Work from home with global travel for 2 to 4 weeks per year for internal and external events 

What we are looking for in you

A proven track record of professional experience of software delivery
Professional python development experience, preferably with a track record in open source
A proven understanding of the machine learning space, its challenges and opportunities to improve
Experience designing and implementing MLOps solutions
An exceptional academic track record from both high school and preferably university
Willingness to travel up to 4 times a year for internal events

Additional skills that you might also bring

The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them.

Hands-on experience with machine learning libraries, or tools.
Proven track record of building highly automated machine learning solutions for the cloud.
Experience with building machine learning models
Experience with container technologies (Docker, LXD, Kubernetes, etc.)
Experience with public clouds (AWS, Azure, Google Cloud)
Experience in the Linux and open-source software world
Working knowledge of cloud computing
Passionate about software quality and testing
Experience working on a distributed team on an open source project -- even if that is community open source contributions.
Demonstrated track record of Open Source contributions

What we offer you

We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally.

Distributed work environment with twice-yearly team sprints in person - we've been working remotely since 2004!
Personal learning and development budget of USD 2,000 per year
Annual compensation review
Recognition rewards
Annual holiday leave
Maternity and paternity leave
Employee Assistance Programme
Opportunity to travel to new locations to meet colleagues from your team and others
Priority Pass for travel and travel upgrades for long haul company events

About Canonical

Canonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do.

Canonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business.

Canonical is an equal opportunity employer

We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",[]
Engineering Manager - MLOps & Analytics,Canonical,"res, QC",Remote,"About the job
The role of an Engineering Manager at Canonical

As an Engineering Manager at Canonical, you must be technically strong, but your main responsibility is to run an effective team and develop the colleagues you manage. You will develop and review code as a leader, while at the same time staying aware of that the best way to improve the product is to ensure that the whole team is focused, productive and unblocked.

You are expected to help them grow as engineers, do meaningful work, do it outstandingly well, find professional and personal satisfaction, and work well with colleagues and the community. You will also be expected to be a positive influence on culture, facilitate technical delivery, and regularly reflect with your team on strategy and execution.

You will collaborate closely with other Engineering Managers, product managers, and architects, producing an engineering roadmap with ambitious and achievable goals.

We expect Engineering Managers to be fluent in the programming language, architecture, and components that their team uses, in this case popular open-source machine learning tools like Kubeflow, MLFlow, and Feast.

Code reviews and architectural leadership are part of the job. The commitment to healthy engineering practices, documentation, quality and performance optimisation is as important, as is the requirement for fair and clear management, and the obligation to ensure a high-performing team.

Location: This is a Globally remote role.

What your day will look like

Manage a distributed team of engineers and its MLOps/Analytics portfolio
Organize and lead the team's processes in order to help it achieve its objectives
Conduct one-on-one meetings with team members
Identify and measure team health indicators
Interact with a vibrant community
Review code produced by other engineers
Attend conferences to represent Canonical and its MLOps solutions
Mentor and grow your direct reports, helping them achieve their professional goals
Work from home with global travel for 2 to 4 weeks per year for internal and external events 

What we are looking for in you

A proven track record of professional experience of software delivery
Professional python development experience, preferably with a track record in open source
A proven understanding of the machine learning space, its challenges and opportunities to improve
Experience designing and implementing MLOps solutions
An exceptional academic track record from both high school and preferably university
Willingness to travel up to 4 times a year for internal events

Additional skills that you might also bring

The following skills may be helpful to you in the role, but we don't expect everyone to bring all of them.

Hands-on experience with machine learning libraries, or tools.
Proven track record of building highly automated machine learning solutions for the cloud.
Experience with building machine learning models
Experience with container technologies (Docker, LXD, Kubernetes, etc.)
Experience with public clouds (AWS, Azure, Google Cloud)
Experience in the Linux and open-source software world
Working knowledge of cloud computing
Passionate about software quality and testing
Experience working on a distributed team on an open source project -- even if that is community open source contributions.
Demonstrated track record of Open Source contributions

What we offer you

We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally.

Distributed work environment with twice-yearly team sprints in person - we've been working remotely since 2004!
Personal learning and development budget of USD 2,000 per year
Annual compensation review
Recognition rewards
Annual holiday leave
Maternity and paternity leave
Employee Assistance Programme
Opportunity to travel to new locations to meet colleagues from your team and others
Priority Pass for travel and travel upgrades for long haul company events

About Canonical

Canonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do.

Canonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business.

Canonical is an equal opportunity employer

We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.",[]
Machine Learning (ML) Engineer,Deloitte,,,"About the job
Job Type: PermanentWork Model: HybridReference code: 127082Primary Location: Toronto, ONAll Available Locations: Toronto, ON

Our Purpose

At Deloitte, our Purpose is to make an impact that matters. We exist to inspire and help our people, organizations, communities, and countries to thrive by building a better future. Our work underpins a prosperous society where people can find meaning and opportunity. It builds consumer and business confidence, empowers organizations to find imaginative ways of deploying capital, enables fair, trusted, and functioning social and economic institutions, and allows our friends, families, and communities to enjoy the quality of life that comes with a sustainable future. And as the largest 100% Canadian-owned and operated professional services firm in our country, we are proud to work alongside our clients to make a positive impact for all Canadians.

By living our Purpose, we will make an impact that matters.

Have many careers in one Firm.
Enjoy flexible, proactive, and practical benefits that foster a culture of well-being and connectedness.
Learn from deep subject matter experts through mentoring and on the job coaching


Are you passionate about solving complex analytical problems, learning about the latest in cutting-edge Al and continuing to develop your analytical and business development skills? If you answered yes, then we have an opportunity waiting for you!

What will your typical day look like?

As a Machine Learning Operations Engineer, you will take a hands-on role in delivering advisory services to high growth organizations with a diverse team consisting of data scientists, data architects, software developers, information designers, and business/industry leaders. You will work with the team to design, develop, deploy, and manage machine learning models at scale in production for our clients. You will play a role in pitches and proposal bids, and will assist in different areas of project of project management, including client projects and internal initiatives.

About The Team

Deloitte AI and Data, Deloitte's Artificial Intelligence (Al) practice is comprised of Al/ML experts with hands-on experience in developing and deploying Al/ML solutions to create competitive advantage for the Canadian businesses as part of their overall Data and Al/ML transformations journey. AI and Data Data Science team works together with Canadian businesses to envision and craft the solutions that drive automation, optimization, efficiency and many cases new opportunities with being mindful of driving responsible and transparent Al. We strive for empowering our clients' organization to become data and insight driven organizations with Al/ML first mindset to produce tangible business outcomes.

Data Science team will work with our clients to:

 Assess, recommend and create business capability roadmaps where Data Science can provide a significant business value and impact
 Harnessing data to craft best Al/ML driven solutions solving business problems and creating business opportunities
 Deploy Al/ML solutions with the state-of-the-art MLOps practices
 Leverage visual analytics to maximize business gain from data driven insights and findings

Enough about us, let’s talk about you

You are someone with:

3+ years relevant work experience with building and automating data analytics and Machine Learning (ML) pipelines
Good understanding of ML and Al concepts. Hands-on experience in ML model development.
Experience in operationalization of Machine Learning projects (MLOps) using at least one of the popular frameworks or platforms (e.g. Kubeflow, AWS Sagemaker, Google Al Platform, Azure Machine Learning, DataRobot, MLFlow).
Strong experience in Python used both for ML and automation tasks.
Database and programming languages experience and data manipulation and integration skills using SQL, Oracle, Hadoop, NoSQL Databases, or similar tools
Experience with Kubernetes and the ecosystem of Cloud Native tools.
Ability to work with data with significant ambiguity, develop creative approaches to analytical problems, and interpret data and results from a business/industry perspective
Strong oral and written communication skills
Minimum Bachelor degree in Computer Science, Software Engineering, Electrical Engineering, Computer Engineering or related field.
Experience with Azure or AWS platforms is an asset
Project management experience is an asset
Professional services, consulting, or advisory experience is an asset 

Total Rewards

The salary range for this position is $72,000 - $138,000, and individuals may be eligible to participate in our bonus program. Deloitte is fair and competitive when it comes to the salaries of our people. We regularly benchmark across a variety of positions, industries, sectors, targets, and levels. Our approach is grounded on recognizing people's unique strengths and contributions and rewarding the value that they deliver.

Our Total Rewards Package extends well beyond traditional compensation and benefit programs and is designed to recognize employee contributions, encourage personal wellness, and support firm growth. Along with a competitive base salary and variable pay opportunities, we offer a wide array of initiatives that differentiate us as a people-first organization. On top of our regular paid vacation days, some examples include: $4,000 per year for mental health support benefits, a $1,300 flexible benefit spending account, firm-wide closures known as ""Deloitte Days"", dedicated days of for learning (known as Development and Innovation Days), flexible work arrangements and a hybrid work structure.

Our promise to our people: Deloitte is where potential comes to life.

Be yourself, and more.

We are a group of talented people who want to learn, gain experience, and develop skills. Wherever you are in your career, we want you to advance.

You Shape How We Make Impact.

Diverse perspectives and life experiences make us better. Whoever you are and wherever you’re from, we want you to feel like you belong here. We provide flexible working options to support you and how you can contribute.

Be the leader you want to be 

Some guide teams, some change culture, some build essential expertise. We offer opportunities and experiences that support your continuing growth as a leader.

Have as many careers as you want.

We are uniquely able to offer you new challenges and roles – and prepare you for them. We bring together people with unique experiences and talents, and we are the place to develop a lasting network of friends, peers, and mentors.

The next step is yours

At Deloitte, we are all about doing business inclusively – that starts with having diverse colleagues of all abilities. Deloitte encourages applications from all qualified candidates who represent the full diversity of communities across Canada. This includes, but is not limited to, people with disabilities, candidates from Indigenous communities, and candidates from the Black community in support of living our values, creating a culture of Diversity Equity and Inclusion and our commitment to our AccessAbility Action Plan , Reconciliation Action Plan and the BlackNorth Initiative .

We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation for the recruitment process (including alternate formats of materials, accessible meeting rooms or other accommodations) or indigenouscareers@deloitte.ca for any questions relating to careers for Indigenous peoples at Deloitte (First Nations, Inuit, Métis).

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.

Deloitte Canada has 20 offices with representation across most of the country. We acknowledge that Deloitte offices stand on traditional, treaty, and unceded territories in what is now known as Canada. We recognize that Indigenous Peoples have been the caretakers of this land since time immemorial, nurturing its resources and preserving its natural beauty. We acknowledge this land is still home to many First Nations, Inuit, and Métis Peoples, who continue to maintain their deep connection to the land and its sacred teachings. We humbly acknowledge that we are all Treaty people, and we commit to fostering a relationship of respect, collaboration, and stewardship with Indigenous communities in our shared goal of reconciliation and environmental sustainability.",[]
ML Ops Engineer (6 month contract),Rakuten Kobo Inc.,,,"About the job
Job Description

Here at Rakuten Kobo Inc. we offer a casual working start-up environment and a group of friendly and talented individuals. Our employees rank us highly in terms of commitment to work/life balance. We realize that for our people to be innovative, creative and passionate they need to feel valued and supported. We believe in rewarding all our employees with competitive salaries, performance based annual bonuses, stock options and training opportunities.

If you’re looking for a company that inspires passion, personal, and professional growth – join Kobo and come help us on our mission of making reading lives better.

The Role

Rakuten Kobo is building a robust ML Ops infrastructure on Google Cloud Platform (GCP) to automate the development and deployment of AI/ML models. We are seeking a senior ML Ops/DevOps Engineer with deep GCP experience to lead the design and implementation of scalable, automated ML pipelines.

Key Responsibilities

Design and implement an end-to-end MLOps capabilities in GCP using VertexAI
Lead the transition from manual to automated ML workflows
Collaborate with data scientists and engineers to integrate models into production
Mentor internal team members on ML Ops best practices
Ensure system reliability, scalability, and performance 

Must-Haves

5+ years in ML Ops or DevOps roles
Strong experience with GCP, especially Vertex AI
Proficiency in Kubernetes, Airflow, and ML lifecycle management
Experience with system design and automation 

Nice-to-Haves

Familiarity with Flume and PubSub
Experience with CI/CD for ML pipelines
Knowledge of GCP ML Ops maturity levels and best practices

About Rakuten Kobo Inc.

Owned by Tokyo-based Rakuten and headquartered in Toronto, Rakuten Kobo Inc. is one of the most advanced global ecommerce companies, with the world’s most innovative e-reading services offering more than 6 million eBooks and audiobooks to 30 million + customers in 190 countries. Kobo delivers the best digital reading experience through creative innovation, award-winning e-readers, and top-ranking mobile apps. Kobo is a part of the Rakuten group of companies.

Rakuten Kobo Inc. is an equal opportunity employer. Accessibility accommodations for candidates with disabilities participating in the selection process are available on request. Any information received related to accommodation needs of applicants will be addressed confidentially.

Rakuten Kobo would like to thank all applicants for their interest in this role however only qualified candidates will be shortlisted.

Beware of fraudulent job offers claiming to be from Rakuten. Rakuten does not send unsolicited job offers or request money during the recruitment process. Learn more: https://rakutenemploymentalert.com/

#RKIND",[]
ML OPS Senior _ Groupe Technologique Création de contenu,Jobs for Humanity,,,"About the job
This job is sourced from a job board. Learn More
Le Content Creation Technology Group (CCTG) est à la recherche d'un ML Ops senior qui travaillera au sein d'une équipe qui développe des solutions d’apprentissage automatique pour améliorer l'expérience joueur, entre autres avec un projet sur des robots visant à simuler de vrais joueurs concurrents. Le rôle du ML Ops senior sera de définir les meilleures pratiques et les principes de conception pour aider l'équipe à livrer notre ambitieuse feuille de route de fonctionnalités.

Principales Responsabilités

Concevoir et développer des systèmes d'apprentissage automatique et des schémas basés sur les requis et les objectifs de l'entreprise.
Optimiser les solutions existantes pour améliorer les performances, l'évolutivité et l'efficacité.
Contribuer à l’industrialisation des projets d’apprentissage automatique, en se concentrant sur la création de pipelines et du déroulement des opérations de travail.
Adapter et améliorer l'utilisation des modèles, faciliter l'utilisation des outils et les adapter aux besoins des utilisateurs.
Créer des outils pour soutenir et intégrer les modèles d'apprentissage automatique dans un pipeline multi-processus.
Améliorer les librairies et frameworks d'apprentissage automatique existants.
Collaborer avec les équipes de production du jeu, l'équipe de science des données, l'équipe de recherche et d'autres parties prenantes.

Autres Responsabilités

Mener des recherches pour rester au courant des dernières avancées technologiques.
Documentation, présentations et partage des connaissances pour communiquer des concepts d'IA complexes aux collaborateurs techniques et non techniques.
Création de preuves de concepts pour satisfaire les exigences sur les orientations du produit.

Formation

Baccalauréat en informatique ou en génie informatique ou équivalent. Une spécialisation en apprentissage automatique est un atout.

Expérience Pertinente

Un minimum de 5 ans d'expérience en génie logiciel.
Un minimum de 2 ans d'expérience en apprentissage automatique.

Compétences

Une bonne connaissance d'un pipeline d'apprentissage automatique de production ; de la formation et du déploiement de l’apprentissage automatique au suivi de la performance des modèles/behavioral-drift.
Maîtrise de Python et expérience des librairies et frameworks tels que PyTorch et/ou TensorFlow.
Une bonne connaissance des plateformes MLOps telles que Databricks et/ou ClearML.
Une bonne connaissance de la technologie des conteneurs tels que Docker et/ou Kubernetes.
Une bonne connaissance des notions de base de l'apprentissage automatique et de l'apprentissage profond.
Une bonne connaissance des plateformes infonuagiques est un atout.
Une bonne connaissance des produits de base de données est un atout.

Jobs for Humanity is collaborating with Ubisoft to build an inclusive and just employment ecosystem. We support individuals coming from all walks of life.

Company Name: Ubisoft

Quoi nous envoyer

Votre CV mettant en valeur votre formation, votre expérience, vos compétences et les jeux livrés",[]
Principal Software Developer- MLOps Platform,Autodesk,"Vancouver, BC",Hybrid,"About the job
Job Requisition ID #

25WD87574

25WD87574, Principal Software Developer- MLOps Platform 

French translation to follow!/Traduction française à suivre!

Position Overview

We are looking for an experienced Principal Software Engineer to join our platform team focusing on AI/ML Platform (AMP). This team builds and maintains central components to fast track the development new ML/AI models such as model development studio, feature store, model serving, model observability.   Ideal candidate would have background in MLOps, Data engineering, DevOps with the experience of building high scale deployment architectures, observability. As an important contributor to our engineering team, you will help shape the future of our AI/ML capabilities, delivering solutions that inspire value for our organization. You will report to a manager.

Responsibilities

System design: You will design, implement and manage software systems for the AI/ML Platform, orchestrating the full ML development lifecycle for the partner teams
Mentoring: Spreading your knowledge, sharing best practices, doing design reviews to step up the expertise at the team level
Multi-cloud architecture: Define components which leverages strengths from multiple cloud platforms (e.g., AWS, Azure) to optimize performance, cost, and scalability
AI/ML observability: You will build systems for monitoring performance of AI/ML models and finding insights on the underlying data such as drift detection, data fairness/bias, anomalies  ML Solution Deployment: You will develop tools for building and deploying ML artifacts in production environments, facilitating a smooth transition from development to deployment 
Big Data Management: Automate and orchestrate tasks related to managing big data transformation and processing, building large-scale data stores for ML artifacts 
Scalable Services: Design and implement low-latency, scalable prediction, and inference services to support the diverse needs of our users 
Cross-Functional Collaboration: Collaborate across diverse teams, including machine learning researchers, developers, product managers, software architects, and operations, fostering a collaborative and cohesive work environment 
End-to-end ownership: You will take the end-to-end ownership of the components and work with other engineers in the team including design, architecture, implementation, rollout, onboarding support to partner teams, production on-call support, testing/verification, investigations etc. 

Minimum Qualifications

Educational Background: Bachelors degree in Computer Science or equivalent practical experience 
Experience: Over 8 years of experience in software development and engineering, delivering production systems and services 
Prior experience of working with MLOps team at the intersection of the expertise across ML model deployments, DevOps, data engineering
Hands-on skills: Ability to fluently translate the design into high quality code in golang, python, Java
Knowledge of DevOps practices, containerization, orchestration tools such as CI/CD, Terraform, Docker, Kubernetes, Gitops 
Demonstrated knowledge of distributed data processing frameworks, orchestrators, and data lake architectures using technologies such as Spark, Airflow, iceberg/ parquet formats
Prior collaborations with Data science teams to deploy their models, setting up ML observability for inference level monitoring
Exposure for building RAG based applications by collaborating with other product teams, Data scientists/AI engineers 
Demonstrated creative problem-solving skills with the ability to break down problems into manageable components
Knowledge of Amazon AWS and/or Azure cloud for solutioning large scale application deployments
Excellent communication and collaboration skills, fostering teamwork and effective information exchange 

Preferred Qualifications

 Experience of integrating with third party vendors
Experience in latency optimization with the ability to diagnose, tune, and enhance the efficiency of serving systems 
Familiarity with tools and frameworks for monitoring and managing the performance of AI/ML models in production (e.g., MLflow, Kubeflow, TensorBoard) 
Familiarity with distributed model training/inference pipelines using (KubeRay or equivalent) 
Exposure to leveraging GPU computing for AI/ML workloads, including experience with CUDA, OpenCL, or other GPU programming tools, to significantly enhance model training and inference performance 
Exposure to ML libraries such as PyTorch, TensorFlow, XGBoost, Pandas, and ScikitLearn

______________________________________________________________________________________________________________

25WD87574, Développeur principal de logiciels - Plateforme MLOps

Présentation du poste

Nous recherchons un ingénieur logiciel principal expérimenté pour rejoindre notre équipe de plateforme spécialisée dans la plateforme AI/ML (AMP). Cette équipe construit et maintient des composants centraux pour accélérer le développement de nouveaux modèles ML/AI tels que le studio de développement de modèles, le magasin de fonctionnalités, le service de modèles, l'observabilité des modèles.   Le candidat idéal aura une formation en MLOps, en ingénierie des données, en DevOps et une expérience dans la construction d'architectures de déploiement à grande échelle et l'observabilité. En tant que contributeur important à notre équipe d'ingénierie, vous contribuerez à façonner l'avenir de nos capacités en matière d'IA/ML, en fournissant des solutions qui inspirent de la valeur à notre organisation. Vous serez sous la responsabilité d'un manager.

Responsabilités

Conception de systèmes: vous concevrez, mettrez en œuvre et gérerez des systèmes logiciels pour la plateforme IA/ML, en orchestrant l'ensemble du cycle de développement de l'apprentissage automatique pour les équipes partenaires
Mentorat : vous diffuserez vos connaissances, partagerez les meilleures pratiques et effectuerez des revues de conception pour renforcer l'expertise au niveau de l'équipe
Architecture multi-cloud: vous définirez des composants qui tirent parti des atouts de plusieurs plateformes cloud (par exemple, AWS, Azure) pour optimiser les performances, les coûts et l'évolutivité
Observabilité de l'IA/ML: Vous construirez des systèmes pour surveiller les performances des modèles d'IA/ML et trouver des informations sur les données sous-jacentes telles que la détection de dérive, l'équité/biais des données, les anomalies Déploiement de solutions ML: Vous développerez des outils pour construire et déployer des artefacts ML dans des environnements de production, facilitant une transition en douceur du développement au déploiement
Gestion des Big Data: Automatiser et orchestrer les tâches liées à la gestion de la transformation et du traitement des Big Data, en construisant des magasins de données à grande échelle pour les artefacts ML
Services évolutifs: Concevoir et mettre en œuvre des services de prédiction et d'inférence évolutifs à faible latence pour répondre aux divers besoins de nos utilisateurs
Collaboration interfonctionnelle: Collaborer entre différentes équipes, y compris des chercheurs en apprentissage automatique, des développeurs, des chefs de produit, des architectes logiciels et des opérations, en favorisant un environnement de travail collaboratif et cohésif
Propriété de bout en bout: Vous serez responsable de bout en bout des composants et travaillerez avec d'autres ingénieurs de l'équipe, notamment pour la conception, l'architecture, la mise en œuvre, le déploiement, l'intégration des équipes partenaires, le support de production sur appel, les tests/vérifications, les investigations, etc.

Qualifications Minimales

Formation: Licence en informatique ou expérience pratique équivalente
Expérience: Plus de 8 ans d'expérience dans le développement et l'ingénierie de logiciels, la fourniture de systèmes et de services de production
Expérience préalable de travail avec l'équipe MLOps à l'intersection de l'expertise dans les déploiements de modèles ML, DevOps, ingénierie des données
Compétences pratiques: Capacité à traduire couramment la conception en code de haute qualité en golang, python, Java
Connaissance des pratiques DevOps, de la conteneurisation, des outils d'orchestration tels que CI/CD, Terraform, Docker, Kubernetes, Gitops
Connaissance avérée des cadres de traitement des données distribuées, des orchestrateurs et des architectures de lacs de données utilisant des technologies telles que Spark, Airflow, les formats iceberg/parquet
Collaborations antérieures avec des équipes de science des données pour déployer leurs modèles, en mettant en place l'observabilité ML pour la surveillance au niveau de l'inférence
Expérience dans la création d'applications basées sur RAG en collaborant avec d'autres équipes de produits, des scientifiques des données/ingénieurs en IA
Compétences démontrées en matière de résolution créative de problèmes, avec la capacité de décomposer les problèmes en composants gérables
Connaissance d'Amazon AWS et/ou du cloud Azure pour la résolution de problèmes de déploiement d'applications à grande échelle
Excellentes compétences en communication et en collaboration, favorisant le travail d'équipe et l'échange efficace d'informations

Qualifications Préférées

Expérience de l'intégration avec des fournisseurs tiers
Expérience de l'optimisation de la latence avec la capacité de diagnostiquer, d'ajuster et d'améliorer l'efficacité des systèmes de service
Connaissance des outils et des cadres de travail pour la surveillance et la gestion des performances des modèles d'IA/AA en production (par exemple, MLflow, Kubeflow, TensorBoard)
Connaissance des pipelines distribués d'entraînement/inférence de modèles utilisant (KubeRay ou équivalent)
Expérience de l'utilisation du calcul GPU pour les charges de travail d'IA/AA, y compris l'expérience de CUDA, OpenCL ou d'autres outils de programmation GPU, pour améliorer considérablement les performances d'entraînement et d'inférence des modèles
Expérience avec des bibliothèques d'apprentissage automatique telles que PyTorch, TensorFlow, XGBoost, Pandas et ScikitLearn

Learn More / Plus d'information

About Autodesk / À Propos D’Autodesk

Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.

We take great pride in our culture here at Autodesk – our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers.

When you’re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us!

Bienvenue à Autodesk ! Des choses incroyables sont créées chaque jour avec nos logiciels - des bâtiments les plus écologiques et des voitures les plus propres aux usines les plus intelligentes et aux plus grands films à succès. Nous aidons les innovateurs à transformer leurs idées en réalité, transformant non seulement la façon dont les choses sont faites, mais ce qui peut être fait.

Nous sommes très fiers de notre culture ici chez Autodesk - notre code en matière de culture est au cœur de tout ce que nous faisons. Nos valeurs et nos méthodes de travail aident nos employés à prospérer et à réaliser leur potentiel, ce qui conduit à des résultats encore meilleurs pour nos clients.

Lorsque vous êtes un employé Autodesk, vous pouvez être entier et authentique et effectuer un travail significatif qui aide à construire un avenir meilleur pour tous. Prêt à façonner le monde et votre avenir? Joignez-vous à nous !

Salary transparency / Transparence salariale

Salary is one part of Autodesk’s competitive compensation package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package.

Le salaire est l'un des éléments de l'offre compétitive d'Autodesk. Les offres sont basées sur l'expérience et la situation géographique du candidat. Outre les salaires de base, nous accordons également une grande importance aux primes annuelles discrétionnaires en espèces, aux commissions pour les fonctions de vente, aux actions ou aux primes d'encouragement à long terme en espèces, ainsi qu'à un ensemble complet d'avantages sociaux.

Diversity & Belonging / Diversité et appurtenance

We take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging

Nous sommes fiers de cultiver une culture d’appartenance et un milieu de travail équitable où tout le monde peut s’épanouir. Pour en savoir plus, cliquez ici : https://www.autodesk.com/company/diversity-and-belonging

Are you an existing contractor or consultant with Autodesk? 

Êtes-vous un sous-traitant ou un consultant existant d’Autodesk ?

Please search for open jobs and apply internally (not on this external site).

Veuillez rechercher des emplois vacants et postuler à l’interne (pas sur ce site externe).",[]
GenAI ML/MLOps Engineering Lead (Remote or Hybrid),S&P Global,,,"About the job
About The Role:

Grade Level (for internal use):

11

About The Role:

We are seeking a Lead/Associate Director of ML & MLOps Engineering - GenAI to join our ML team within the Data Science COE at S&P Global focusing on building Generative AI solutions.

You will lead the engineering activities for building production grade generative AI solutions, play a pivotal role in implementing our machine learning engineering operations to ensure the seamless deployment, monitoring, and management of our machine learning models and data pipelines.

The Team:

You will be work closely in a world class AI ML team comprised of experts in AI ML modeling, ML & LLMOps engineers, data science and data engineering teams. You will contribute to engineering and developing solutions for ML operations and be a critical part of leading S&P’s AI-driven transformation to drive value internally and for our customers.

S&P is a leader in automation and AI/ML to transform risk management. This role is a unique opportunity for ML/MLOps engineers to grow into the next step in their career journey.

Responsibilities And Impact:

Lead ML Engineering to architect, build and deploy production grade GenAI services and solutions.
Work on large-scale stateful and stateless distributed systems, including infrastructure, data ingestion platforms, SQL and no-SQL databases, microservices, orchestration services and more.
Lead MLOps/LLMOps platform development & automated pipelines focusing on deploying, monitoring and maintaining models in production environments; with model governance, cost and performance optimization.
Collaborate with cross-functional teams to integrate machine learning models into production systems.
Create and manage Documentation and knowledge base, including development best practices, MLOps/LLMOps processes and procedures.
Work closely with members of technology teams in the development, and implementation of Enterprise AI platform.

Compensation/Benefits Information: (This section is only applicable to US candidates)

S&P Global states that the anticipated base salary range for this position is $108,000 to $215,000. Final base salary for this role will be based on the individual’s geographic location, as well as experience level, skill set, training, licenses and certifications.

In addition to base compensation, this role is eligible for an annual incentive plan.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, please click here.

What We’re Looking For:

Basic Required Qualifications:

Bachelor's degree in Computer Science, Engineering, or a related field.
8+ years of progressive experience as in machine learning, data analytics or similar roles.
5 years of relevant experience with
Writing production level, scalable code with Python (or scala)
MLOps/LLMOps, machine learning engineering, Big Data, or a related role.
Elasticsearch, SQL, NoSQL, Apache Airflow, Databricks, MLflow.
Containerization, cloud platforms, CI/CD and workflow orchestration tools.
Distributed systems programming, AI/ML solutions architecture, Microservices architecture experience.
Additional Preferred Qualifications:

2-3 years of experience with operationalizing data-driven pipelines for large scale batch and stream processing analytics solutions
Experience with contributing to open-source initiatives or in research projects and/or participation in Kaggle competitions
6-12 months of experience working with RAG pipelines, prompt engineering and/or Generative AI use cases.
Experience with SageMaker and/or Vertex AI

Return To Work: 

Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative, Restart, we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace.

About S&P Global Ratings

At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions.

S&P Global Ratings is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit www.spglobal.com/ratings

What’s In It For You?

Our Purpose:

Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:

We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.

Our Values:

Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits: 

We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our Benefits Include:

Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.

For more information on benefits by country visit: https://spgbenefits.com/benefit-summaries

Global Hiring And Opportunity At S&P Global:

At S&P Global, we are committed to fostering a connected and engaged workplace where all individuals have access to opportunities based on their skills, experience, and contributions. Our hiring practices emphasize fairness, transparency, and merit, ensuring that we attract and retain top talent. By valuing different perspectives and promoting a culture of respect and collaboration, we drive innovation and power global markets.

S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.

Recruitment Fraud Alert:

If you receive an email from a spglobalind.com domain or any other regionally based domains, it is a scam and should be reported to reportfraud@spglobal.com. S&P Global never requires any candidate to pay money for job applications, interviews, offer letters, “pre-employment training” or for equipment/delivery of equipment. Stay informed and protect yourself from recruitment fraud by reviewing our guidelines, fraudulent domains, and how to report suspicious activity here.

Equal Opportunity Employer

S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. 

US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. Pay Transparency Nondiscrimination Provision - https://www.dol.gov/sites/dolgov/files/ofccp/pdf/pay-transp_%20English_formattedESQA508c.pdf

IFTECH202.2 - Middle Professional Tier II (EEO Job Group)

Job ID: 312048

Posted On: 2025-06-26

Location: New York, New York, United States",[]
Principal Software Developer- MLOps Platform,Autodesk,"Montreal, QC",Hybrid,"About the job
Job Requisition ID #

25WD87574

25WD87574, Principal Software Developer- MLOps Platform 

French translation to follow!/Traduction française à suivre!

Position Overview

We are looking for an experienced Principal Software Engineer to join our platform team focusing on AI/ML Platform (AMP). This team builds and maintains central components to fast track the development new ML/AI models such as model development studio, feature store, model serving, model observability.   Ideal candidate would have background in MLOps, Data engineering, DevOps with the experience of building high scale deployment architectures, observability. As an important contributor to our engineering team, you will help shape the future of our AI/ML capabilities, delivering solutions that inspire value for our organization. You will report to a manager.

Responsibilities

System design: You will design, implement and manage software systems for the AI/ML Platform, orchestrating the full ML development lifecycle for the partner teams
Mentoring: Spreading your knowledge, sharing best practices, doing design reviews to step up the expertise at the team level
Multi-cloud architecture: Define components which leverages strengths from multiple cloud platforms (e.g., AWS, Azure) to optimize performance, cost, and scalability
AI/ML observability: You will build systems for monitoring performance of AI/ML models and finding insights on the underlying data such as drift detection, data fairness/bias, anomalies  ML Solution Deployment: You will develop tools for building and deploying ML artifacts in production environments, facilitating a smooth transition from development to deployment 
Big Data Management: Automate and orchestrate tasks related to managing big data transformation and processing, building large-scale data stores for ML artifacts 
Scalable Services: Design and implement low-latency, scalable prediction, and inference services to support the diverse needs of our users 
Cross-Functional Collaboration: Collaborate across diverse teams, including machine learning researchers, developers, product managers, software architects, and operations, fostering a collaborative and cohesive work environment 
End-to-end ownership: You will take the end-to-end ownership of the components and work with other engineers in the team including design, architecture, implementation, rollout, onboarding support to partner teams, production on-call support, testing/verification, investigations etc. 

Minimum Qualifications

Educational Background: Bachelors degree in Computer Science or equivalent practical experience 
Experience: Over 8 years of experience in software development and engineering, delivering production systems and services 
Prior experience of working with MLOps team at the intersection of the expertise across ML model deployments, DevOps, data engineering
Hands-on skills: Ability to fluently translate the design into high quality code in golang, python, Java
Knowledge of DevOps practices, containerization, orchestration tools such as CI/CD, Terraform, Docker, Kubernetes, Gitops 
Demonstrated knowledge of distributed data processing frameworks, orchestrators, and data lake architectures using technologies such as Spark, Airflow, iceberg/ parquet formats
Prior collaborations with Data science teams to deploy their models, setting up ML observability for inference level monitoring
Exposure for building RAG based applications by collaborating with other product teams, Data scientists/AI engineers 
Demonstrated creative problem-solving skills with the ability to break down problems into manageable components
Knowledge of Amazon AWS and/or Azure cloud for solutioning large scale application deployments
Excellent communication and collaboration skills, fostering teamwork and effective information exchange 

Preferred Qualifications

 Experience of integrating with third party vendors
Experience in latency optimization with the ability to diagnose, tune, and enhance the efficiency of serving systems 
Familiarity with tools and frameworks for monitoring and managing the performance of AI/ML models in production (e.g., MLflow, Kubeflow, TensorBoard) 
Familiarity with distributed model training/inference pipelines using (KubeRay or equivalent) 
Exposure to leveraging GPU computing for AI/ML workloads, including experience with CUDA, OpenCL, or other GPU programming tools, to significantly enhance model training and inference performance 
Exposure to ML libraries such as PyTorch, TensorFlow, XGBoost, Pandas, and ScikitLearn

______________________________________________________________________________________________________________

25WD87574, Développeur principal de logiciels - Plateforme MLOps

Présentation du poste

Nous recherchons un ingénieur logiciel principal expérimenté pour rejoindre notre équipe de plateforme spécialisée dans la plateforme AI/ML (AMP). Cette équipe construit et maintient des composants centraux pour accélérer le développement de nouveaux modèles ML/AI tels que le studio de développement de modèles, le magasin de fonctionnalités, le service de modèles, l'observabilité des modèles.   Le candidat idéal aura une formation en MLOps, en ingénierie des données, en DevOps et une expérience dans la construction d'architectures de déploiement à grande échelle et l'observabilité. En tant que contributeur important à notre équipe d'ingénierie, vous contribuerez à façonner l'avenir de nos capacités en matière d'IA/ML, en fournissant des solutions qui inspirent de la valeur à notre organisation. Vous serez sous la responsabilité d'un manager.

Responsabilités

Conception de systèmes: vous concevrez, mettrez en œuvre et gérerez des systèmes logiciels pour la plateforme IA/ML, en orchestrant l'ensemble du cycle de développement de l'apprentissage automatique pour les équipes partenaires
Mentorat : vous diffuserez vos connaissances, partagerez les meilleures pratiques et effectuerez des revues de conception pour renforcer l'expertise au niveau de l'équipe
Architecture multi-cloud: vous définirez des composants qui tirent parti des atouts de plusieurs plateformes cloud (par exemple, AWS, Azure) pour optimiser les performances, les coûts et l'évolutivité
Observabilité de l'IA/ML: Vous construirez des systèmes pour surveiller les performances des modèles d'IA/ML et trouver des informations sur les données sous-jacentes telles que la détection de dérive, l'équité/biais des données, les anomalies Déploiement de solutions ML: Vous développerez des outils pour construire et déployer des artefacts ML dans des environnements de production, facilitant une transition en douceur du développement au déploiement
Gestion des Big Data: Automatiser et orchestrer les tâches liées à la gestion de la transformation et du traitement des Big Data, en construisant des magasins de données à grande échelle pour les artefacts ML
Services évolutifs: Concevoir et mettre en œuvre des services de prédiction et d'inférence évolutifs à faible latence pour répondre aux divers besoins de nos utilisateurs
Collaboration interfonctionnelle: Collaborer entre différentes équipes, y compris des chercheurs en apprentissage automatique, des développeurs, des chefs de produit, des architectes logiciels et des opérations, en favorisant un environnement de travail collaboratif et cohésif
Propriété de bout en bout: Vous serez responsable de bout en bout des composants et travaillerez avec d'autres ingénieurs de l'équipe, notamment pour la conception, l'architecture, la mise en œuvre, le déploiement, l'intégration des équipes partenaires, le support de production sur appel, les tests/vérifications, les investigations, etc.

Qualifications Minimales

Formation: Licence en informatique ou expérience pratique équivalente
Expérience: Plus de 8 ans d'expérience dans le développement et l'ingénierie de logiciels, la fourniture de systèmes et de services de production
Expérience préalable de travail avec l'équipe MLOps à l'intersection de l'expertise dans les déploiements de modèles ML, DevOps, ingénierie des données
Compétences pratiques: Capacité à traduire couramment la conception en code de haute qualité en golang, python, Java
Connaissance des pratiques DevOps, de la conteneurisation, des outils d'orchestration tels que CI/CD, Terraform, Docker, Kubernetes, Gitops
Connaissance avérée des cadres de traitement des données distribuées, des orchestrateurs et des architectures de lacs de données utilisant des technologies telles que Spark, Airflow, les formats iceberg/parquet
Collaborations antérieures avec des équipes de science des données pour déployer leurs modèles, en mettant en place l'observabilité ML pour la surveillance au niveau de l'inférence
Expérience dans la création d'applications basées sur RAG en collaborant avec d'autres équipes de produits, des scientifiques des données/ingénieurs en IA
Compétences démontrées en matière de résolution créative de problèmes, avec la capacité de décomposer les problèmes en composants gérables
Connaissance d'Amazon AWS et/ou du cloud Azure pour la résolution de problèmes de déploiement d'applications à grande échelle
Excellentes compétences en communication et en collaboration, favorisant le travail d'équipe et l'échange efficace d'informations

Qualifications Préférées

Expérience de l'intégration avec des fournisseurs tiers
Expérience de l'optimisation de la latence avec la capacité de diagnostiquer, d'ajuster et d'améliorer l'efficacité des systèmes de service
Connaissance des outils et des cadres de travail pour la surveillance et la gestion des performances des modèles d'IA/AA en production (par exemple, MLflow, Kubeflow, TensorBoard)
Connaissance des pipelines distribués d'entraînement/inférence de modèles utilisant (KubeRay ou équivalent)
Expérience de l'utilisation du calcul GPU pour les charges de travail d'IA/AA, y compris l'expérience de CUDA, OpenCL ou d'autres outils de programmation GPU, pour améliorer considérablement les performances d'entraînement et d'inférence des modèles
Expérience avec des bibliothèques d'apprentissage automatique telles que PyTorch, TensorFlow, XGBoost, Pandas et ScikitLearn

Learn More / Plus d'information

About Autodesk / À Propos D’Autodesk

Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.

We take great pride in our culture here at Autodesk – our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers.

When you’re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us!

Bienvenue à Autodesk ! Des choses incroyables sont créées chaque jour avec nos logiciels - des bâtiments les plus écologiques et des voitures les plus propres aux usines les plus intelligentes et aux plus grands films à succès. Nous aidons les innovateurs à transformer leurs idées en réalité, transformant non seulement la façon dont les choses sont faites, mais ce qui peut être fait.

Nous sommes très fiers de notre culture ici chez Autodesk - notre code en matière de culture est au cœur de tout ce que nous faisons. Nos valeurs et nos méthodes de travail aident nos employés à prospérer et à réaliser leur potentiel, ce qui conduit à des résultats encore meilleurs pour nos clients.

Lorsque vous êtes un employé Autodesk, vous pouvez être entier et authentique et effectuer un travail significatif qui aide à construire un avenir meilleur pour tous. Prêt à façonner le monde et votre avenir? Joignez-vous à nous !

Salary transparency / Transparence salariale

Salary is one part of Autodesk’s competitive compensation package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package.

Le salaire est l'un des éléments de l'offre compétitive d'Autodesk. Les offres sont basées sur l'expérience et la situation géographique du candidat. Outre les salaires de base, nous accordons également une grande importance aux primes annuelles discrétionnaires en espèces, aux commissions pour les fonctions de vente, aux actions ou aux primes d'encouragement à long terme en espèces, ainsi qu'à un ensemble complet d'avantages sociaux.

Diversity & Belonging / Diversité et appurtenance

We take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging

Nous sommes fiers de cultiver une culture d’appartenance et un milieu de travail équitable où tout le monde peut s’épanouir. Pour en savoir plus, cliquez ici : https://www.autodesk.com/company/diversity-and-belonging

Are you an existing contractor or consultant with Autodesk? 

Êtes-vous un sous-traitant ou un consultant existant d’Autodesk ?

Please search for open jobs and apply internally (not on this external site).

Veuillez rechercher des emplois vacants et postuler à l’interne (pas sur ce site externe).",[]
Senior Machine Learning Engineer,Loblaw Digital,,,"About the job
Come make your difference in communities across Canada, where authenticity, trust and making connections is valued – as we shape the future of Canadian retail, together. Our unique position as one of the country's largest employers, coupled with our commitment to positively impact the lives of all Canadians, provides our colleagues a range of opportunities and experiences to help Canadians Live Life Well®.

At Loblaw Companies Limited, we succeed through collaboration and commitment and set a high bar for ourselves and those around us. Whether you are just starting your career, re-entering the workforce, or looking for a new job, this is where you belong.

At Loblaw Digital, we know that our customers expect the best from us. Whether that means building the best, most innovative online shopping experiences, or designing an app that will impact the lives of people across the country, we’re up for the challenge. Loblaw Digital is the team responsible for building and operating the online businesses of Canada’s largest and most successful retailer. Based in downtown Toronto, we are an entrepreneurial, fast-paced, and collaborative team working towards transforming the way Canadians shop by creating leading eCommerce experiences in the online grocery shopping, beauty, pharmacy, loyalty, and apparel spaces, and we’re only just getting started! To achieve these goals, we are looking for talented and passionate individuals who want to collaborate and solve challenging problems and make a significant and lasting impact on Canadians.

As a Senior Machine Learning Engineer in the Retail Media domain, you will use an abundance of data from the Loblaw enterprise in order to build machine learning solutions. Your team will collaborate with business stakeholders and engineers within Loblaw Digital to deliver models to production that help in driving our AdTech and E-commerce business. You will design experiments to measure your success with KPIs that include adoption, conversion & retention. You will use data every single day to uncover meaningful insights that inform your experimentation strategy and ultimately, your product roadmap.

What You’ll Do

Design, build, and maintain highly scalable, robust, and efficient cloud infrastructure using Google Cloud Platform (GCP) services, including Vertex AI, BigTable, BigQuery, AlloyDB, and Cloud Composer.
Develop automation and orchestration of ML pipelines, integrating data ingestion, feature engineering, training, and deployment processes.
Collaborate with cross-functional teams to understand their needs and build solutions that improve platform usability, scalability, and the overall development experience.
Optimize data processing pipelines and cloud resources to ensure low-latency, cost-effective operation.
Implement monitoring, alerting, and failover strategies to ensure platform reliability.
Stay updated with industry trends and best practices in cloud engineering, data engineering, and machine learning

What You'll Bring

Customer-centric mindset: Passionate about delivering an exceptional experience for data scientists through a self-service platform, reducing friction in their workflows.
Collaboration: Strong communication skills to work closely with cross-functional teams, including data scientists and engineers, to ensure platform features meet user needs and expectations.
Problem-solving: Ability to identify and solve complex technical issues related to ML pipelines, cloud infrastructure, and scalability, ensuring an efficient and robust platform.
Automation-first approach: Commitment to streamlining and automating processes for scalability and reliability, enabling data scientists to focus on experimentation and model development.
Adaptability: Ability to quickly adjust to new technologies and evolving platforms needs to keep the infrastructure cutting-edge and efficient.
Ownership and initiative: Comfortable taking ownership of key platform components, driving innovation and improvements that benefit the platform’s scalability and usability.
Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field.
2+ years of experience in software engineering with a focus on cloud infrastructure and/or data engineering.
Hands-on experience with Google Cloud Platform services such as Vertex AI, BigTable, BigQuery, Cloud Composer, Cloud Storage, etc.
Proficiency in one or more programming languages such as Python, Java, and SQL.
Experience with orchestration tools such as Apache Airflow (Composer).
Knowledge of CI/CD pipelines and DevOps tools for continuous integration and deployment.
Familiarity with containerization and orchestration (Docker, Kubernetes).
Strong problem-solving skills and attention to detail.
Excellent communication skills and ability to work in a collaborative, fast-paced environment

Our commitment to Sustainability and Social Impact is an essential part of the way we do business, and we focus our attention on areas where we can have the greatest impact. Our approach to sustainability and social impact is based on three pillars – Environment, Sourcing and Community – and we are constantly looking for ways to demonstrate leadership in these important areas. Our CORE Values – Care, Ownership, Respect and Excellence – guide all our decision-making and come to life through our Blue Culture. We offer our colleagues progressive careers, comprehensive training, flexibility, and other competitive benefits – these are some of the many reasons why we are one of Canada’s Top Employers, Canada’s Best Diversity Employers, Canada’s Greenest Employers & Canada’s Top Employers for Young People.

If you are unsure whether your experience matches every requirement above, we encourage you to apply anyway. We are looking for varied perspectives which include diverse experiences that we can add to our team.

We have a long-standing focus on diversity, equity and inclusion because we know it will make our company a better place to work and shop. We are committed to creating accessible environments for our colleagues, candidates and customers. Requests for accommodation due to a disability (which may be visible or invisible, temporary or permanent) can be made at any stage of application and employment. We encourage candidates to make their accommodation needs known so that we can provide equitable opportunities.

Please Note:

Candidates who are 18 years or older are required to complete a criminal background check. Details will be provided through the application process.

#EN

#SS #LD #ON",[]
Intermediate II DevOps/MLOps,Global Relay,"Vancouver, BC",Hybrid,"About the job
Who we are:

For over 20 years, Global Relay has set the standard in enterprise information archiving with industry-leading cloud archiving, surveillance, eDiscovery, and analytics solutions. We securely capture and preserve the communications data of the world’s most highly regulated firms, giving them greater visibility and control over their information and ensuring compliance with stringent regulations.

Though we offer competitive compensation and benefits and all the other perks one would expect from an established company, we are not your typical technology company. Global Relay is a career-building company. A place for big ideas. New challenges. Groundbreaking innovation. It’s a place where you can genuinely make an impact – and be recognized for it.

We believe great businesses thrive on diversity, inclusion, and the contributions of all employees. To that end, we recruit candidates from different backgrounds and foster a work environment that encourages employees to collaborate and learn from each other, completely free of barriers.

Your role:

As an Intermediate II DevOps/MLOps on our Artificial Intelligence team you will be responsible for the reliability and smooth operation of various environments and build automation to improve reliability and efficiency of code and machine learning model delivery from build to production. Challenge yourself by learning new technologies, and apply your skills across our different projects and application domains. You'll get to work in the exciting field of MLOps and will have the opportunity to work with tools unique to machine learning and artificial intelligence.

At Global Relay we use leading edge technologies to deploy and manage the infrastructure that delivers highly scalable and available services. The role involves cross-team collaboration and communication; you will be working closely with key stakeholders to ensure that product requirements are met. This is an opportunity to influence the design and implementation of systems at scales that many do not get a chance to work at.

Your responsibilities: 


Automation: Developing tools & frameworks to enhance our CI (Continuous Integration) & CD (Continuous Delivery) automation using industry standard CI/CD practices.
Deployments: Leveraging the above mentioned CI/CD automation to deploy our services to Kubernetes. 
Operations: Monitor and ensure smooth operation of our services in various environments.
Service Reliability: Occasionally provide support and initial troubleshooting when required by reviewing dashboards and logs to ensure system issues are timely addressed.


About you: 


3-5 years experience in a DevOps/MLOps or in a similar role.
Bachelor's degree in computer science or related field, or equivalent work experience.
Understanding of computer science fundamentals like threading, OOP and more.
Understanding of software systems concepts such as networking, firewalls, protocols, databases and more.
Understanding of software delivery practices such as Git branching models, configuration management, secret rotation, feature toggling, no-downtime deployments, and more.
Experience mentoring Junior DevOps/MLOps.
Strong organizational and communication skills.
Experience with:
CI/CD tools such as Jenkins.
Containerization technology such as; Docker, Kubernetes.
Python or other similar scripting languages.
Databases such as; CockroachDB, PostgreSQL. 
Distributed event streaming platforms such as; Kafka.
Instrumentation & Monitoring tools such as: Splunk, Loki, Zabbix, or Prometheus.
Package managers and artifact repositories such as: Artifactory, npm.
Mentoring Junior DevOps/MLOps.


Nice-to-haves:


Artificial intelligence or machine learning tools such as; MLFlow, JupyterHub, DVC, TensorFlow.
Supporting containerized GPU workloads in Kubernetes.
NoSQL data stores, including vector databases.
Supporting Large Language Models.


Compensation:

Global Relay advertises the pay range for this role in compliance with British Columbia’s pay transparency laws. Individual pay rates are determined by evaluating factors such as expertise, skills, education, and professional background.

The range below reflects the expected annual base salary, which is only one element of our comprehensive total rewards package designed to reflect our company pay philosophy, culture and values. We aim to foster an inspiring work environment and support employees' work-life rhythms. We provide a comprehensive extended health benefits program, including virtual healthcare and a wellness allowance. Employees also receive annual allotted vacation days, which increase based on tenure. Other benefits include: Paid sick days, maternity/parental enhancement program, corporate bonuses, and an RRSP contribution matching program.

For Vancouver-based employees, we provide a subsidized meal program, courtesy of our talented in-house culinary team!

British Columbia - Base Salary Range:

$80,000—$100,000 CAD

What you can expect:

At Global Relay, there’s no ceiling to what you can achieve. It’s the land of opportunity for the energetic, the intelligent, the driven. You’ll receive the mentoring, coaching, and support you need to reach your career goals. You’ll be part of a culture that breeds creativity and rewards perseverance and hard work. And you’ll be working alongside smart, talented individuals from diverse backgrounds, with complementary knowledge and skills.

Global Relay is an equal-opportunity employer committed to diversity, equity, and inclusion.

We seek to ensure reasonable adjustments, accommodations, and personal time are tailored to meet the unique needs of every individual.

We understand flexible work arrangements are important, and we encourage that in our work culture. Whether it’s flexibility around work hours, workstyle, or lifestyle, we want to ensure our employees have a healthy work/life balance. We support and value a hybrid work model that blends collaboration with the team in the office and focus time from the comfort of your home.

To learn more about our business, culture, and community involvement, visit www.globalrelay.com.",[]
Machine Learning Ops / AI Ops Engineer,Haptiq,"Toronto, ON",Hybrid,"About the job
Overview
Haptiq is a leader in AI-powered enterprise operations, delivering digital solutions and consulting services that drive value and transform businesses. We specialize in using advanced technology to streamline operations, improve efficiency, and unlock new revenue opportunities, particularly within the private capital markets. Our integrated ecosystem includes the Core Platform, an AI-native enterprise operations foundation built to optimize workflows, surface insights, and accelerate value creation across portfolios; Olympus Software, a cloud platform delivering unmatched performance, intelligence, and execution at scale; and the Pantheon Solutions Suite, modular technology playbooks designed to manage, grow, and optimize company performance. With over a decade of experience supporting high-growth companies and private equity-backed platforms, Haptiq brings deep domain expertise and a proven ability to turn technology intoa strategic advantage.

About the Role
We’re seeking a skilled MLOps / AIOps Engineer to lead the deployment, operation, and monitoring of AI services in production. You’ll operate at the intersection of infrastructure engineering and AI systems, ensuring our AI-powered APIs, RAG pipelines, MCPs, and agentic services run reliably, securely, and at scale. You’ll collaborate closely with ML Engineers, Python Developers, and AI Architects to design resilient infrastructure and operational workflows for distributed AI applications.

Key Responsibilities
Design, provision, and maintain infrastructure-as-code for AI service deployment (using tools like Terraform, Pulumi, AWS CDK).
Build and manage CI/CD pipelines for deploying AI APIs, RAG pipelines, MCP services, and LLM agent workflows.
Implement and maintain operational and LLM observability through monitoring and alerting systems.
Track AI-specific operational metrics, including inference latency, error rates, drift detection, and hallucination monitoring.
Optimize inference workloads and manage distributed AI serving frameworks (Ray Serve, BentoML, vLLM, Hugging Face TGI, etc.).
Collaborate with ML Engineers and Python Developers to define scalable, secure, and automated deployment processes.
Enforce operational standards for AI system security, data governance, and compliance.
Stay current with evolving AIOps and LLM observability frameworks, integrating emerging tools and best practices into our stack.

Required Skills & Experience
Proficiency with cloud infrastructure (AWS, Azure, or GCP) and container orchestration platforms (Docker, Kubernetes, ECS/EKS).
Hands-on experience deploying and managing AI/ML services in production.
Strong understanding of CI/CD pipelines for AI services, LLM workflows, and model deployments.
Experience working with distributed AI serving frameworks and inference optimization strategies.
Solid grasp of observability practices, operational monitoring, incident response, and AI-specific performance tracking.
Familiarity with defining and maintaining AI system health metrics, dashboards, and alerts.
Awareness of AI security considerations, data protection policies, and operational governance requirements.
Curiosity and openness to adopting emerging AIOps, LLM observability, and AI infrastructure tools.

Salary range $120,000- $140,000 CAD

Benefits 
Flexible work arrangements (including hybrid mode)
Great Paid Time Off (PTO) policy
Comprehensive benefits package
Competitive salary
Opportunities for professional growth and development.
A supportive, dynamic, and inclusive work environment.

Why Join Us?
We value creative problem solvers who learn fast, work well in an open and diverse environment and enjoy pushing the bar for success ever higher. We do work hard but we also choose to have fun while doing it.",[]
DevOps Engineer 3 (ML Infra),Behavox,,,"About the job
About Behavox

Behavox is shaping the future for how businesses harness their most important raw material - data. Our mission is bold: Organize enterprise data into actionable information that protects and promotes the business growth of multinational companies around the world.

From managing enterprise risk and compliance to maximizing revenue and value, our data operating platform presents a widespread opportunity to build multilingual, AI/ML-based solutions that activate data for every function within a global enterprise.

Our approach is unique, and it’s validated by our customers who tell us to keep forging ahead because no one else is aggregating, analyzing, and acting on data to uncover opportunities or solve problems quite the way we are.

We are looking for fearless innovators who have an insatiable appetite for building what no one has built before.

About The Role

The Machine Learning Operations team at Behavox designs and builds the next-generation cutting-edge tooling, infrastructure, and web interfaces that enable the building of efficient ML models, including LLM. We are exposed to a wide range of interesting challenges that include (but are not limited to): building infrastructure that enables scalable development of ML models; building scalable and secure data infrastructure; development and deployment of ML services. As a DevOps Engineer, you will work on Kubernetes-based infrastructure in AWS and GCP, CI/CD/CT processes for ML models and services, data infrastructure. If you are interested in taking your career to the next level and building the next generation AI Infrastructure then this is the right place for you.

For the right Talent, this is a great opportunity because:

 It's a greenfield. Our team is young and we can choose any tools and frameworks that we consider the best ones to fulfill the requirements. 
 Huge impact. You will work on the ML and data infrastructure components that directly related to the efficiency of ML models - the heart of the company's success. 
 Visibility - all the services will be used by other departments immediately; you will have a lot of feedback. 

What You'll Bring

A deep and genuine interest in Behavox as demonstrated by a connection to its mission, marketplace and/or technologies

Linux system administration expertise, solid knowledge of Linux and networks

Designing and managing infrastructure in a public cloud (AWS, GCP)

Hands-on experience with Kubernetes

Development and scripting skills (Python, Bash)

What You'll Do

Manage and troubleshoot complex distributed large-scale software systems
Build scalable, secure and reliable container-based infrastructure
Design the cloud infrastructure
Automate software delivery processes with CI\CD pipelines
Develop tools, services, and scripts (Python)

What We Offer

A truly global mission with a passionate community in locations all over the world
The ability to have a high impact and learning potential as our aspirations require bold innovation
Highly competitive cash compensation package
Benefits include comprehensive health coverage for the employee and their family
Generous time-off policy (30 days annually) and flexible work schedule

About Our Process

We take Talent very seriously and we are building a community of extraordinary individuals working together in very high performing teams. We also know that the best Talent always has options so we believe that the process has to be a two way assessment - the company AND the candidate assessing the business needs alignment, the career next step alignment, and the cultural alignment.

During the process we will begin by exploring the core factors regarding salary and location along with core experience and skills and values alignment. We will then deep dive explore the critical technical competencies we have identified for the role, and then we will deep dive in behavioral competencies.

The most aligned candidate will then be asked to do a practical work task simulation activity so we can make sure that you will enjoy the kind of work the role requires, and this task will typically be presented and discussed with a group of colleagues and managers. Finally we will ask you to meet with a number of our senior leaders to make sure that you are making the most informed call possible. We may record interviews for training purposes.",[]
"MLOps Engineer (Java, Python, AWS)",Atimi Software,Canada,Remote,"About the job
Atimi is seeking an experienced MLOps Engineer to fill a position in Canada. Please note this is a fully remote position with EST working hours but we're open to candidates from all provinces. Atimi works with some of the leading companies in North America, providing them with high-quality software solutions that integrate both mobile and web experience. If you are a creative, self-motivated individual with vast user experience working with complex problems, Atimi is the place for You. We are looking for an established leader in the domain with solid experience in software development principles, hands-on knowledge of the latest cloud technologies and soft skills. You work well with colleagues, partners and clients and have great communication skills.

Responsibilities

Proactive collaboration in the project team to help develop the product using your experience to help guide the team through the entire development lifecycle 
Ensuring code quality and governance 
Ensuring engineers follow any patterns/designs set out and agreed with project leads
Planning, estimating, and contributing to the architecture, coding, and development 
Refactoring and continuous improvements of the codebases 
Ensuring that technical decisions and information are communicated thoroughly to the global team 
Taking responsibility for releases and contributing to the ongoing support of live apps 
Looking beyond pure programming, get involved with the deployment and operation of the software we build (DevOps) 
Delivering fair outcomes for our customers, ensuring conduct maintains a high level of professionalism


Requirements


Basic qualifications

Strong Java experience (5+ years)
Experience with LLM optimization
Experience setting ML pipelines and infrastructure
Experience with Python (3+ years) 
Experience with AWS EC2, ECS, CDK, Lambda, S3
Experience with DynamoDB and SQL
Experience with using and/or configuring CI/CD pipelines
Experience building Gen AI-based applications 
Knowledge of SOLID principles and design patterns
Experience working directly with clients and other project stakeholders to define and refine requirements
Strong English skills (written and verbal.)


Preferred Qualifications

Experience with PyTorch
Experience with PySpark
Experience with REST Integrations
Experience with GraphQL Integrations
Experience with gRPC Integrations
Experience with MCP (Model Context Protocol)
Experience with DDD (Domain Driven Design)
Experience with TDD (Test Driven Development)


The position is open to anyone, but you must be located in Canada. Relocation support is not provided.

Please submit your resume and cover letter for review. All applications will be reviewed, but only those who are able to demonstrate the right skills will be contacted for a remote interview.

Benefits

Why Work for Atimi?

Find the work-life balance you have been craving with a flexible schedule, generous time off convenient commute to work or the option to work from home. Join a team where fun is encouraged with team-building activities and online Company events. You can also expect generous compensation along with awesome benefits, so come to work in your comfy clothes, make yourself a cup of fresh ground coffee, and dive into your amazing career.

About Atimi Software

Hello, we're Atimi. If you've got a smartphone or a computer, you've seen our work. You may not know our name, but you use our software - whether it's on Apple or Android devices, you're already familiar with what we do. You just don't know it yet. We work with high-profile companies that want to extend their brand reach. Our clients hire us to do the flagship work for major brands. We know what it takes to get noticed: over 60% of our apps have been featured by Apple in TV ads, iTunes advertising, and in-store or in print ads. We work with Fortune 500 companies who want to be recognized for being innovative and want to ensure a true brand experience at every customer touch-point.

Fundamentally, Atimi believes in compensating people based on the value they provide. All of us are evaluated on the core skills we are able to demonstrate when doing our job. Once you demonstrate new skills, there's no reason that shouldn't be recognized. We want to provide developers with fast-moving, cutting-edge projects where everybody has a voice, and nobody is concerned with ego or internal politics, so all of us are challenged to improve constantly.

About The Interview Process

The interview process for this position involves multiple stages that cover:

Communication and soft-skills skills evaluation
Technical evaluation of general software development principles
Practical evaluation (live coding exercise) in Java
Practical evaluation (live coding exercise) in Python
Cultural fit with other team members 


About Salary And Compensation

The salary for this position is based on the Atimi Salary Grid, ranges between 128k and 183k per annum and depends on the individual's experience and performance during the interview.",[]
DevOps Engineer 3 (ML Infra),Behavox,,,"About the job
About Behavox

Behavox is shaping the future for how businesses harness their most important raw material - data. Our mission is bold: Organize enterprise data into actionable information that protects and promotes the business growth of multinational companies around the world.

From managing enterprise risk and compliance to maximizing revenue and value, our data operating platform presents a widespread opportunity to build multilingual, AI/ML-based solutions that activate data for every function within a global enterprise.

Our approach is unique, and it’s validated by our customers who tell us to keep forging ahead because no one else is aggregating, analyzing, and acting on data to uncover opportunities or solve problems quite the way we are.

We are looking for fearless innovators who have an insatiable appetite for building what no one has built before.

About The Role

The Machine Learning Operations team at Behavox designs and builds the next-generation cutting-edge tooling, infrastructure, and web interfaces that enable the building of efficient ML models, including LLM. We are exposed to a wide range of interesting challenges that include (but are not limited to): building infrastructure that enables scalable development of ML models; building scalable and secure data infrastructure; development and deployment of ML services. As a DevOps Engineer, you will work on Kubernetes-based infrastructure in AWS and GCP, CI/CD/CT processes for ML models and services, data infrastructure. If you are interested in taking your career to the next level and building the next generation AI Infrastructure then this is the right place for you.

For the right Talent, this is a great opportunity because:

 It's a greenfield. Our team is young and we can choose any tools and frameworks that we consider the best ones to fulfill the requirements. 
 Huge impact. You will work on the ML and data infrastructure components that directly related to the efficiency of ML models - the heart of the company's success. 
 Visibility - all the services will be used by other departments immediately; you will have a lot of feedback. 

What You'll Bring

A deep and genuine interest in Behavox as demonstrated by a connection to its mission, marketplace and/or technologies

Linux system administration expertise, solid knowledge of Linux and networks

Designing and managing infrastructure in a public cloud (AWS, GCP)

Hands-on experience with Kubernetes

Development and scripting skills (Python, Bash)

What You'll Do

Manage and troubleshoot complex distributed large-scale software systems
Build scalable, secure and reliable container-based infrastructure
Design the cloud infrastructure
Automate software delivery processes with CI\CD pipelines
Develop tools, services, and scripts (Python)

What We Offer

A truly global mission with a passionate community in locations all over the world
The ability to have a high impact and learning potential as our aspirations require bold innovation
Highly competitive cash compensation package
Benefits include comprehensive health coverage for the employee and their family
Generous time-off policy (30 days annually) and flexible work schedule

About Our Process

We take Talent very seriously and we are building a community of extraordinary individuals working together in very high performing teams. We also know that the best Talent always has options so we believe that the process has to be a two way assessment - the company AND the candidate assessing the business needs alignment, the career next step alignment, and the cultural alignment.

During the process we will begin by exploring the core factors regarding salary and location along with core experience and skills and values alignment. We will then deep dive explore the critical technical competencies we have identified for the role, and then we will deep dive in behavioral competencies.

The most aligned candidate will then be asked to do a practical work task simulation activity so we can make sure that you will enjoy the kind of work the role requires, and this task will typically be presented and discussed with a group of colleagues and managers. Finally we will ask you to meet with a number of our senior leaders to make sure that you are making the most informed call possible. We may record interviews for training purposes.",[]
Senior ML OPS _ Content Creation Technology Group,Ubisoft Montréal,"Montreal, QC",Hybrid,"About the job
Company Description

Ubisoft is a global leader in gaming with teams across the world creating original and memorable gaming experiences, from Assasin's Creed, Rainbow Six to Just Dance and more. We believe diverse perspectives help both players and teams thrive. If you're passionate about innovation and pushing entertainment boundaries, join our journey and help us create the unknown!

Job Description

The Content Creation Technology Group (CCTG) is looking for a Senior ML Ops to work in a team that develops machine learning tools to support teams in creating, testing, and deploying ML solutions to games. You will support and collaborate with Data Scientists, Software Developers and other stakeholders in delivering these ML solutions. The Senior ML Ops role will bring best practices and design principles to assist the team in delivering our ambitious features roadmap.

Main responsibilities: 


Designing and developing machine learning systems and schemes based on the business requirements and objectives. 
Optimizing existing tools for improved performance, scalability, and efficiency. 
Contribute to the industrialization of machine learning projects, focusing on building pipelines and workflows. 
Adapting and improving models’ usage, facilitating tools usage, and adapting these to users needs. 
Create tools to support and integrate the ML models inside a multi-process pipeline. 
Enhancing the existing machine learning libraries and frameworks. 
Collaborating with game production teams, data science team, research team and other stakeholders. 


Other responsibilities: 


Conducting research to stay up to date with the latest advancements. 
Documentation, presentations, and knowledge sharing to communicate complex AI concepts to both technical and non-technical collaborators. 
Creating proof of concepts to satisfy investigations into product directions. 


Qualifications

Education: 


Bachelor’s degree in computer science or computer engineering or equivalent. A specialization in Machine Learning is an asset. 


Relevant Experience: 


A minimum of 5 years of experience in software engineering. 
A minimum of 2 years of experience in machine learning. 


Skills: 


A good knowledge of a production machine learning pipeline; from ML training and deployment to model performance-tracking/behavioral-drift. 
Proficient in Python and have experience with libraries and frameworks such as PyTorch and/or TensorFlow. 
A familiarity with MLOps platforms such as Databricks and/or ClearML. 
A good knowledge of container technology such as Docker and/or Kubernetes. 
A good knowledge of machine learning and deep learning fundamentals. 
A good knowledge of Database products is an asset. 
A good knowledge of cloud-based platforms is an asset. 


Additional Information

We embrace a hybrid work model helping you stay connected with your team and aligned with business priorities, while giving you the opportunity to maintain your work-life balance. Note, that some roles are fully office-based and are not eligible for hybrid work.",[]
ML OPS Senior _ Groupe Technologique Création de contenu,Ubisoft Montréal,"Montreal, QC",Hybrid,"About the job
Description De L'entreprise

Ubisoft est une référence mondiale du jeu vidéo, avec des équipes réparties aux quatre coins du monde qui créent des expériences de jeu originales et mémorables, de Assassin’s Creed à Rainbow Six en passant par Just Dance et bien d’autres encore. Nous croyons que la diversité des points de vue fait progresser à la fois les joueurs et les équipes. Si vous êtes passionné·e par l’innovation et que vous souhaitez repousser les limites du divertissement, rejoignez notre aventure et aidez-nous à créer l’inconnu!

Description Du Poste

Le Content Creation Technology Group (CCTG) est à la recherche d'un ML Ops senior qui travaillera au sein d'une équipe qui développe des solutions d’apprentissage automatique pour améliorer l'expérience joueur, entre autres avec un projet sur des robots visant à simuler de vrais joueurs concurrents. Le rôle du ML Ops senior sera de définir les meilleures pratiques et les principes de conception pour aider l'équipe à livrer notre ambitieuse feuille de route de fonctionnalités.

Principales responsabilités: 


Concevoir et développer des systèmes d'apprentissage automatique et des schémas basés sur les requis et les objectifs de l'entreprise. 
Optimiser les solutions existantes pour améliorer les performances, l'évolutivité et l'efficacité. 
Contribuer à l’industrialisation des projets d’apprentissage automatique, en se concentrant sur la création de pipelines et du déroulement des opérations de travail. 
Adapter et améliorer l'utilisation des modèles, faciliter l'utilisation des outils et les adapter aux besoins des utilisateurs. 
Créer des outils pour soutenir et intégrer les modèles d'apprentissage automatique dans un pipeline multi-processus. 
Améliorer les librairies et frameworks d'apprentissage automatique existants. 
Collaborer avec les équipes de production du jeu, l'équipe de science des données, l'équipe de recherche et d'autres parties prenantes. 


Autres responsabilités: 


Mener des recherches pour rester au courant des dernières avancées technologiques. 
Documentation, présentations et partage des connaissances pour communiquer des concepts d'IA complexes aux collaborateurs techniques et non techniques. 
Création de preuves de concepts pour satisfaire les exigences sur les orientations du produit. 


Qualifications

Formation: 


Baccalauréat en informatique ou en génie informatique ou équivalent. Une spécialisation en apprentissage automatique est un atout. 


Expérience pertinente: 


Un minimum de 5 ans d'expérience en génie logiciel. 
Un minimum de 2 ans d'expérience en apprentissage automatique. 


Compétences: 


Une bonne connaissance d'un pipeline d'apprentissage automatique de production ; de la formation et du déploiement de l’apprentissage automatique au suivi de la performance des modèles/behavioral-drift. 
Maîtrise de Python et expérience des librairies et frameworks tels que PyTorch et/ou TensorFlow. 
Une bonne connaissance des plateformes MLOps telles que Databricks et/ou ClearML. 
Une bonne connaissance de la technologie des conteneurs tels que Docker et/ou Kubernetes. 
Une bonne connaissance des notions de base de l'apprentissage automatique et de l'apprentissage profond. 
Une bonne connaissance des plateformes infonuagiques est un atout. 
Une bonne connaissance des produits de base de données est un atout.


Informations supplémentaires

Quoi nous envoyer


Votre CV mettant en valeur votre formation, votre expérience, vos compétences et les jeux livrés


Nous adoptons un modèle de travail hybride qui vous aide à rester connecté avec votre équipe et aligné sur les priorités de l'entreprise, tout en vous donnant la possibilité de maintenir votre équilibre entre vie professionnelle et vie privée. Notez que certains rôles sont entièrement basés au bureau et ne sont pas éligibles au travail hybride.",[]
Senior Machine Learning Engineer,Loblaw Companies Limited,,,"About the job
Come make your difference in communities across Canada, where authenticity, trust and making connections is valued – as we shape the future of Canadian retail, together. Our unique position as one of the country's largest employers, coupled with our commitment to positively impact the lives of all Canadians, provides our colleagues a range of opportunities and experiences to help Canadians Live Life Well®.

At Loblaw Companies Limited, we succeed through collaboration and commitment and set a high bar for ourselves and those around us. Whether you are just starting your career, re-entering the workforce, or looking for a new job, this is where you belong.

Does working with some of Canada’s most talented minds in innovation supporting retail, digital consumer solutions and analytical platforms excite you? Loblaw Technology powers some of Canada’s most game-changing retail solutions, giving our customers the ability to live their lives well.

Come work with a team that values diverse ideas, fosters a culture of inclusion and develops our talent from within. Loblaw Technology gives you the chance to excel and helps you to strive for success in a big way. Keep reading to learn more!

Senior ML Engineer, Brampton, ON (14-Month Contract)

Loblaw Technology and Analytics is looking for an experienced, dedicated Senior ML Engineer to join our fast-growing team of Data Scientists, Engineers, Front-End Developers and Designers to build and enhance Loblaw's price optimization platform.

In addition to knowledge of cutting-edge machine learning models and techniques, you will bring experience in cloud-based development, engineering best practices and end-to-end product development. This includes the design and implementation of AI/ML algorithms, data pipelines, and ML infrastructure. You will assist teams of Data Scientists, ML Engineers, and Data Engineers in collaboration with an accomplished team of Product Managers and Designers to implement ML/AI solutions at scale. Our price optimization platform is critical to Loblaw’s long-term strategy, directly impacting revenue and customer satisfaction. As a Senior ML Engineer, you’ll play a key role in driving its evolution for this 14-month contract.

We are passionate about what we do and support each other’s growth! You will learn and grow with the team and will have the opportunity to work on a diverse set of challenges as you shape your career.

What You’ll Do: 

Offer expert-level guidance on architecture and champion best practices for internally developed ML/AI applications. This includes driving improvements to existing features, developing new microservices, and ensuring seamless integration with external third-party solution within the team’s various projects.
Act as a key individual contribution, capable of actioning innovative ML techniques and quantifying their potential business impact when deployed at scale.
Develop and implement ML Ops strategies that optimize our deployment pipeline, monitoring systems, and long-term maintenance of machine learning models within the Google Cloud Platform (GCP) environment.
Refine machine learning workflows to maximize scalability, improve operation efficiency, and minimize the overall cost of production-ready machine learning solutions.
Partner closely with diverse, cross-functional teams – including data scientists, engineers, project managers, and business representatives – to deliver enhancements to current capabilities and pioneer new features.

What you Bring: 

Extensive practical industry experience in developing large-scale, production-level machine learning systems.
Advanced proficiency with Python and SQL, including extensive experience with their associated libraries and frameworks.
Have significant experience in building complete, end-to-end applications within cloud environments, with preference for individuals who have worked extensively in GCP.
Demonstrate practical experience in packaging and deploying applications as APIs, utilizing containerization technologies like Docker and Kubernetes.
Solid understanding of software engineering best practices (e.g., object-oriented programming, automated testing, clean code) and experience with Git workflows, Jira, and Confluence within Agile product development environments.
A Master’s or Ph.D. degree in a quantitative discipline (e.g Computer Science, Engineering, Mathematics, Physics, etc.) is preferred.

What Loblaw Offers You

We offer flexibility and balance, and an environment that sets you up for success no matter where your workspace is located.

Here, you will find a great team to help you achieve your goals as you help us achieve ours! Work in our fast-paced, exciting Technology environment, helping our stores, colleagues and customers every day.

Loblaw colleagues also enjoy:

Benefits
Paid Vacation

If you’re up to the challenge, then we would love to hear from you. Apply today, and get the process started. 

Loblaw recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. At Loblaw, we celebrate diversity and strive to build a culture of inclusion where differences are embraced, valued and supported. We are committed to being an equal opportunity employer and encourage people from all backgrounds and identities to apply to our jobs. Accommodation in the recruitment, assessment, and hiring process is available upon request for applicants with disabilities. 

We thank all candidates for their interest but please note, those candidates who meet the minimum requirements for the position will be contacted. 

www.Loblaw.ca/careers

Our commitment to Sustainability and Social Impact is an essential part of the way we do business, and we focus our attention on areas where we can have the greatest impact. Our approach to sustainability and social impact is based on three pillars – Environment, Sourcing and Community – and we are constantly looking for ways to demonstrate leadership in these important areas. Our CORE Values – Care, Ownership, Respect and Excellence – guide all our decision-making and come to life through our Blue Culture. We offer our colleagues progressive careers, comprehensive training, flexibility, and other competitive benefits – these are some of the many reasons why we are one of Canada’s Top Employers, Canada’s Best Diversity Employers, Canada’s Greenest Employers & Canada’s Top Employers for Young People.

If you are unsure whether your experience matches every requirement above, we encourage you to apply anyway. We are looking for varied perspectives which include diverse experiences that we can add to our team.

We have a long-standing focus on diversity, equity and inclusion because we know it will make our company a better place to work and shop. We are committed to creating accessible environments for our colleagues, candidates and customers. Requests for accommodation due to a disability (which may be visible or invisible, temporary or permanent) can be made at any stage of application and employment. We encourage candidates to make their accommodation needs known so that we can provide equitable opportunities.

Please Note:

Candidates who are 18 years or older are required to complete a criminal background check. Details will be provided through the application process.

#EN

#SS #DISTRC #ON",[]
Senior ML Operations Engineer,Abbott,,,"About the job
Job Description – Sr ML Operations Engineer

Interested in applying your wealth of technical knowledge and experience towards an opportunity in the medical field and improving the lives of people with diabetes? The candidate will be responsible for building machine learning and artificial intelligence products and has exceptional skills and experience in productionizing machine learning and AI models.

The candidate will be working with other data engineers, data analysts and data scientists to focus on applying data engineering, data science and machine learning approaches to solve business problems. As a senior member of the Data Engineering & Analytics team, you will be building machine learning and artificial intelligence products to uncover customer, product and operational insights.

The candidate should have a passion for software engineering to help shape the direction of the team. Highly sought-after qualities include a self-starter, versatility and a desire to continuously learn, improve, and empower other team members. Candidate will support building scalable, highly available, efficient, and secure software solutions for big data initiatives.

Responsibilities

Designing, architecting and developing machine learning and deep learning systems and platforms.
Support the AI Ops needs of data science & software engineering teams from multiple products
Customize large language models for product applications, and knowledgeable in natural language processing and generative AI
Lead design and coding of big data and machine learning systems
Collaborate with product stakeholders to ideate and prove viability of machine learning use cases
Translate business needs and goals into an AI approach and solution, and articulate findings to a non-technical audience
Effective advanced analytics and AI skills with a foundation in programming (e.g. R, python), database environment (e.g. big-data platforms and SQL skills), and dashboard development
Design model performance metrics, retraining schedule and tests
Assist with deploying models to cloud infrastructure such as AWS and Microsoft Azure
Create software architecture and design documentation for the supported solutions and overall best practices and patterns
Provide architecture and technical knowledge training and support for the solution groups
Develop good working relations with the other solution teams and groups, such as Engineering, Marketing, Product, Test, QA.
Mentor other engineers and data scientists, remain aware of new developments in the field, and help build and grow the team

Required Qualifications

Bachelors Degree in Computer Science, Information Technology or other relevant field
At least 3 to 8 years of recent experience in ML or ML Ops experience in a production environment
Experience building end-to-end scalable ML infrastructure and data pipelines with cloud platforms
Strong programming (e.g. Python / Java / Kotlin) and data engineering skills.
Experience building data pipelines for models and analytics
Experience with deploying and managing model endpoints
Experience with natural language processing and generative AI
Experience in time series data, signal, image, and video processing
Experience using the following software/tools:
Unsupervised, semi-supervised and supervised learning methods
Machine learning frameworks such as Keras, PyTorch, or Tensorflow
Libraries such as numpy, scikit-learn, scipy and statsmodel
Outstanding analytical and problem-solving skills
Prior experience in the healthcare or other regulated industries
Excellent written, verbal and listening communication skills
Comfortable working asynchronously with a distributed team
Ability to work effectively within a team in a fast-paced changing environment",[]
